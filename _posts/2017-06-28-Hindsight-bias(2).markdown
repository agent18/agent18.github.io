---
layout: post
comments: true
title:  "Hindsight bias  (2)    "
date:   28-06-2017	23:00
categories: The Beginning
permalink: /:title.html
---
From the post by [Eleizer on Hindsight bias][ele_hind]

#### Cost of general policy

In 1986 a Challenger exploded for reasons traced to the o-rings being faulty. The team was aware of warning signs with the O-rings. Using hindsight it would seem, like the team had made the obvious mistake to ignore the warning and hence it is the teams' fault. But in reality, if we would have had to solve all the other problems we saw with warning signs, such as the warning signs from the chains and the belt drive. In hindsight it might appear that the O-rings had very high probabilty. This is because we know the outcome. But in the past, we had no idea that the O-rings would fail in the future. We just had a bunch of warning signs of seeming low probability to deal with. This goes to say that the cost of general policy a.k.a, the cost of effective safety precautions is quite high. If every warning had to be tackled, then the cost would be really high. We should not assume otherwise.

It is not the goal of this essay to say that all those who made mistakes in the past should not be blamed for. But that to take the right factors into account without hindsight, before your judge someone or yourself. As we saw in the [yesterdays post][th_hindsight], it is not enough to just say that we should not take into account hindsight bias. Instructing the jury doesn't help! You have to write your predictions before hearing the outcome. 

>Shortly after September 11th, some minor intelligence warnings surfaced regarding an al Qaeda plot. But the Intelligence probably already had minor warnings about nuclear material for sale, other mafia activity and invasion from mars.

>The test of a model is how much probability it assigns to an observed outcome.

I guess this means that we conclude whether a model is good or not, by comparing the predicted-probability it assigns to an event, to the number of times that event is actually observed after prediction. With Hindsight bias, we may think that our model assigned much more probability than it actually did. Because of hindsight bias, we were quick to assume that the probability assigned to O-rings warning signs was high enough, and yet the warnings were neglected. But in reality, all the different type of warning signs had the same probability. You don't have a favorite (bias). You would have to attend to all. Attending to all would mean a heavy cost of general policy.

>When we attempt to understand past events, we implicitly test the hypotheses or rules we use both to interpret and to anticipate the world around us. If, in hindsight, we systematically underestimate the surprises that the past held and holds for us, we are subjecting those hypotheses to inordinately weak tests and, presumably, finding little reason to change them. (OI2)

#### Open Issue
1) Relate to own life the cost of general policy
2) OI2: Explain



[ele_illusion]:http://lesswrong.com/lw/ke/illusion_of_transparency_why_no_one_understands/
[ele_hind]:http://lesswrong.com/lw/il/hindsight_bias/
[th_hindsight]:/Hindsight-bias.html
