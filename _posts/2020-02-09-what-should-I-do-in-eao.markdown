	---
layout: post
comments: true
title:  "What should I do in life?" 
date:    09-02-2020 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: false
---

## Claims, Claims, Claims!

How does one go about choosing what he can do? This is very crucial it
appears as that could be the difference between slogging for AI vs
slogging for GR. Finding out where I am needed seems to need to look
into the future somehow, look at my capabilities and identify where I
would pose long term success. This is a really hard question to
estimate impact, cause that is the only thing I care about.

Many people propose different ways to identify. Some say look at the
bottlenecks in the top industries. In another article they suggest to
look at a survey they made. I personally have some theories. These
theories include looking at the demand and supply and identifying
where I am needed. How to go from there to what will result in my
insane impact to the best of my abilities is another big ass puzzle, I
have no clue about. Aother intervention to solve this problem is
looking into 80k's tool that they made which gives a frame work on how
to identify which direction to go.

So we start by pasting the links here.

1. https://80000hours.org/articles/high-impact-careers/#1-research-in-relevant-areas

2. 
https://80000hours.org/2017/03/what-skills-are-effective-altruist-organisations-missing/

https://80000hours.org/2017/11/talent-gaps-survey-2017/


https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions

https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience#comments

3. https://80000hours.org/career-decision/article/

All three seem to be different. If there is anything I learn't in the
past regarding these things is that I need to test the claims with
atleast one example.

Also instead of testing these? which I think is going to be hard,
because of the lack of numbers, I think I should just pursue something
and test maybe things like: how to calculate "estimated impact". That
sounds like an option. These are just to brainstorm what is
important. I have to stand on their shoulders man, I got not much
choice or time. I will "make sure" that there are ways to correct the
course of action. 

## High impact careers (What anyone/I could potentially do)

https://80000hours.org/articles/high-impact-careers/#1-research-in-relevant-areas

This section is based on high-impact-careers (post link above).

The below are some of the top recommendations.
> AI safety research in academia or industry.  
> Working in “effective altruist” and existential risk research non-profits.  
> AI and biorisk policy and government careers.  
> Global priorities research in academia.  
> Being a “China specialist”.

Method suggested is to:

- Choose the 2-4 global problems you think are most pressing.
- Identify the ‘key bottlenecks’ to progress within each of these.
- Identify career paths that help relieve those bottlenecks.
- Focus on the options where you have the best personal fit.
- Make quantitative estimates of the impact of your top options.
- Start to narrow down, or if there are no suitable options, go back
  to the start.

I am going to indeed follow these steps. i.e., brainstorm,
bottlenecks, try to have real positions next to it and then make
quantitative estimates of impact, then calculate my personal fit (what
ever that means). I am going to be making several claims like I have a
personal fit for generalist research, I hope I can drop much needed
evidence for these. 

## What are the bottlenecks

How badly is it bottlenecked? I don't think I will ever have an
idea. Is this then worth pursuing?

Defining bottleneck: There aren't enough people now but there is
funding

OR please hang in there, there will be more people needed later.

There are a couple of data points here:
https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really

to compare from. Panindian pandian. and Milan griffes, tara macaulay
and others.

List out the things I am investigating at the moment:

Whether I will get a job? Is there a  bottleneck? how do I get there?
and can I get there? is there any evidence for this? and  how is the
competition? and is there any point going up and beyond the
competition? To understand competition maybe it is better to ask the
org how many people apply.

### Criteria:

**What does it mean?**

**One example of an actual position and a person who go into it**

**Someone who didn't get there?**

EA applicant aaron gertler Max daniel all from:

https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really?commentId=Aic5bcvLmunfhmnhr



**Is there any bottleneck? (evidence)**

There is no bottleneck at this moment it looks like, in that case
consider going into personal fit types? or potential in the future
types?

EA applicant talks about his 5 friends, Max daniel gets several
rejections, despite thier credentials such as: 

> However, I don’t think I am a very special case. I know several
> people who fulfil all of the following criteria:
>
> - They studied/are studying at postgraduate level at a highly
>   competitive university (like Oxford) or in a highly competitive
>   subject (like medical school)
>
> - They are within the top 5% of their course
>
> - They have impressive extracurricular activities (like leading a
>   local EA chapter, having organised successful big events,
>   peer-reviewed publications while studying, …)
>
> - They are very motivated and EA aligned
>
> - They applied for at least 5 positions in the EA community and got
>   rejected in 100% of the cases.
>
> I think I also fulfil all these criteria. Here is my CV roughly at
> the time when I was doing the applications. It sports such features
> as ranking 16th out of around 6000 German medical students, and 8
> peer-reviewed publications while studying.

> People working at EA organisations, sometimes in senior positions,
> were surprised when they heard I didn't get an offer (from another
> organisation).  But he did get several interviews.

> Regarding me being a bit of an outlier: Yes, I think so as well. I
> personally don't know anyone who applied for quite as many
> positions. I still don’t think I am a *very* special case. I also
> got several private messages in response to this post, of people
> saying they had made similar experiences. --- EA Applicant

> I know at least 2 people who unsuccessfully applied to a large
> number of 'EA jobs'. (I'm aware there are many more.) I feel
> confident that they have several highly impressive relevant skills,
> e.g. because I've seen some of their writing and/or their CVs. I'm
> aware I don't know the full distribution of their relevant skills,
> and that the people who made the hiring decisions are in a much
> better position to make them than I. I'm still left with a
> subjective sense of "wow, these people are really impressive, and I
> find it surprising that they could not find a job".---Max Daniel

> I've recently graduated from one of the top ~10 universities
> worldwide, after investing heavily in EA throughout my
> studies. While a student, EA was the biggest thing in my life. I
> read a lot, and several of my EA peers told me I stood out as
> particularly well-informed about EA topics, especially long-termist
> ones. Eventually I contributed some of my own research too. I also
> invested enormous amounts of time in student EA projects. Many
> people, including ones I thought well-informed about the talent
> landscape, fully expected that I would go work for an 'EA
> organisation'. Naively, I believed it too.
>
> Over the last seven months, I've made over 20 unsuccessful job
> applications (I keep a spreadsheet). This has increased the severity
> of my depression and anxiety.

> --- Anonymousthrowaway

But 80khours continues to argue shit like Talent constrain but where
is the talent constrain mother fucker?

People working here don't seem to have funds to grow, idhula talent
oru keda?

And more of this here:
https://physticuffs.tumblr.com/post/183108805284/slatestarscratchpad-this-post-is-venting-it

> So instead I earn-to-give, and am constantly hit with messages (see
> above caveat! messages may not be real!) of “Why are you doing this?
> Nobody’s funding-constrained! Money isn’t real! Only talent
> constraints matter!” while knowing that if I tried to help with
> talent constraints, I would get “Sorry, we have 2,000 applicants per
> position, you’re imposing a huge cost on us by even making us
> evaluate you”.

**Ways to work in this direction?**

**Odds of getting into it?**

### AI technical research (in safety it looks like)

**What does it mean?**

OpenAI is an often quoted example by 80khours in this regard: They
seem to be working on AI systems that act in line with complex human
values and preferences.

**Companies**

Working at OpenAI, Deep Mind, MIRI, FHI, Center for Human Compatible
AI, CSER, BERI, AI Impacts. somehow in the capacity of ML.

**One example of an actual position**

According to [this Google brain guide by 80k](https://80000hours.org/articles/ml-engineering-career-transition-guide/): You can join in as a software engineer or an
ML research engineer. Both seem to work for MIRI, Ought, OpenAI etc...

As a researcher in Ought you are expected to have [lot of software
capabilities](https://ought.org/careers/research-engineer?utm_campaign=80000+Hours+Job+Board&utm_source=80000+Hours+Job+Board) as Ought tries to implement latest ML to check if
computers can do reasoning. 

At OpenAI they seem to want [2+ years of ML experience](https://jobs.lever.co/openai/a0d3b158-14a0-48db-b38c-1c94bb18f69b) and
programming skills for a researcher. And a [research scientist](https://jobs.lever.co/openai/588c1d80-4632-4d5c-a535-9f2c8c80c501) needs
also experience in ML and first author publications and be able to
conduct his research.

**Someone who got into here?**

[Daniel Ziegler](https://www.linkedin.com/in/daniel-ziegler-b4b61882/), graduated from MIT in Software and seems to have
gotten in touch with OpenAI team lead and boosted his ML skills. 6
full-time weeks later he interviewed and became an ML engineer on the
safety team.

[Catherine Olsson](https://www.linkedin.com/in/catherineolsson/), CS from MIT seems to have worked in Amazon,
seems to have got in to OpenAI and then Google Brain and now Open
Phil. Seems to have gotten a fellowship and couple of papers while
researching at Google Brain.

[Josh Achiam](https://www.linkedin.com/in/joshua-achiam-13887199/), worked on his ML skills along with Daniel and is
working at OpenAI since 2018 (just like Daniel). He seems to have a
bachelor's in Aerospace engineering and Physics in University of
Florida and is pursuing his Phd degree in the field of AI in UC
Berkeley and somehow contributing to OpenAI

**Someone who didn't get in there?**

[Max Daniel](https://www.linkedin.com/in/max-daniel/?originalSubdomain=uk), is from Germany and has done his Bachelor's and
Master's in Mathermatics in Heidelberg University. After which he
started working at Sentience Politics and FRI as Executive Director
somehow looks like the role was in operations. He also was Vice
President of an "international nonprofit" with budget of 100k€. Got
scholorship in Germany (might be overrated considering education is
dirt cheap or almost free (<1k a year)). He has done quiet some ML
courses self study.  

Didn't get OpenAI fellowship, but got into FHI as a researcher. And got
into CEA Research Fellowship, 2nd AI safety camp having done all those
courses at Coursera.

**Odds of getting into it?**

I have to check his profile (Josh Achiam) out thoroughly. But if he
studied in UF only (where I also managed to get a degree with funding)
then he ain't no big shit. But his recent publications in 2018 already
has 166 citations. He is on the citations list since 2017. But it
doesn't add up that he was at UF and suddenly got into an AI PhD.

So not sure! Seems too ambitious still (for current me).

**Is there any bottleneck? (evidence)**

For myself, is there a point in apping if other wise

  * [ ] Can write to OpenAI, Ought, FHI and Center for Human compatible AI and
see what they say? 


**Ways to work in this direction?**

There is a [case study](https://80000hours.org/articles/ml-engineering-career-transition-guide/#case-study-daniel-zieglers-ml-self-study-experience) of what needs to be done. Mainly 2 months
of full time debugging, implementation etc.. and got job in OpenAI
after an MIT Bachelor's in CS.

- [ML engineering in Google Brain](https://80000hours.org/articles/ml-engineering-career-transition-guide/) talks about what could qualify you.

- Applying for Fellowship/residency program at Google, OpenAI,
  Facebook, Uber or Microsoft.

- 

> , e.g. for AI strategy & policy I'd be excited to see EAs (a) train
> up in ML, for later work in either AI safety or AI strategy/policy,
> (b) follow these paths into a US AI policy career (esp. for US
> citizens, and esp. now that CSET exists), and (c) train up as a
> cybersecurity expert (I hope to say more later about why this path
> should be especially exciting for AI-interested EAs; also the worst
> that happens is that you'll be in extremely high demand and highly
> paid).--- luke prog who seems to work for openphil recruiting

very interesting thoughts though. especially considering that people
keep telling that once the disentanglement is over shit will hit the
roof here and that it is one of the most important parts of AI. (Link
disentanglement here)


**Value if you work on it?**

No idea

**Other Links**

https://80000hours.org/career-reviews/artificial-intelligence-risk-research/#what-are-some-good-first-steps-if-youre-interested


https://80000hours.org/articles/ml-engineering-career-transition-guide/#case-study-daniel-zieglers-ml-self-study-experience


Or [PHD's](https://80000hours.org/articles/ai-safety-syllabus/#degree) in ML as this is also bottleneck according to some
others..

### Podcasts

https://80000hours.org/podcast/episodes/the-world-needs-ai-researchers-heres-how-to-become-one/

https://80000hours.org/podcast/episodes/paul-christiano-ai-alignment-solutions/

https://www.quora.com/Is-it-difficult-to-get-into-DeepMind-FAIR-or-OpenAI-without-a-PhD-from-a-top-10-university

https://www.reddit.com/r/MachineLearning/comments/5zgbyy/d_what_is_the_job_interview_process_like_at_openai/




### AI policy & Strategy & implementation

**What does it mean?**

**Companies**

**One example of an actual position**

**Someone who got into here**

**Someone who didn't get into here?**

**Odds of getting into it**

**Is there any bottleneck? (evidence)**

**Ways to work in this direction?**

**Value of work on it?**

**Other links**

> It’s not just FHI. There’s also the Center for the Study of
> Existential Risk, the Leverhulme Center for the Future of
> Intelligence, the Tech Policy Lab at the University of Washington, and
> various faculty programs. [00:32:30] Various academic programs around
> the country, in the US, and around the world are looking to hire
> people, for example, as postdocs or a faculty member in areas related
> to AI and policy if you’re someone with an academic background. There
> are probably a fair number of policy positions at tech companies that
> aren’t necessarily specific to AI, but that would lead to getting
> valuable experience in the broad area of tech policy.--- The world
> desperately needs AI strategists


https://80000hours.org/articles/high-impact-careers/#ai-policy

For definitions of what the hell these mean, look [here](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy).

- AI strategy research (how to navigate the transition to advanced AI
  in the scope of political, economic, military considerations)

An example is: ???

- AI policy implementation (implementing policies, working with
  governments, lobbying, fund allocation, advancing policy objectives)

An example is: ???

- Operations (Growing, building, managing and sustaining)

Example is [Tanya Singh](https://www.linkedin.com/in/tanya-singh-08b36a65/?originalSubdomain=uk) working at FHI. Here is a [EAconf talk](https://www.youtube.com/watch?v=sK4lgWx4gjE) that
she gave that makes it clear what in the hell an operations person is
expected to do. 

Or [Seán Ó Heigeartaigh](https://www.linkedin.com/search/results/all/?keywords=Se%C3%A1n%20%C3%93%20Heigeartaigh&origin=GLOBAL_SEARCH_HEADER) 

- Disentanglement research 

Example is what Nick Bostrom does it seems. Write books on abstract
concepts on how AI is expected to take over? So I guess then, taking
these concepts ideas, questions and detailing them and allowing others
to work on it. 

OP of [this article](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy) on EAForum, created this term, it looks
like. Sounds to me like it is strategy research at a fundamental
level.

**How bottlenecked is it?**

But maybe we consider them all equally bottlenecked or trust in
Carricks judgement as this is what he has been doing in 2017
atleast and check for personal fit instead.

**Is there space currently?**

Don't think so unless it is *Disentanglement research, which is
apparently too hot and complicated*, based on

> First, I want to make clear, that if you want to work in this space,
> you are wanted in this space. There is a tremendous amount of need
> here. That said, as I currently see it, because of the low
> tractability of disentanglement research, institutional constraints,
> and the effect of both of these things on the progress of AI
> strategy research, a large majority of people who are very needed in
> this area, even extremely talented people, will not be able to
> directly contribute immediately. (This is not a good position we are
> currently in, as I think we are underutilizing our human resources,
> but hopefully we can fix this quickly.)---[Carrick (Project Manager
> at FHI)](https://www.linkedin.com/in/carrickflynn/?trk=pub-pbmap).

Disentanglement is really important otherwise we are stalled for now
according to Carrick.

**Ways to work in this direction ("career capital") later**

Key organizations to work for according to 80khours listed [here](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/#what-are-the-key-organizations-you-could-work-for):
DeepMind, FHI, OpenAI, MIRI, Cambridge CSER, Alan Dafoe's research
group,AI Impacts, etc...

**Things to read or do before getting any further**

- [EA global talk ](https://youtu.be/Zef-mIKjHAk)
- FHI and EA newsletters
- [Open Phil's analysis](http://www.openphilanthropy.org/blog/potential-risks-advanced-artificial-intelligence-philanthropic-opportunity)
- [Fun primer on AI](https://nickbostrom.com/astronomical/waste.html)
- Finally, Superintelligence

- Attend meetups
- engage with community



## Identify real positions for each bottleneck position

## personal fit estimation

Now it seems to look more tangible.

## Quantitative estimation of the impact of additional person working
there

Need to also figure out what it means to be replaceable

## Rant

A lack of direction I think is my biggest problem. Just a few days
back, working for 2 hrs 2.5 hrs was not that hard. But now it is. I
don't know what is the point and the end seems so less tangible. I
don't like it. I think it will take for ever, and I won't even know if
the outcome is good.

## Why I continue to hate 80khours

So cheeky they are, they say oh you should consider making
quantitative estimates of the value of different career options.
Fucking hell, they even go as far as giving an example, but make it
hypothetical. That's when I lost my shit. Fucking cunts, love to be in
the air, make sick claims, but not show people how to do it. They
really need evidence on if these posts are even working.  

Like one of the hardest things to do is estimate the impact and
conveniently they leave it out. They get very creative in their
example giving. 

## Some other things I could potentially try

- try to improve the lives of ordinary EA folk 
- Coaching for example to people who could potentially save years of
  wasteful life.
  
- 
## Detour

How bottle-necked is EA?

Will I get a job in EA?



How replaceable is your job in EA? What is your value added as a
result of replaceability?

why 80khours is the worst resource on planet earth? Why is 80khours
elitist and useless

## Links being used while writing this article:

high impact research
https://80000hours.org/articles/research/

https://80000hours.org/2015/12/how-to-pursue-a-career-in-research-to-lower-the-risks-from-superintelligent-machines-a-new-career-review/

high impact careers
https://80000hours.org/articles/high-impact-careers/#1-research-in-relevant-areas

How to judge success?
https://80000hours.org/2012/12/how-to-judge-your-chances-of-success/

How to make tough career choices
https://80000hours.org/career-decision/article/

Actual claims of bottleneck in AI:
https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy




Should you play to your compartive advantage when choosing your
career?
https://80000hours.org/articles/comparative-advantage/


If you are unsure to quit a job, quit it?
https://80000hours.org/2018/08/randomised-experiment-if-youre-really-unsure-whether-to-quit-your-job-or-break-up-you-really-probably-should/

Is deepwork the most underappreciated skill for career success?
https://80000hours.org/2016/08/is-deep-work-the-most-underappreciated-skill-for-career-success-an-interview-with-cal-newport/


---

high-impact careers
https://80000hours.org/articles/high-impact-careers/#ai-policy

AI policy
https://80000hours.org/articles/ai-policy-guide/#how-do-you-position-yourself-to-get-into-those-roles

Ai policy
https://80000hours.org/articles/us-ai-policy/

## articles written before (deprecated)

**career-2020-2 aka what should I do in EAO <-- deprecated**

- 80khours hours sucks
- attemps at understanding demand and supply and failing

**what-should-i-do-in-eao** <-- paused

- different careers and what is claimed to be "bottlenecked"

- this branches out to articles on bottleneck and replaceability


**career-2020-1** 

supposed to be the ultimate essay. but being tangented by other
thing. based on the below

**work-one-example**

complete brain dump of attempts to understand career decisions.
