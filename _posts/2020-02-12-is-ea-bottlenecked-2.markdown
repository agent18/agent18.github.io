---
layout: post
comments: true
title:  "EA is not Talent constrained or bottlenecked" 
date:    12-02-2020 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: true
---

## Introduction

EA is TC apparently, but there seems to be a lot of evidence that it is
not. And as I am trying to figure out what I need to do in life, I am
confused and want to clarify my thoughts.

## Definitions

We are going to be primarily dealing with the term "Talent
Constrained". To avoid confusion we try to understand what it is
first. 80khours defines TC in "[Why you should work on Talent
gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps)" (Nov 2015) as,

> For some causes, additional money can buy substantial progress. In
> others, the key bottleneck is finding people with a specific skill
> set. This second set of causes are more “talent constrained” than
> “funding constrained”; we say they have a “talent gap”.

Ok! A cause is TC if finding people with specific skill set proves to
be difficult. The difficulty I assume is in the lack of of those
skilled people, and not some process/management constrain. [EA
Concepts](https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/), clears this confusion up with a better worded "example":

> Organization A: Has annual funding of $5m, so can fund more staff,
> and has been actively hiring for a year, but has been unable to find
> anyone suitable... Organization A is more talent constrained than
> funding constrained...

**Note**: In this post, discussions are focused on "Orgs that are TC"
and not "Causes that are TC". When I am told that AI strategy is TC
with the lack of "Disentanglement Research" (DR), I don't know what to
do about it. But if I know FHI and many other orgs are TC in DR, then
I can plausibly get skilled in DR and apply to close the talent
gap. So looking at causes for me is less helpful and less concrete and
is not what I have set out to uncover.

<!-- needs repair in english but content ok-->

## Why I think EA is TC

EA has been and is talent constrained, according to surveys made by
80khours and CEA since 2017. Several organizations seem to think so in
these surveys: [2017 survey](https://80000hours.org/2017/11/talent-gaps-survey-2017/), [2018 survey](https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions), [2019
survey](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis). In all the surveys EAs on average claim to be more Talent
Constrained than Funding constrained. For example in 2019 EAOs
reported feeling more (3 out of 5 rating) Talent Constrained and less
(1 out of 5 rating) Funding Constrained[^11]. More details in the
footnote [^1].

80khours doesn't seem to have changed it's position on this matter
since 2015. 80khours suggests that we should focus on providing talent
to the community rather than ETG in ["Why you should focus on talent
gaps and not funding gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/). They explain that in AI Safety, the
funds seem enough as per the evaluation of Open Phil and there are
people who are ready to donate even more funds, but think there isn't
enough "talent pool" (back in 2015)[^12]. More posts such as ["Working
at EAO](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/) (June 2017), ["The world desperately needs AI
strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/)[^16] and "[Why operations
management is the biggest bottleneck in EA](https://80000hours.org/articles/operations-management/)" (March 2018), continue
to make the case for EAOs being TC.

In Nov 2018, they wrote a post to clarify any misconceptions regarding
the understanding of the term TC: ["Think twice before talking about
Talent gaps"](https://80000hours.org/2018/11/clarifying-talent-gaps/). 80khours informs us that EAOs are not TC in general
but are TC by specific skills. Some examples being, people capable of
Disentanglement Research in Strategy and Policy (FHI, OpenAI,
Deepmind), dedicated people in influential government positions
etc... Great! The claim becomes narrower: EA is TC in specifically X.

## Where is the EA specifically TC

There seem to be a list of posts from 80khours from which we can
gather where EA is specifically TC.

- Surveys ([2017](https://80000hours.org/2017/11/talent-gaps-survey-2017/), [2018](https://80000hours.org/2018/10/2018-talent-gaps-survey/), [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis))
- Bottlenecks in problem profiles ([Shaping AI](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/), [Working in an EAOs](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/))
- Priority career paths (in "[High Impact Careers](https://80000hours.org/articles/high-impact-careers/)") 
- Bottleneck hype posts ([AI strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/), [Operations](https://80000hours.org/articles/operations-management/))

**The surveys** from 2017 to 2019 that informed us that the EA Orgs are
TC, also provide information on "what sort of talent the EA orgs and
EA as a whole would need more of, in the next 5 years?". This question
sounds like a proxy to "Where is EA specifically TC?". 80khours seems
to agree with this proxy approximation of the question in the surveys,
as evidenced [here](https://80000hours.org/articles/high-impact-careers/#our-list-of-priority-paths) and [here](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#what-skills-are-the-organisations-most-short-of). The top 7 results (out of 20 or
so) are below:

|   | 2017        | 2017 (EA)   | 2018       | 2018 (EA)  | 2019      | 2019 (EA)   |
|---|-------------|-------------|------------|------------|-----------|-------------|
| 1 | GR          | G&P\***     | Oper.      | G&P\***    | GR        | G&P\***     |
| 2 | Good Calib. | Good Calib. | Mngment    | Oper.      | Oper.     | Mngment     |
| 3 | Mngment     | Mngment     | GR         | ML/AI      | Mngment   | H. GPR\*\*  |
| 4 | Off. mngers | ML/ AI tech | ML/AI      | Mngment    | ML        | Founding    |
| 5 | Oper.       | Movt. build | H. GPR\*\* | Hustle GPR | Econ/math | Soc. Skill  |
| 6 | Math        | GR          | Founder    | GR         | HighEA\*  | ML          |
| 7 | ML/AI       | Oper.       | Soc. skill | Founding   | H. GPR    | Movt. Build |

\* High level overview of EA  
\*\* The hustle to really figure out what matters most and set the
right priorities  
\*\*\* Government and Policy 

Although some of the "talents" are down right vague, the rest of them
seem to ring a bell with me as to what they could mean. For example
when I think of GR, I think of a Generalist Researcher in Open Phil or
GiveWell, whereas when I think of "hustle to really figure out what
matters" or "one-on-one social skills", I have 0 examples in mind and
have no idea what they are talking about. As a result I can't do much
with these vague descriptions and am forced to skip it as I am unsure
how to interpret them.

Another way to arrive at or to supplement this list, is to look at the
**problem profiles** and check what the bottlenecks are. For example, in
the [profile on shaping AI](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/) (March 2017), we see that 80khours
calls for people to help in AI technical research, AI strategy and
policy, Complimentary roles and, Advocacy and capacity building. So
basically EVERYTHING IN AI, except ETG is TC (it appears). In the
problem profile on [GPR](https://80000hours.org/problem-profiles/global-priorities-research/#what-is-most-needed-to-solve-this-problem) (July 2018), 80khours suggests that they
mainly need researchers trained in math econ and phil etc... Also
needed are academic managers and operations staff. Is it just me or is
the EA TC in "general"? Like when researchers in econ etc...,
operations and managers are in shortage in a GPR org and an AI org,
then what does that mean?

In the post on [High Impact Careers](https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories) (August 2018), the **priority
career paths** aka TC paths according to 80khours, are research and
policy work in AI safety, biorisk, EA, GPR, grantmaking, nuclear
security and institutional decision making.

> In brief, we think our list of top problems (AI safety, biorisk, EA,
> GPR, nuclear security, institutional decision-making) are mainly
> constrained by research insights, either those that directly solve
> the issue or insights about policy solutions.

<!--- AI strategy and Policy research
- AI safety technical research
- Grant maker focused on top areas
- Work in effective Altruism orgs
- Global priorities researcher
- Bio-risk strategy and policy
- China Specialists
- Earning to give in quant trading
- Decision making psychology research and roles-->

Some **hyped posts** exist as well for operations and AI Strategy
atleast:

- [The world desparately needs AI strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/) (June 2017)

	Here, other than the title, I didn't really understand the
    "desperate need for AI strategists" as Miles nor Rob seem to help
    the listener understand the TC. We might have to rest on the
    shoulders of these giants as they are expected to have better
    insight into the problems.
	
- [Why operations management is one of the biggest bottlenecks in
  effective altruism](https://80000hours.org/articles/operations-management/#which-traits-do-you-need) (March 2018)
  
  80khours updated this post saying that the post is "somewhat out of
  date", and that the job market has changed over the last year. Fair
  enough, these things happen.
  
In conclusion, EA seems to be TC with global priorities researchers
and other researchers, AI safety strategy and all policy researchers,
~~operations staff~~ and Managers. I deliberately ignore China
Specialists as I don't think it will ever be an option for me.

## EA does not seem to be TC

<!--In the previous sections it is clear that GR is quite sought after
in all three surveys
([2017](https://80000hours.org/2017/11/talent-gaps-survey-2017/),
[2018](https://80000hours.org/2018/10/2018-talent-gaps-survey/),
[2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis)). In
fact in 2019 it climbed all the way to the top implying that it is
"most" TC. Furthermore in their recent post on [High Impact
careers](https://80000hours.org/articles/high-impact-careers/) (Aug
2018), they suggest that research insights in EA, GPR etc... are some
of the most constrained. But when we look at the [recent hiring round
of Open
Phil](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting)
the claims don't seem to hold water. --> 

Contrary to the claims in the previous section, there seems to be
evidence against those claims. A couple of organizations such as Open
Phil, EAF, Rethink Charities (group), FHI, and TLYCS don't seem to
feel TC. 

Researchers in GPR are claimed to be constrained. GR's also stand on
top of the survey lists shown before. Yet Open Phil seems to paint a
different picture. The hiring round by Open Phil started in Feb 2018
and ended in December 2018. They wanted to hire 5 GRs. They report
that more than a 100 strong resumes with missions aligned to that of
OP were received. 59 of were selected after remote work tests and went
into an interview. Of this, 17 of them were offered a 3 month trial
and 5 selected in the end. "Multiple people" they met in this round
have potential to excel in roles at Open Phil in the future (how many
is mentioned exactly). Open Phil does not seem to feel that there is a
lack of skilled people. It appears that they had plenty to choose from
and that they have found suitable candidates.

Would Open Phil like to hire more GRs? Yes, but they don't have the
capability to deploy such a pool of available talent, they say. They
seem to be constrained by something else, something not "talent" such
as process or management or mentorship etc...

---

Researchers in AI are also claimed to be a constrained. In [EAFs
recent hiring round](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) (Nov 2018) to hire 1 GR ([grant making
evaluator in AI](https://ea-foundation.org/open-position-research-analyst/)) and 1 operations personnel, *within just 2 weeks,
66 people applied to this EAO in a [non-hub](/what-should-I-do-in-eao.html)*. These 66 trickled
down to 10 interviews after work tests, 4 were offered trials and 2
were selected in the end. No TC in GR here either.

[Carrick from FHI](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy) (June 2017) lists the following from the AI
strategy space: There is a high Demand for highly skilled
Disentanglement Researchers. AI policy implementation and research
work is on hold until research disentangles. And even extremely
talented people will not be able to contribute directly. There is
institutional capacity to absorb adn utilize more research in
Strategy. 

Except for Disentanglement research (DR) where there seems to be large
demand and if you meet the bar, you will get a job it looks like. But
for the rest the story doesn't sound like AI policy and other
opportunities in Strategy are TC except for DR. This article was
written in September 2017 and I am not sure what is the update in
Feb 2020. 

Most articles on [AI strategy and Policy appear to be written in
2017](https://80000hours.org/topic/priority-paths/ai-policy/). And as late as 2018 this article by Carrick is still [cite
this article as of nov 2018](https://80000hours.org/2018/11/clarifying-talent-gaps/). Suggesting to me that they may still
well be not TC. But they claim in the future they would need "a lot of
AI researchers" working on this. But currently not so much.

For AI strategy to advance Disentanglement Researchers are apparently
needed and these are really hard to find and in huge demand according
to Carrick of FHI. NOW THAT IS TC.

---

[Peter Hurford](https://www.linkedin.com/in/peterhurford8/), has various titles such as Vice Chairman of the
Board, President of Board and Co-executive Director of Charity
Science, Rethink Charity and Rethink Priorities. He seems to have no
problem finding talented people to work for him. In fact he says he
finds it hard to turn down strong applicants and still has to do it
anyway in 2019.

> I’ve certainly had no problem finding junior staff for Rethink
> Priorities, Rethink Charity, or Charity Science (Note: Rethink
> Priorities is part of Rethink Charity but both are entirely separate
> from Charity Science)… and so far we’ve been lucky enough to have
> enough strong senior staff applications that we’re still finding
> ourselves turning down really strong applicants we would otherwise
> really love to hire.---[Peter Hurford says in the 2019 survey](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC)

Peter Expresses his concern on the bemoaning of ETG. As evidence to
his claim I believe unless I can be a quants trader I am a loser and
that it is better to focus on working at an EAO as a result. And now
even this is turning out to be hard as fuck. And the one org we turn
to for career advice sucks. 

The Life You Can Save's Jon Behar also agrees with Peter that this
whole "talent bottleneck", atleast with the people they seem to be the
case and that money is more in need for them. And that they are more
strapped for Funding to hire new talents and not the lack of talents themselfs.

So far we have seen Open Phil, Rethink serieses, TLYCS, FHI and EAF
all seem to be full a people and not having much capacity to take in
new players. Except for one concrete thing of Disentanglement that I
have, it appears for the jobs.


If 5 of the best people are hired here, then the pool of best people
reduces. But there are 100s of people with good resumes. I am not sure
how to go beyond this thing. I could slog my ass and end up as a GR
but then I don't want to be fucking replaceable. If all I am going to
be is replaceable then there seems to be little point in working your
ass off, growing your skill in that direction. but howeerve if there
are other advantages of being a GR at open phil like growth, then that
is a separate point. Anyways, 80khours seems to be off in its
generalization. And all the survey orgs are probably talking about
something else. This is not just for GR. AI safety, Rethink charity,
report similar lack of TC. 

complete AI safety example and other examples. 

Conclude with they are not TC. Now it still stands if we should work
in these situations, and for that competitiveness plays a role. 

80khours sprays bullshit suchas TC does not imply non competitiveness.
Try to give a rebutt to it..

## Let's help the world out

I have been using 80khours since 2017 and have read almost all their
posts, spent weeks after weeks reading them to figure out what I
should be doing in life. They seem to have done a ton of research and
put out many many posts for us readers to benefit from. In the process
they have made a lot of claims, as shown in the previous section which
are hard to verify as we don't have the insight, contacts or the data
that 80khours is exposed to. Unfortunately, 80khours doesn't seem
approachable other than through coaching (which is only for the
ELITE), comments sections are pretty empty, and I don't know of any
other sources doing this sort of research and coaching people. So
being as low IQ as I am, I formed the impression as shared by my
brother [EA applicant](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really):

> Hey you! You know, all these ideas that you had about making the
> world a better place, like working for Doctors without Borders?
> They probably aren’t that great. The long-term future is what
> matters. And that is not funding constrained, so earning to give is
> kind of off the table as well. But the good news is, we really,
> really need people working on these things. We are so talent
> constrained...--- [EA applicant in the EA Forum](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really)

And looking at the *276 upvotes* this post got (*the highest ever
votes in this forum*), it might appear that a "lot of people" share
the sentiment that EA could potentially be seriously TC (as per the
list in the previous section).

But are these claims true? Can you test them? What do they mean? Maybe
they meant something else? Are you able to verify them with atleast
one example? Did 80khours try to generalize too much?

Until I stumbled upon EA Forum just 2 weeks back (by accident), the
word of 80khours was the word of God for me. Finding this one
particular post seems to have grounded me and brought me to reality:
"[After one year of Applying for EA jobs](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really)". It opened a pandora box
of evidence (which I am really really grateful for). Without further
ado the ANTI-THESIS.

## Replaceability

I think this is something very important, that converts that
competitiveness of something into whether there is a point working on
something or not. 

Start with 80khours claiming replaceability is bullshit adn then put
forth arguments and also quote rob wambuliamman

It's too competitive and I despise 80khours for selling me bullshit.



Orgs are hiring slow, they remain small, 

So am wondering what in the hell 80khours is talking about, as the
only 2 hiring rounds details I see, seem to be saying it is not hard
to find GRs... AT ALL.

## You wont get into EA

Start with 80khours telling people they shouldn't ETG (as it is
pointless). They should focus on 

and maybe list all the people who didn't get in

## How I think 80khours misleads everybody

- definitions 

- no examples

- working for the elite

or try to see if you can make that a post the things I have written
earlier.

or maybe it is just better to take mild digs at them... here and
there. 



## Todo

1. Footnotes

2. repair english in texts

3. Spell check

4. 

## Footnotes

[^1]: 

[^2]: 
