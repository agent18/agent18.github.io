---
layout: post
comments: true
title:  "Should you work at an EAO or ETG for that EAO"
date:    12-03-2020 
categories: posts
tags: 
permalink: /:title.html
published: false
---

## Entry question and Claims Claims Claims 

80khours saying it is better to work at eao than do ETG.


How much ETG for a GR at Open Phil, Rethink Charity, TLYCS, GiveWell?

How much ETG for AI strategy policy person?

How much ETG for editor types?

How much ETG AI safety positions?

How much ETG for management positions in any org?

First year alone?

What about life time?

Of course this begs the question if onvr I knw this, these numbers
will also make sense for me. Emmm... They will make sense for me if
I am able to get the job there. I assume making it to the top is
already a big deal. And it is not clear how much of the impact you
actually make. So lets gets the daaaaay staaaarted waaaat....

I am trying to look at what people typically are and trying to see if
the climb the steep hill is even worth it?

## What do you need to determine how much ETG? 

- how replaceable it is

- spillover effects (aka displacement chain) how big it is

- amount of dollars moved/raised by the org

- % of contribution to you vs donar

- % contribution within the org associated to you

## Open Phil

Some of the hardest things to estimate would be Open replaceability
and spill over effects.



## Introduction

Jobs are not TC. great. But how replaceable are there... how far do
the displacements go until... 

What is the value of working in EA vs ETG 5 examples spanning the
different things.... 

What can you do? Ask the organizations them selves which is a bullshit
advice... because orgs are super busy and wern't able to help me out. 

## TC

TC is not true, atleast I barely know of cases where a position is
TC. 

## Why replaceability

Whether an org is TC or not, has implications on the impact made. The
true impact you make when a job is TC at an EA org is (much) higher,
than when the job is not TC. A junior GR at GiveWell is expected to
move 2.4m<span>$</span> if the job was TC. The same GR is expected to
move only [244k](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable) in the case that the hired GR is better than the
next-best-candidate by 10% (Not TC). Such is the distinction between
being TC and not. 

So what is this replaceability and how do we come about it?

Say there is only one EAO and they have an opening. Peter and Jay are
the only people "worthy" of that job. Peter can produce a value of
500k at that EAO and Jay can produce a value of 400k at that job. 

If Peter gets the job the value for the world is 500k. If Peter sits
on his ass at home and masturbates and B takes the job, then the value
for the world is 400k. So when Peter takes up a job and doesn't he
only makes the world better by 100k and that is his value. 

You are only as good as you are better than the last candidate. 

The above is a very simple case, where Jay doesn't take up any other
job or where there is only one EAO and one job and not many more like
Jay. These also influence what is the impact. 

So let's say there are a dozen jobs then what happens?

Peter creates 500k value, and then Jay creates 400k value and then
what we see is that there is 900k value. 

There are not many GR openings (5 in Open Phil in 2018). And 100s of
applicants applied for such a position. Not sure what to make of the
English... The current situation feels like there are not many places
those 100s can go. Let's say another 5 could go to? Maybe they go to
other places and create impact and then the ones left over are people
like me and there are many of them... all claims... Like how will I
get far with determining this ? This seems like I can't do shit about
it. 


Maybe I can say as peter suggested that it is between this and
that... this being one person and the other guy turned off? and that
being there are plenty of jobs 

The spectrum is somewhere between the second best not getting the job
and everyone in line getting a job because it is TC. But we all know
that is not true. 

You wont get into EA... It is so FULLLLLLLLLLLLLLLLLLLLLLLLLL.

Level 1 thinking... Level 2 thinking 

Its so hard to get values such as what would be your contribution? 


Level 1 thinking and Level 2 thinking:

Level 1 thinking is when it is TC (which it clearly is not), and level
2 thinking is when it is 

## Comparing two different interventions...

Comparing ETG to where and a GR at GiveWell...

Should I donate to a priority cause? or give to GiveWell? 

So then the discussion is how much you move (under level 1 and level 2
thinking)  

GiveWell does RCTs and ensures weather an org is worthy or not. So it
is the only org that has estimates on where ETG can best go... ETG to
valliammai polytech and ETG

**Claims**: there are more people responsible for the impact than just
the donor and the grants researcher.

**Example**: When you give money to GiveWell, you naturally share
impact. The grants researcher will have some impact as he is the one
who guides your money. This money is guided to say AMF, where there
are 2 people and many volunteers working, who will claim some impact
for guiding the money to buy nets... are there other poeple getting
money from here? salary of the employee?

There are so many people and it would be naive to assume that it is
only the GR and donor who share the impact. 

**Definition**: check 

**Checklist**: 
 
**Claims**: You can compare ETG to working at an EAO

**Example**:  Let's take working at GiveWell as a scene and donating
to GiveWell.

I could donate 50k to GiveWell. In 2015 Milan Griffes estimates 2m
moved by him. And a good chunk went to AMF probably. 

Donor comes with 113m. Org costs say take up a few million and
givewell reports moving 110m

- Donor (60%)
- GiveWell (20%)
  - GR (0.2%)
	- replaceability (10%)
	- actual impact (2%)
  - other people
	- replaceability (x%)
	- actual impact (98%)
- Intervention master (AMF evidence aravind action) (20%)
  - employees
  - employers 
  - Org costs?
  
A donation of 50k will lead to 30k impact. GiveWell moved 110k donated
dollars in 2015 of which the GR Junior could be associated with
(0.2%). Of this 0.2% moved only 20% is associated with the
employee. So I think a GiveWell employee would contribute 0.04%. This
implies that in 2015 junior GR moved 44k. So working at GiveWell being
10% better than the last hire in a level 1 assumption is still better
than donating 50k. Interesting... Impact wise.... and this number
could only be higher as it moves towards the TC assumption.

Anyways this is GiveWell...

I am wondering whether salary of the GR should also come in the
picture. Operations costs... As per the impact, it is split between
diff orgs. Not as per the cost. Regarding replaceability of the org
itself, I think it is hard to estimate. Am more inclined to the level
0 thinking in this case. If GiveWell is removed then are there other
organizations that can do the job? not yet.. but also maybe because
GiveWell is alive. 

Is GiveWell replaceable? If it is then I need to take it into
account. As I have split GiveWell into people and their contribution,
it doesn't seem to bother my part of the contribution. I claim that
because the replaceability is brought to a personal level it doesn't
affect me. 

For example if there is as good of a person working available instead
of holden enbadhadi shoulder then if holden doesn't work he then the
other person takes care of the work. So this doesn't affect GiveWell's
output. I look at it as GiveWell has 110k to distribute. That is
replaceability on a personal level. So if donors didn't have giveWell
what would he do? he would probably spend on the best guesses he can
make. So what is the contribution of GiveWell when it is there - when
it is not there, in terms of output... Insanely hard to
calculate... And I don't have any resources to do it. 


**Claims**: It is fair to compare ETG to GiveWell with working at GiveWell

I don't know what it is fair means. 

but I can do the following: 

**Example**: ETG of say 50k to GiveWell (donor), say 50% goes to donor
and 50% to the person who decides where the money should go. If you
give 50k to GiveWell, based on their research they gonna say 


**Definition**: 

**Checklist**: 
 

**Claims**: It is not fair to compare ETG to Not-GiveWell with working at GiveWell

## Are there spillover effects?

Possibly


## Impact at a job what all do you need?


## Estimate AI safety or research job

## Estimate GR at open Phil

## Peter's company

## GiveWell

## TLYCS

## references

https://www.lesswrong.com/posts/3Ss29ihXsBb8tuoxK/earning-to-give-vs-altruistic-career-choice-revisited

https://www.facebook.com/jefftk/posts/613456690752?comment_id=713258

https://forum.effectivealtruism.org/posts/M958XZGP6w6anfEGQ/what-s-the-median-amount-a-grantmaker-gives-per-year


## Reply to Arun Gertler

First of all. Thank you very much. Appreciate that you provided me
valuable feedback.

> I've made some comments. 

By this you mean this email is your 'comments' right? or was there
supposed to be an attachment?

> There were a few spots where your interpretation of evidence didn't
> match mine.

Can you please provide an example? and also say where else? so I can
check it.

> Overall, I think the truth is complicated -- some areas of EA are
> talent-constrained, some aren't, and which is which depends on your
> definition of "constrained".

But the definition is clear right? The post starts off with it, from
80khours or did I misinterpret their definition? TC is when you are
unable to find skilled people (e.g., Disentanglement Research). Are
there other areas that are TC? 

> The job market is tough for some people and easy for others. 

Other than in the end of the essay I didn't really talk about
this. So, I think you are pointing to the end where it says, "They
severely downplayed how competitive it is to get jobs in EA orgs."
80khours say that as long as I am "EA-minded" that gives me a decent
chance of getting a job in EA, but the truth is far from it (link).

> 80K said a lot of true things, some things that weren't
> well-supported, 

For example?

> and some things that were true at the time but became less true
> later.

For example? Operations jobs being not TC you mean? do you have other
examples?

> I don't know how you should integrate this into your post. Overall,
> I thought the best parts were:

> * You pointing out that a lot of 80K's claims have weak or unclear
>   backing 
> * You looking at real hiring rounds for evidence of
>   whether different orgs had a hard time finding people

Do you know other hiring rounds posts. I didn't find any other.

> The parts that weren't as good:

> * Generalizing from a couple of orgs, or a few personal statements,
>   to make claims about the whole EA movement (which involves
>   hundreds of people working full-time positions across dozens of
>   orgs) 

1. So looking at Carrick's statment and using it to represent the AI
   strategy community was wrong? Even Nick Beckstead said that jobs
   were "quite competitive" (in a podast) in this field (suggesting
   that strategy community is not TC).

2. Concluding from Open Phil, EAF and RC that GRs are not TC is wrong?

	I really find it unlikely that other orgs in GR are TC. These orgs
	point out that they had to turn down many of those who applied and
	were good. This suggests that several other jobs would be filled in GR
	in other orgs as well.

3. "Contrary to the claims from 80khours, it appears that several orgs
   are not TC." is wrong?
   
   I just want to point out here that when I looked for evidence there
   was very little in favor of TC and many people from EA suggesting
   otherwise.

> * Blaming 80K for a lot of individuals' problems when those
>   individuals had many other ways to look for advice (as you've
>   shown by emailing me and posting on the Forum).

You are absolutely right. I was gullible enough to believe that
80khours would have done their research, are good in communication and
that it was going to be hard for me to verify all the research that
they have done. Everywhere I turned, people were talking about 80ks
advice. I feel stupid now that I wasted so much time reading
those. But many people have fallen prey to this (footnote 8). 80khours
needs to hear this that they were one of the reasons for it, I
think. They need to be held responsible for the content they put up.

Also Aaron, looking for advice seems to be not easy. For example, I
recently reached out to several people from the EA community to get a
feel of how replaceable are the specific jobs at EA. This would allow
me to compare ETG to working at an EAO. I barely got any
response. What am I doing wrong? What else can I do?

I am hoping the EA conference in October and my posts in EA forum help
clear out the air a bit more.

> These are all just my opinions, and you can post whatever you'd
> like. But if you do end up revising the draft, I'd be glad to look
> over a new version sometime! It's really good that you're trying to
> make evidence-based critiques, and checking with experienced people
> to hear their thoughts.

Thank You indeed for your kind words. I hope to hear from you
regarding this email as that will pinpoint the things I would need to
change. Once I hear from you on this mail I will change parts of the
essay to take in your criticism. If I didn't do too many changes then
I don't ask you for feedback. And I will post the essay. Otherwise I
will write to you again.

Thank You very much.

## replying to Peter_hurford

> I mean, it's kinda intertwined, right? Presumably you are earning to
> give to fund people to do stuff. So someone needs to do that
> stuff. That person could be you. Or you could be the one funding. I
> think it really comes down to comparative advantage / personal fit
> (how good are you personally at doing vs. earning?) and marginal
> resources (of the orgs you would donate to or work for, how much do
> they want a talented person versus more money?).

How do I do this Peter? I would think I need to start with what values
of impact I can get with ETG and working at an EAorg? And based on the
outcome I can choose to get better/pursue in ETG or GR-sills.

For example, if it turns out that 30k donation is enough to meet the
EA org impact, then I would do an MS and get a job in the FAANG and
30k would be easy to donate. But if it turns out that working at
GiveWell creates an impact of 200k as a GR, then I would rather spend
the next few years doing focused practice on GR-skills as I know for
that 200k in donations is going to be super hard unless I do something
like trading (which I can't). I would like to maximize my impact.

So I am looking for examples that show how people came to the
conclusion that it is better to work in research in an EAO rather than
ETG. These examples would include replaceability and other factors I
think.

> In short, I think getting general examples of people having a high
> impact by working in an EA org would be misleading for anyone actually
> making this kind of career path decision.

I don't want general examples. I would like specific examples of
impact of people in GR and management positions in Open Phil (and the
like), AI safety (technical researcher) positions in OpenAI (and the
like) etc...

AT WHAT ETG DO I BECOME INDIFFERENT TO WORKING IN EA ORGS
(specifically GR, Safety strategy research and management positions)?


## replay to Michael St Jules

> I suppose I'm not directly answering your question, but I think it
> might be pretty hard to answer well, if you want to try to account
> for replaceability properly, because many people can end up in
> different positions because of you taking or not taking a job at an
> EA org, and it wouldn't be easy to track them.

If one hasn't taken into account [replaceability](https://www.jefftk.com/p/replaceability-thinking-on-the-margin), or the
[displacement chain](https://forum.effectivealtruism.org/posts/nn4nPvxF59AAr2G2n/replaceability-with-differing-priorities), how do you know it is better to work in EA
orgs rather than ETG (for X dollars).

Milan Griffes reports with a replaceability of 10% (guess) and
attributing 60% (guess) contribution to the donor, that his impact was
244k. Now if you remove the replaceability it is 2.4m. 

> I doubt anyone has tried to. See this and my recent post.

And the 80khours [article you cited on replaceability](https://80000hours.org/2015/07/replaceability-isnt-as-important-as-you-might-think-or-weve-suggested/) seems to be
so off with its suggestions. 80khours are suggesting that "Often if
you turn down a skilled job, the role simply won't be filled at all
because there's no suitable substitute available". Whilst the only
evidence I can find says completely otherwise: [Carricks take on AI
S&P](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC), [Peter representing RC](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC), [Open Phil's hiring round](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting),
[Jon Behar's comments](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB), [EAF's hiring round](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round).

As for your post, I saw it as well, and gained on the "displacement
chain" verbiage and calculation. It was very difficult for me to
follow the discussion on difference in priorities. In any case, I
think we need atleast one real example to test a claim.

How are people so confident in saying that working at an EAO is better
than doing ETG especially considering how "full" the talent pool is
([Carricks take on AI S&P](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC), [Peter representing RC](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC), [Open Phil's
hiring round](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting), [Jon Behar's comments](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB))?

What is the evidence?


## People are like parrots

Just repeating the same story that 80khours says. jesus.

## Parrot

> Firstly, it's maybe worth being explicit that lots of people should
> neither EtG nor work for an EA org: a lot of people should be
> focused on building skills for future work, and others should be
> working in places (like in government) which are not explicitly EA.

I am not sure what this means for me. 

> To answer the question as best I can, I would do the following:
>
> - Which roles am I considering?

This I have figured. GR in EA orgs or Research in AI safety Strategy
policy and maybe management positions.

> - In each of these roles, what value would I provide over the
>   counterfactual?

How am I supposed to do this? And my question to you is mainly
oriented towards this! Ask organizations? They
are too busy to help me. Check out at 80khours? Well, there is no
evidence there only more claims. The whole Talent constrain discussion
seems to fall
apart:http://agent18.github.io/is-ea-bottlenecked-2.html. The values
of new hires estimated as shown by Michelle's link is not right. They
are inflated according to people in the comments due to adding several
costs such as finding new people etc... And their stands on
replaceability currently is "depends". 

> - What does the organisation I most recently donated to do (on the
>   margin) with my donations?
> - Which looks better? 

This is easier said than done. I am really looking for examples of
people showing how this is done. As in the post my only example is
from Milan Griffes. I don't think anyone has done this and that people
are piggy backing on 80k's "research". I have spent a lot of time on
80khours.

> Therefore, it depends on what you think the best funding opportunity
> is as well as what roles you are considering. This in turn depends on
> your beliefs about what you want to make happen and your skills. Even
> the way I broke up the question is somewhat tailored to situations
> I've had in the past.

> There is no general calculation for all orgs or
> all people, though you may be able to copy the decision of someone who
> shares your rough values and rough skillset.  

Now this is something I haven't thought off.

> It may also be possible to resolve this by answering the simpler
> question 'for an organisation that I think is really valuable, how
> much would more money would they need to be able to add equivalent
> value to having me around' (which is sort of what the survey Michelle
> links to tries to help with) but this is often trickier than it seems.

I doubt I would get a response. I reached out to Open Phil, EAF, RC,
FHI, TLYCS, CEA asking them about value created by a GR in the
respective orgs. People seemed to be busy and didn't have such numbers
ready to deploy.

## reply to PH

Peter please bear with me.

> To make a very long story very short, I think you should focus on
> trying to get a direct work job while still doing what is needed to
> keep your FAANG* options open. Then apply to direct work jobs and
> see if you get one. If you don't, pivot to FAANG.

1. So it looks like you are suggesting that ALL DIRECT WORK (DW) any
day is better than FAANG type of work, provided you get a job, EVEN if
THE MARKET pool IS has [many strong applicants](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC). Is that correct?

2. I think I can focus on one, either on keeping FAANG open or on DW
opportunities. I am 29, Indian by birth and working in Netherlands
right now. The common route to a Big Bucks FAANG job (hence
California), would require 50k$ in costs and a Master's degree to get
into the US. And I probably need to start masters in 1-2 years max, if
I hope to be a FAANG guy in US (Guess, feeling). So prepping on this
from "now" on would be option 1.

	I don't think I will make it to Direct work jobs now based on what I
have seen. I would need to work intensely on it separately as well,
depending on what type of job. This would be option 2 provided I know
what to focus on. Focusing on option 1 and 2 I think will be hard at
the same time I think in this case! Thoughts?

3. Direct work in what? Each seems to need its own separate prep: GR,
   AI safety tech researcher, Management positions

	How do I compare different opportunities? It circles back again I
think to calculations, examples of values.

4. **On the other hand I could try to COPY YOU.**

- Get a Data Science Job in the US (by doing a Master's maybe?) 
- Be REALLY GREAT at something! Have atleast a Triple Master Rank on Kaggle
  (for e.g.,) (2-3 years maybe)
- Be involved with EA community (treasurer, research manager-->No idea
   how to get there though!)
- Build relevant skills for direct work (Not sure what "relevant
  skills" mean)
- And SOMEHOW IT WILL WORK OUT! (possibly because there is a lot of
  overlap between research, Data science?)

>Also, while doing a FAANG job, you could still aim to build relevant
>skills for direct work and then switch. This is what I did (except I
>didn't work in FAANG specifically).

Can you give 2 examples of relevant skills you built for a particular
direct work? And how you built it?

>Also, from what I know, donating $200k/yr while working in FAANG is
>possible for the top ~10% of engineers after ~5 years.

Wow. The Power of ETG at FAANG. 

## Response to Carrick

> New charities will sometimes be started to make more EA org
> positions, and they wouldn't get far if they didn't have people who
> were the right fit for them. Rethink Priorities and Charity
> Entrepreneurship are relatively new (although very
> funding-constrained, and this might be the bottleneck for their
> hiring and the bottleneck for starting new charities like
> them). Charity Entrepreneurship is starting many more EA orgs with
> their incubation program (incubated charities here). Maybe worth
> reaching out to them to see what their applicant pool is like?

Good idea. I will contact them as well to see the talent pool. If they
still need "high-quality people", somehow getting better (gaining) in that
direction seems like a good opportunity.

> I think there are also specific talent bottlenecks, see [1], [2],
> [3]. 

Micheal, I have written an article here:
http://agent18.github.io/is-ea-bottlenecked-2.html in my unfinished
blogspace about [1] and [2]. I really don't find evidence for their
claims of bottlenecks. Or I don't understand what they are trying to
say. For example, GR in GPR is recommended by 80khours in their
[high-impact-careers](https://80000hours.org/articles/high-impact-careers/) post, also in the [surveys](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis), also in the separate
[problem profiles](https://80000hours.org/problem-profiles/global-priorities-research/#what-is-most-needed-to-solve-this-problem) etc... but yet during [open phil's round](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting) on there is
literally 100s of "good resumes" and "many candidates worthy of
positions" but OP could not consume all of them.

Peter Hurford can also be seen talking about the [lack of Talent
constrian](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC) in GR (I think)

> Actually, this last one comes from Animal Advocacy Careers, a
> charity incubated by Charity Entrepreneurship to meet the effective
> animal advocacy talent bottlenecks.

This I really need to look into. Thanks for that.

> Btw, I think you have the wrong link for Carricks.

Thanks. Corrected it. Sorry about that.


**Bottom line**

I don't know how people evaluate which career to choose. Many people
are redirecting me to posts from 80khours. But I find only claims
there. When I ask organizations on value generated replaceability I
don't get any info from them. I think people do a guess at max, falling prey to vague words
like Career Capital or possibly primarily focusing on what they are
good at or I don't know.

Anyways... It seems like a dead end to think that I can actually
evaluate what I should be doing. Your thoughts?

How did you end up choosing to go to DarwinAI? Why not something else
like GR in GPR or FAAANG?

## Reply to MSJ

>I'm currently trying to transition to effective animal advocacy
>research, reading more research, offering to review research before
>publication, applying to internships and positions at the orgs, and
>studying more economics/stats, one of the bottlenecks discussed here,

Your options sounds solid. I guess your 28 and can thus still get into
relatively different quantitative Finance.

But, how did you decide that it is best for you to dedicate your time
to AAR? You could be working at GiveWell/Open Phil as a GR, or in
OpenAI/MIRI in AI safety research (especially with your CS and Math
background), you could also be working in ETG at the FAANG. Also
80khours no where seems to suggest that AAR of all the things are
"high-impact-careers" nor does the EA survey say anything about it. In
fact the survey talks about GR and AI safety.

>I feel that EA orgs have been a bit weak on causal inference (from
>observational data), which falls under econometrics/stats.

So you hope to apply causal inference in AAR?

Lastly I want to thank you from the heart for taking your time and effot to
respond to me. Appreciate it brother.

## replay to arun

Thanks for the advice and detailed corrections in the previous mail. I will make changes this weekend and see If I need to run it by you again.w
Regarding the podcast, I started to listen to it yesterday and it seems like it is mainly about the article:key ideas.
This post seems to be largely recycled from the August 2018 article on high-impact-careers. For example, the Career paths suggested (including the text) is hasn't changed verbatim: key-ideasand old-article. Another example is the priority paths: key ideas and old-article.

## Story so far

**EA is not TC**

We know this from my TC article. Atleast GR and I would go out on a
limb and say they are not TC at all.

This is good, we know now that our value wont be as high. The
difference between 244k and 2.4m as in Milan Griffes article.

Now that I know this about TC, what does it mean for me? Should I
forget working at an EA org?

**Value, Replaceability**

We often hear that in most cases it is better to work in an EAO rather
than work in ETG. Hmmm, how. Is there one example where that is true?
I don't know. It looks like Milan Griffes is the only example that
talks about this. No one else seems to do this to come to a
conclusion.

Why am I panicking so much?

If EA is not TC and the replaceability of you is easy then it is as
good as you wanking. 

But of course depends of if everyone gets displaced. But currently the
pool of candidates is so high that we are unsure or favoring towards
many people being quite replaceable. 

  * [ ] so displacement chain, replaceability, spillover effects and value
included you can make a comparison. You can make an estimation of what
you should be doing. 

But no one seems to have done it. I have very little info and based on
the info I have, I think that it is very replaceable. Peter said
people whom they didn't hire were exactly the same. Jon said 5%. By
the looks of it, AGB discussion and  it looks like people who don't
get a job are going to end up at some ETG job. The last I saw unless
you are ETGing in FAAANG you are not going to drop 50-100k per
year. That's going to be hard. 

  * [ ] Continue reaching out to people how they came to make thier
        decision
		
But the few examples I have that is all I am going to look at to
understand the value a person. 
		
**Most people make decision based on being parrots**

- Peter said I needed to keep FAANG open and try for a job, without
  providing any evidence for it. And most of them don't seem to think
  that they need to make such a calcualtion (e.g., MSj and other
  people in FB). 
  
- They seem to be good at something and pursue that  thats it and when
  they hear from AAC that they need someone they decide to go there. 
  
- No one seemse to have made such a calculation.


**What should I do**

1. I could copy others

If I copy PETER, then I start with getting better at something and
move further. 

2. I could do calculations

I am afraid I will get no where. 

3. One example check claims...

There si still no way I am going to be able to check out value. 


**Counter arguments**

- the replaceability, lack of jobs is only now (why will it reduce?)

- It's only increasing. the movement is growing strong. 200 to 2000
  people for CE (insanity). 
  
**I wont get a job now as is**

I have seen the type of people being rejected. EA applicant, some
marketting guy and some other examples in that same webiste. 

It is super competitive. why would I try to get in?

**I wont get a job after 6 months of prep?**

I don't know about this. but it takes a lot of time to apply and go to
interviews and get rejected. 

**Even with 0 replaceability, this could be your chance to grow in the
industry**

?


**Taking a job now vs doing some thing else?**

**DS and DS in EA**

### What gets you in?

**Being GREAT at something gets you in**

William McAskil  PhD DPhil in oxford --> 80khours CEA founding

Varsha Venugopal UIUC + 15 years experience --> CE

Peter Hurford literally is awesome kaggle level master etc... and he
pivoted by getting skills into the field. 

Jon Behar, top IB firms and then moved to TLYCS in research

dAVID ROODMAN

Phil Tetlock

Can you be great at anything though?

**Region**

Most people are from Axford or US (look at CE hiring round).


### Different options... 

If it does happen that EA orgs are providing more impact, and more
opportunities

**Management people have high impact** (atleast according to 2015 givewell)
and every other payment scheme of companies. 

I know being a GR I will not have much impact, but what if I grew to
be a Management guy? I think that is kind of thing I should work
towards. Hopefully as seen in CE it is not truly replaceable.

This is gonna be hard, there are not going to be fallback options.

Broadly I see two options,,, app for faang, donate be really good at
such a job and then try to get into EA org in what ever capacity,
mostly DS or SwE or Management. 

The other option being work your ass off towards an EAO position from
now on. 

The third option would be that I try for one year and realize I wont
get now and then try for faang.

The fourth option is that I would try to get into faaang without a
masters in DS (the probability of that happening am I right?)

<!-- Some thing that I could separately research --> I don't know one
case where someone has gone to the US from NL without a masters degree
directly. This is really important. (So o this first). and further
maybe through ASML!

Is my clock running out to do a masters in DS? 
<!-- Something that I need to research separately. How long do I have -->
<!-- -->

Is it possible to get into EA within 1 year? In any aspect and then
climb the ladder from there?
<!-- something to research -->

Or should I spend my time wisely on becoming great first as getting
great while at the job might be hard (due to little time to do other
things like improve way beyond other people). 
<!-- Is it true I can't get great while at a job (Warren Buffet? FTW) -->



