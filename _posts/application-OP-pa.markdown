**Briefly, what's your current plan for making lives happier? *
We do not expect you to have a definite answer to this question;
please describe how you are thinking about this problem.**

Get better at "critical thinking", "Rationality", statistics, writing,
and research (using Deliberate practice)

Break into EA orgs in the coming years with ETG Data Science as backup.

Work in or start an Aspiring EA org in GH&P.


---

**Why do you think you are a good fit for this role? *
Please list your key points.**

- I have 2 years of research experience (albeit in another field)

- EA is the purpose of my life. It is very important to me to have
  maximum counterfactual impact. It is why I spend 20-30 hrs every
  week in addition to my day job on EA skills related activities.
  
- I think I am good at communication and my job involves me regularly
  communicating with stake holders.
  
- I am a quick learner. At work I am able to pick up new and different
  tasks quickly and I thrive in such situations.

- I like seeking challenging assignments. and I thrive in such
  situations.


  

---

**Which giving-opportunity do you currently think is highest impact and why? *
No need for more than ~5 sentences.**

Giving to GiveWell recommended charities in GH&P and MIRI in
Longtermism. I give 10% in total to both orgs.

GiveWell recommended charities, because 40 people are working on it to
produce the "best" research. Also GiveWell charities seem to be able
to absorb a lot more money. For example AMF can receive 100m$ more
than it is projected to receive. I don't want to try to second guess
them now (when I am working on other things).

MIRI, because they seem to be to doing fundamental research in AI
which is very important. I respect Eliezer as a rationalist, too
much. Following that they met 50% of their of 2019 fundraiser, which
is really sad as they would really like to grow.

---

**Say it costs $50 to provide 1 course of Cognitive Behavioural
Therapy (CBT) to someone with severe depression in a low-resource
setting. Please estimate the cost-effectiveness of this
intervention. We suggest you use $/DALY or $/"wellbeing-adjusted
life-year". * We're most interested in how you got to your answer, so
show your reasoning. Please don't google anything or spend longer than
10 minutes on this question.**

DALY = Years of life lost due to disability (YD) + Years of life lost
due to death (YLL)

Assuming disability weights (w=0.5) larger than that associated with a
blind person (w=0.2) .

Assuming 5 CBT Therapy courses reduces YLL and YD by half.

Assuming avg life expectancy in low-resource setting is 70y.

Assuming avg. life expectancy of "severe depression" in a low-resource
setting is 50y.

Assuming the avg. age of life lived to whom this course is given to be
30.

DALYs without CBT = 0.5x50y + (70-50)y = 45y

DALYs with CBT = 0.5x30y + 0.25x(60-30)y + (70-60)y = 32.5y

CE=DALY's/cost = (DALYs with 5 CBT-DALYs without CBT)/50$/5 =
12.5/50/5 = 0.05 DALYs per $. For 1$ invested you get 18 days of life
in return.

## Open Phil Program Assistant question

### Why are you interested in the PA role?

- I am interested in the Program Assistant role as it offers a break
into EA. I believe working in EA is a very high impact opportunity as
opposed to earning to give (more info [here](http://agent18.github.io/career-update.html)).

- Being in regular engagements with people like Luke and their work,
would greatly increase the **pressure** I feel to make myself
"better". This is similar to what Paul Graham suggests about
["absorbing values of the people you are around"](http://www.paulgraham.com/cities.html)".

- I hope to get a detailed insights (by "shadowing Luke") on what
**skills** make a great EA researcher. I hope to use this knowledge to
better myself through Deliberate Practice and one day become one such
researcher.

- I think it is extremely beneficial to get exposed to AI policy world,
people from Open Philanthropy and forecasting activities in EA
organizations.

### What are your current career goals, and how does the Program
Assistant role fit with them? *

**My goal** 

- I would like to work for a top EA organization as a researcher in
  the next 5 years. I think this job would allow me to get started in
  that direction. In addition, working with the likes of Luke is bound
  to persuade me to absorb his values, and feel more pressure to get
  better.

- I would like to identify and learn the skills needed to become a
  great EA researcher through Deliberate practice. With "shadowing
  Luke" I think I can gain a lot of insight into what makes a great
  researcher.
  
- I would like to learn about other roles in EA. With exposure to
  other team members from Open Philanthropy I think I will also get
  some insight into the different roles.

  
  
### Is there anything else you want to share about why you might be a
good fit for this role?  

- I have 2 years of research experience (albeit in another field).

- EA is the purpose of my life. It is most important to me to have
  maximum counterfactual impact. It is why I spend 20-30 hrs every
  week in addition to my day job on EA skills related activities.
  
- I think I am good at communication and my current job involves me regularly
  communicating with stake holders.
  
- I am a quick learner. At work I am able to pick up new and different
  tasks quickly and I thrive in new and previously unknown situations.

- When things come to review to me, my boss often feels that it is
  very thorough. In theory it is the designers responsibility to not
  make mistakes. But as a reviewer I feel quite responsible to make
  sure the designer doesn't make mistakes (unlike my peers at work).

### Anything else you'd like us to know (including comments or clarifications on any of the above)? 

If there is something I don't know, then I am going to tell you
so. But I bet you I know how to find the answer and and I will find
the answer.
