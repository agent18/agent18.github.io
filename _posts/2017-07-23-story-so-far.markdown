---
layout: post
comments: true
title:  "  The story so far "
date:    23-07-2017 19:39
categories:  drafts
permalink: /:title.html

---

#### **Conflicting views**

Everytime I watch a PETA video or a video from Aleppo about the disastrous state the world is in, especially and most likely only ones where people are getting injured, such that the emotional quotient is high for me, I cry. I weep like a bitch. This is approximately 0.0000001% of my time in a day when I happen to, by chance come across a video with such characteristics. But everytime it happens, it bites me to bits, and lasts only for a few seconds after. After that, I am mostly just working, getting paid for that work. I come back home from work, wonder what I am doing in life, while I watch other people hanging out with women and friends, while I just go home and not be a part of such "Cool" activities. I feel sad :(.

On other days, there is gym; Man! what a place to be. There is sports; Man! this is life etc...

Another day, you watch some [not-so-random guy come on the tube][martin] talk about [happiology][martin_ted]. He says most  activities we do are pleasurable, only activities that give you meaning and activities that focus on your doing something bigger than you will get you lasting happiness. Things like say, being in the "service of GOD", or being in the servitude of people (BATMAN, Gandhi), or the like. You mull this over, maybe this is what you want to do and then what happens? Back to the fucking grind.

Another day, you see a video by [Peter singer][peter_ted] and then weep your fucking balls off, shocked at the extent to which people are willing to go to save people they have no idea about and you share that video with friends. "And then?", you ask? Well, Back to the fucking grind.

So can we come to a consensus that it is really unclear **what I want to do**. It seems like I want to do this, that and many other things. But somehow I end up doing the same thing over and over again. I cry, don't take action, just sit around and wonder whats the use of all this?

Should I maybe do something about it?

Get to the bottom of it maybe?

Well!

---

#### **Heuristics connecting the value system to "reality"**

When designing machines, we use rules of thumb. This is primarily to increase speed at which designs are done, without loosing too much cost. For example, if we have a thread, the mating surface will automatically have 0.5mm diameter higher hole than the thread diameter. As designers we don't need to every time, spend resources on deciding what type of mating-hole diameter we should use. By doing this, there is literally no increase in costs at all of the final product and we just save a lot of man hrs. Similarly, within our body, we have such rules of thumb (design rules); 'Sugar Urge' and 'Social proof' are some of them.

We have a true value system, and a set of Heuristics, that help us compute the reality cheaply [[Citation needed][no_link]]. The brain can be imagined as a computer with a ram and storage. Given an infinite ram (computational capability) within an infinitely large storage, it should be  possible to compute what will happen at a given moment in the future in this world, based upon physics of the universe and an initial condition. But we don't have such infinite ram to make those costly computations. In an attempt to bypass such complex computations, we have some Heuristics.

Sugary foods such as apples, oranges and other fruits are rich in vitamins. Instead of making calculations into the future regarding availability of fruits, the evolution just decided to keep a very high threshold on sugary products, as there was [no way of overeating it in the bygone days][sugar]. The design rules were made in the stone age and haven't been updated to be relevant in the recent times [[Citation needed][no_link]]. If we strictly listen to our urge and eat a lot donuts as a result we are sure to have [problems][sugar]. 

Another example of heuristic is social proof.

>Social proof, also known as informational social influence, is a psychological phenomenon where people assume the actions of others in an attempt to reflect correct behavior for a given situation. This effect is prominent in ambiguous social situations where people are unable to determine the appropriate mode of behavior, and is driven by the assumption that surrounding people possess more knowledge about the situation.    
-[Wikipedia][wiki_social]

If you look at the festival of Deewali in India, it feels great to participate in bursting crackers, only when everyone else is bursting crackers, not a month earlier or later for example. In a football stadium it feels great to chant stuff not just by yourself, but when others several others do it, and you do it along with them.

#### **Feelings and Wants connection**

We seem to have 'wants'; 'Wants' such as food, girlfriends, social life, etc. We want some of these more than others, based upon the scenario we are part of at a particular moment. Based on the where we are, who we are around, time of day etc., we want some things more than others. Like for example, **NOW** I see there is a sick want to get girlfriends despite the fact that there are other things to do as there are so many millions of people suffering. But **if I am in a situation** where there is one person dying next to me and I need to give up the (only time I actually get laid in my life), well I guess I would. **And I am in such a situation**, many millions of people are dying, but I don't _feel_ within me anything that pushes me to help them. The only mistake of the people dying is that they are not dying next to me. I don't feel. If I don't feel, well I don't do? I only feel like scrolling through facebook and youtube, and having fun in life in association with my Wants-feeling connection. Sorry.

<!-- #### Feelings might be wrong-->

Next take this for example. 

>Other recent research shows similar results. Two Israeli psychologists asked people to contribute to a costly life-saving treatment. They could offer that contribution to a group of eight sick children, or to an individual child selected from the group. The target amount needed to save the child (or children) was the same in both cases. Contributions to individual group members far outweighed the contributions to the entire group.

I couldn't find the source online unfortunately. It appears that the text is up for some interpretation. People had the choice to offer money to an individual child from the selected from the group or to the whole group. Contributions to the individual group, far outweighed the contributions of the entire group.Essentially people wanted to donate to individual people instead of the whole group. 

>The target amount needed to save the child (or children) was the same in both cases.

While asking people to donate, the target amount mentioned in the case of the group and the individual child was the same i.e., both had a target of X$. 

The best thing to do would be for everyone to donate to the group, so that they maximize the contribution and save everyone. This is with the assumption that we want to save as many lives as we can. It appears that people want to save the children from their willingness to give money in the first place. But the individual contributions seemed to be far higher. I can't understand the logic that they would choose just one person and help him tremendously rather than give the same amount of money to the group. ~Another question is "which person you would choose from the group?". If you are about to say, "By looks", God help you!~

But the people ended up donating to an individual rather than a group.

As Eleizer writes in his [blog][ele_intuition], how can it be that 1,312,433,101 happy children are significantly better than 1,312,433,100 happy children, but then it is somewhat worse to have 1,312,433,108 happy children? 

There are probably a couple of hypothesis:
a) that the brain cannot make such calculations and the brain is wrong in computing what it wants
b) there is some deep moral truth underlying the whole calculation and the brain is right
c) [OI][no_link]

This probably seems like a nice time to start questioning if feelings might actually give us reliable and consistent results. When the brain cant understand the difference between 100,000 people and 1,000,000 people when it sees them, when the brain can't understand the difference between 10,000 hairs and 100,000 hairs (Simple test: How many 1000 hairs do you think you have? and then [Google][no_link]), When the brain evolved in a setting where there were far less people in its tribe, could it still be that option b is right? We can't imagine the large numbers or for that matter the difference between 10,000 or 100,000 hairs, other than that it is somehow "much larger". In addition, knowing some of the heuristics that the brain uses, such as the sugar urge, social proof and the like, to compute things cheaply [[citation needed][no_link]], the level and capability of the brain should be clear. 

An explanation for the discussion on number of children being saved, as seen in Eleizer's [blog][ele_intuition] is that one child causes very high emotional arousal than a group of children, unfortunately.
>focusing your attention on a single child creates more emotional arousal than trying to distribute attention around eight children simultaneously. So people are willing to pay more to help one child than to help eight.

<!-- ~Given all the above, it's hard to believe every feeling we have might actually reflect what we truly want. The way brain can't do complex computations. In this day and age we make all sorts of calculations with large numbers, as we have the tools, such as arithmetic, in which we have been trained for a couple of years. Without such training, I suspect its possible to make the trade-offs that we would typically want to make. Why don't we trust our honorary feelings for things like that. It can easily be proven wrong when we jump into calculations that can only be given correct answers by arithmetic. You go to a shop today and you can't calculate using feelings. The point being that we cannot obviously use feelings for calculations that we might do day to day.~ -->

<!--
I am tempted to say that it makes sense. I am tempted to say that we probably want to donate to a cause rather than what is in the cause. I want to say that we probably want to donate to only one thing and pretty much the same amount. This could be a hypothesis. Looking at it from an evolutionary stand point and considering the tribal stone age mentality, it appears that the analogous situation to this is saving 1 person from the tribe and saving 8 people from the tribe. Can't imagine why someone would help the only the individual as much and not help the group so much. 

And feelings don't really tell us what we want in some cases. Say your either your father or your mother is going die and you had to choose,
But Why is there such a value system?-->

We are currently trying to understand if our feelings are amazing w.r.t telling us what we want. But we see some discrepancy, and we start wondering if feelings are actually helping us get what we want? To add to the fuel...

In [Circular Altruism][ele_circular] Eleizer Yudkowsky talks about how we can easily trick our brain to choose an answer, based on the way the question is framed or based on the way we look at a situation.

Lets say there is a war happening that is killing people. and you only have enough resources to implement one of the following:
	
	1) Save 400 people with 100% certainty
	2) Save 500 people with 90% certainty

Most people chose 1.

Lets say we now have the following:

	1) 100 people die, with certainty
	2) 90% chance no one dies, 10% chance 500 people die

Most people chose 2. 

There is no difference between the two sets of questionnaires. Both say the same thing but in a different way.  In one case we want option 1, and in the other option 2.

So what exactly do we want again? Circular preferences? How do we decide what we actually want, when we seem to not know what we want?

How do we know what we want? Is it possible to know what we want?

#### Feelings as only direction pointers

Eleizer in his post on [The "Intuitions" Behind "Utilitarianism"][ele_intuition] says,

>I see the project of morality as a project of renormalizing intuition.  We have intuitions about things that seem desirable or undesirable, intuitions about actions that are right or wrong, intuitions about how to resolve conflicting intuitions, intuitions about how to systematize specific intuitions into general principles.

>Delete all the intuitions, and you aren't left with an ideal philosopher of perfect emptiness, you're left with a rock.

>Keep all your specific intuitions and refuse to build upon the reflective ones, and you aren't left with an ideal philosopher of perfect spontaneity and genuineness, you're left with a grunting caveperson running in circles, due to cyclical preferences and similar inconsistencies.

>"Intuition", as a term of art, is not a curse word when it comes to morality - there is nothing else to argue from.  Even modus ponens is an "intuition" in this sense - it's just that modus ponens still seems like a good idea after being formalized, reflected on, extrapolated out to see if it has sensible consequences, etcetera.

You see that your feelings are untrustable as they are giving you circular preferences in many places, in some places they are outright wrong (sugar urge). But then we also see that feelings is the only thing we have. Apparently even Modus ponens follows from feelings/intuition, 

>the rule of logic which states that if a conditional statement (‘if p then q ’) is accepted, and the antecedent ( p ) holds, then the consequent ( q ) may be inferred.

At this point yes I did start clubbing the definitions of feelings and intuition together. Everything seems to be ultimately a feeling or rather, something that makes me feel like something is right or wrong, whether I should be doing something or not.

Often times I have thought of questioning my current thought process, but I refrained from it. I can't start at questioning my very thought process right now. Then I am lost max! Where will I even begin if you question the very tool that I use to think. It's one thing that I have been avoiding all along; The only tool I would continue to use and question later. Maybe this is it. You have to use this faulty system, to know more about the faulty system, to repair the faulty system or to make corrections for it. This is how far you can get with this faulty system. You accept that you have a faulty system. As Eleizer says, "Delete all the intuitions and you are not left with an ideal philosopher of perfect emptiness, but with a rock". When you remove all your feelings, you don't become an ideal philosopher of perfect emptiness, you just become a rock. When you are  empty as an ideal philosopher and reject every feeling you have, (which seems like the direction to go), where will you go, what will you do? you are empty bro! you are a rock. I seem to be agreeing with this line of thought, for lack of anything better than this.

What are my other options anyway? I could probably let someone very wise to let me know what I should do. But whether I do it or not would still be in consultation with my current system ([solution inside my head][tj_solution]). For example, if the wise man told you to chop someones head off, you would not do it right! And how do you determine he is wise in the first place! Let me give you a hint? ;) ([solution inside my head][tj_solution])

But we do know of people who are terrorists, who are sufficiently large in number to cause so much havoc in the name of something they think is right! How is it that they can chop someones head off with ease, but not me. Why is it part of their solution in their head [OI][].

#### But what do you do anyway?
As Eleizer says in the [same post][ele_intuition], 

>But what do you do anyway?

Eleizer further elaborates and I seem to agree with him on this part that, if you stick to purely intuition/feeling, your view will be fucked because of all the things we saw earlier such as, misrepresentation of wants, circular logic, heuristics not capable of handling the complexities of current society, etc.,

But if you don't use feelings, then you are just as empty and worthless as a rock.

But then maybe there is a ~middle ground~, a third option perhaps, wherein you reflect on intuitions, extrapolate to see if it makes "sensible consequences" etc...

Eliezer in his post on [Why truth][ele_truth]

>The obvious choice isn’t always the best choice, but sometimes, by golly, it is. I don’t stop looking as soon I find an obvious answer, but if I go on looking, and the obvious-seeming answer still seems obvious, I don’t feel guilty about keeping it. Oh, sure, everyone thinks two plus two is four, everyone says two plus two is four, and in the mere mundane drudgery of everyday life everyone behaves as if two plus two is four, but what does two plus two really, ultimately equal? As near as I can figure, four.

As far as I can figure out 2+2 gives 4. The idea being if you have 2 un-reacting stones, side by side along with 2 more of them, in total you should have 4, and not 3 for example. That is what 2+2 means. Its a facilitator that helps us in daily life to know in advance what we will have in the end. Its a rule of the universe!

If you remove the feelings, there is no you. You just become a rock. If you fully use only your intuitions you are no different from a caveman. You'll be stuck with circular preferences.

But how do you know what feelings are right?

How do you know modus ponens is right?
>"Intuition", as a term of art, is not a curse word when it comes to morality - there is nothing else to argue from.  Even modus ponens is an "intuition" in this sense - it's just that modus ponens still seems like a good idea after being formalized, reflected on, extrapolated out to see if it has sensible consequences, etcetera.

> The snow is white if and only if the snow is white

How do you know what feelings are right? 
We take every intuition we have, reflect upon it, extrapolate to see if it has sensible consequences.

P.S

I've read Eleizer's post on [intuition][ele_intutions] many times but suddenly when I was writing is when it slowly started to make sense. So Shut up and write!

[martin]:https://en.wikipedia.org/wiki/Martin_Seligman
[martin_ted]:https://www.youtube.com/watch?v=9FBxfd7DL3E
[ele_intutions]:http://lesswrong.com/lw/n9/the_intuitions_behind_utilitarianism/):
[ele_truth]:http://yudkowsky.net/rational/the-simple-truth/
[ele_circular]:http://lesswrong.com/lw/n3/circular_altruism/
[tj_solution]:/solution-inside-my-head.html
[peter_ted]:https://www.youtube.com/watch?v=Diuv3XZQXyc
[sugar]:http://www.sheknows.com/health-and-wellness/articles/1025709/your-body-on-sugar-cravings
[wiki_social]:https://en.wikipedia.org/wiki/Social_proof
[no_link]:/story-so-far.html
