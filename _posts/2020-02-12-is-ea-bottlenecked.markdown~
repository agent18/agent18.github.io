---
layout: post
comments: true
title:  "EA is not Talent constrained or bottlenecked" 
date:    12-02-2020 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: true
---
## Story

EA is TC according to some people.. 80khours, surveys etc... and form
view similar to EA applicant

But there is overwhelming evidence it is not be it AI or other poverty
scenes too. Atleast for operations, GR, AI I am unsure there is any TC
as there is atleast no capacity or abundance of people for 2 posts.

My qualms are that 80khours did a poor job with it.  They think
english is the best way to communitcate not numbers. They did this
with CC being focus now its TC. My biggest fear is listening more to
their english blindly, without being able to test their claims. And
that is the danger of the situation. Most people (atleast me and EA
applicant) seem to heavily rely on theirr "research", but am not sure
it is that good or atleast the way they talk. Look at how they loosely
use words like MANY (without numbers or actual examples of what it is
they mean) in the 2018 survey. and TC and CC. Where do they get their
info from? More explanation is needed. maybe they trying to generalze
it so please stop that... your OK is not my OK. (everything with
exmaples)

Lack of accountability to reply to people who have spent years wasting
based on their response.

80ks loose words such as CC. Everything is CC... If I try to estimate
what is good for CC, I have no idea how. IS a DS job good for CC ? for
a job ultimately at GiveWell. If you unsure what to do do MC, gain CC
... what sort of advice is this? becuase they later wrote a diclaimer
that MC should not be pursued. The only example I know of or which I
have example for 

Is there still a point of going all up and beyond and marginally
beating someone?

Someone will find another job so it makes sense to work in EA... what
a load of bullshit that is...

My worries are further exploding because they think the proxy for their
success is VIEWS. OMG! Are you serious BT? are these the kind of
people you trust to change the world! Views gOoh! When you don't care
about those people who view it and all you care about is the super
super elite. Fuck off. 

Mistake with valuing previous hires rather than new hires (getting
extremely inflated answers for their value).

## Introduction
<!-- Need to write this out still -->

I want to cover the following:

- Talent constrain (bottleneck, funding constrain etc..)

- Easiness to get a job in EA (how I compare to these people)

- What is the value you add working at an EAO (how to consider replaceability)

- EA is definitely better than ETG in most cases (Stretch)


## Definitions

80khours in [Why you should work on Talent gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps) Nov 2015, says,

>For some causes, additional money can buy substantial progress. In
>others, the key bottleneck is finding people with a specific skill
>set. This second set of causes are more “talent constrained” than
>“funding constrained”; we say they have a “talent gap”.

So when key bottleneck is finding people with specific skill, then it
is TC. Ok cool! In the same article there is a "slightly more precise
definition":

> A cause is constrained by a type of talent, X, if adding a (paid)
> worker with talent X to the cause would create much more progress
> than adding funding equal to that person’s salary.

This is a bit confusing for me at first, but becomes clear once I take
the example of AMF and FHI in the causes of global health and so for
AI strategy FHI adding 200000 dollars is pointless as FHI recently got
a grant of 10 million and Open Phil seems to have closed the funding
gap by adding another mill. Instead if you added a person, it seems
like it would add more progress. [^14].

<!--80khours in June 2017, in ["Working at
EAOs"](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable),
>Another factor is that hiring takes up a lot of senior staff time –
>you need to source candidates, train them, test them out, and many
>won’t work out. Moreover, a bad hire could easily harm morale, take
>up a lot of time, or damage the reputation of the organisation, so
>there is a lot of risk. This means that it takes a long time to
>convert funding into good new staff, creating a talent
>bottleneck. But if a potential hire takes a short amount of time to
>evaluate, train and manage, they often wouldn’t get replaced for a
>long time.-->

However in their [TC re-description as of Nov 2018](https://80000hours.org/2018/11/clarifying-talent-gaps/), they say 

> Another way to see the problem is that a typical job application
> process only accepts 1-10% of applicants. This means that even if an
> organisation is 3-times keener to hire than average, its acceptance
> rate would still only be 3-30%, and most applicants will still not
> get the job.

(rolling my eyes! OK!).Then that fucking thing is not TC. There is no
skill bottleneck. My problem is not with 3-30% (there could always be
fluff applicants). My problem is with that the way it appears as
though there are many jobs and its hard to fill them, because the
right people don't exist, whereas in reality it is completely
different. If you look at OP's hiring round, you get the picture. They
had 50 candidates of good stature that they had to choose from and
several of whom they would consider hiring in the future. So I am not
really sure how this is contrain in skill. Anyways fuck 80khours and
their definitions.

[Concepts.EffectiveAltruism](https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/)defines TC like how we would imagine,

> Organization A: Has annual funding of $5m, so can fund more staff,
> and has been actively hiring for a year, but has been unable to find
> anyone suitable... Organization A is more talent constrained than
> funding constrained...

Ok, so they have the money but aren't able to find anyone
suitable. Great! Clear. How about fucking that?


**To me**

Instead of trying to focus on how 80khours sucks and to point that
out, it is better to focus on my current understanding and how I
update my understanding based on the evidence. 

There seems to be more than one definition:

> Another factor is that hiring takes up a lot of senior staff time –
> you need to source candidates, train them, test them out, and many
> won’t work out. Moreover, a bad hire could easily harm morale, take
> up a lot of time, or damage the reputation of the organisation, so
> there is a lot of risk. This means that it takes a long time to
> convert funding into good new staff, creating a talent
> bottleneck. But if a potential hire takes a short amount of time to
> evaluate, train and manage, they often wouldn’t get replaced for a
> long time. --- [Working at EAO](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable) June 2017. 

Confusing fuckers.


## EA is talent constrained (Survey says)

With this essay I try to focus on TC and not really FC. I couldn't
care less if an org was FC. As that is not the question I am trying to
answer. The alternative of funding abundance needn't be TC, it could
be focusing on other groups that need money for example.

**Evidence for Talent Constrained**

EA has been and is talent constrained according to surveys made by
80khours and CEA since 2017. Several organizations seem to think so in
these surveys by the EA community: [2017 survey](https://80000hours.org/2017/11/talent-gaps-survey-2017/), [2018 survey](https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions),
[2019 survey](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis). In all the surveys EA's on average seem to be more
Talent Constrained than Funding. For example in 2019 EAOs reported
feeling more (3/5) Talent constrained and less (1/5) Funding
constrained[^11]. More details are added to the footnote about the
surveys [^1].

Since 2015 already, 80khours seems to be preaching that we should
focus on providing talent to the EAO's rather than money. ["Why you
should focus on talent gaps and not funding gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/). They seem to be
making the case that there are many industries that are amply funded
and Talent is often quoted as the bottleneck. For example, they look
at things like International Development and quote that a "good"
charity easily will have access to 10s of millions of dollars by
meeting GiveWell criteria. Similarly they make the case for AI Safety
where there is plenty of money via FHI and Open Phil
(11m<span>$</span> back then) and that there are people who are ready
to donate even more, but think there isn't enough "talent pool" (back
in 2015)[^12].

In June 2017, in ["Working at EAO](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/)", they quote the survey to
inform people, that EAOs are TC.

In June 2017, a podcast is titled ["The world desperately needs AI
strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/)", where Miles Brundage talks to Rob about AI
strategists. Here Miles is seen making claims that this is a growth
area and that jobs are currently "few" like AI safety will grow in a
couple of years. Whether the adjective desperate was warrented or not
is a separate debate. Rob however is also seen 

As late as August 2018, they can be seen saying that we need people to
work on AI safety, Biorisk, EA, GPR, Nuclear security and
institutional decision making.

> Why did we choose these categories (Research, Govt policy, eff non
> profits, ETG)[^13]?  Why do we especially highlight
> research, policy and non-profit jobs; deprioritize earning to give;
> and omit advocacy and entrepreneurship?
>
> In brief, we think our list of top problems (AI safety, biorisk, EA,
> GPR, nuclear security, institutional decision-making) are mainly
> constrained by research insights, either those that directly solve the
> issue or insights about policy solutions. --- [High Impact Careers
> ](https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories) Aug 2018


In Nov 2019, 80khours talks about the "confusions" we create when we
talk about "talent gaps".

> Rather than funding vs. talent gaps, we propose that people aim to
> identify specific bottlenecks facing the field and the skills needed
> to resolve them. A ‘bottleneck’ is the resource that a field most
> needs in order to make progress.

Ok, what if a cause is bottlenecked by a specific skill? Let me
think... ah Talent constrained. It appears that the word is not
confusing as per their initial definition. But somehow somewhere in
the way, wait am not sure what happened. Let's read that article
again. 

**What I think Talent Constrained means**

EAOs are talent constrained when there are not enough capable people
to work at that EAO. There is a lot of demand and the supply is really
low was my thought process.

**80khours defines it:**

Lack of people with specific skill set. 

I am going to try and argue here that for majority of the people EA is
not constrained by talent. 

First we need to be more clear than 80khours, so we talk about the
lack of talent constrain, in 80khours suggested top career paths.

- AI strategy and Policy research
- AI safety technical research
- Grant maker focused on top areas
- Work in effective Altruism orgs
- Global priorities researcher
- Bio-risk strategy and policy
- China Specialists
- Earning to give in quant trading
- Decision making psychology research and roles

---

## EA seem to be Talent Constrained (EAorgs say)

Rethink Charity, Open Phil Gen Researcher, TLYCS, EAF's hiring round

I don't have a whole lot of evidence for every single of the career
paths. But just broadly in general looking at "Working at EAO" or
"Global Priorities Research", there seems to be evidence of the lack
of highly skilled personnel for the job. Especially in the cases of
Operations people, Senior hires in places like Rethink Charity and
also Generalist researchers. 

Open Philanthropy (OP) hired 5 Generalist Research Analysts (GRs) in
2018 and wrote about their experience and provide some key
numbers. Apparently, there were hundreds of applicants with strong
resumes and seemed quite aligned with OP's mission. 58 of them
performed best in their work-tests and 17 of them were offered 3-month
trials from which 5 were selected. Further more OP acknowledges that
it doesn't have the capability to deploy such a pool of available
talent. 

I don't know why GR is one of the most talked about (top 3) in all the
surveys done by 80khours. Maybe it is because it is the demand but
there is plenty of supply as seen above. Global priorities research
seems to be a joke, considering the lack of capability to absorb
talent. This is also a priority paths. I can hear 80k's defense: "but
we will need them in the coming years", really? you are going to
absorb 50 people and who knows how many more are going to be available
especially in the coming years? All this considering the "startups
should hire slow philosophy". Maybe there are plenty of these orgs and
everyone gets a job? but unlikely.

EAF (Germany), similar to OP, gave a [detailed account into their
hiring round](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) for Operations and Research Analyst. Without any
further research I assume that the RA position is similar to that of
GiveWell's. Within a period of 2 weeks they got 66 applicants. 66
applicants --> 17 work tests --> 10 interviews --> 4 trial week --> 2
offers. They didn't want to have a larger period for apping due to
organizational constraints. In the end they appear to have hired 4% of
their initial applicants. Considering that this is Germany (not really
an EA hub), it appears that they atleast had 17 potential candidates
whom they wanted to test. It still appears that there are a lot of
talented people out there for roles like these despite being in a
non-EA hub.

[Peter Hurford](https://www.linkedin.com/in/peterhurford8/), has various titles such as Vice Chairman of the
Board, President of Board and Co-executive Director of Charity
Science, Rethink Charity and Rethink Priorities. He seems to have no
problem finding talented people to work for him. In fact he says he
finds it hard to turn down strong applicants and still has to do it
anyway in 2019.

> I’ve certainly had no problem finding junior staff for Rethink
> Priorities, Rethink Charity, or Charity Science (Note: Rethink
> Priorities is part of Rethink Charity but both are entirely separate
> from Charity Science)… and so far we’ve been lucky enough to have
> enough strong senior staff applications that we’re still finding
> ourselves turning down really strong applicants we would otherwise
> really love to hire.---[Peter Hurford says in the 2019 survey](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC)

Peter Expresses his concern on the bemoaning of ETG. As evidence to
his claim I believe unless I can be a quants trader I am a loser and
that it is better to focus on working at an EAO as a result. And now
even this is turning out to be hard as fuck. And the one org we turn
to for career advice sucks. 

The Life You Can Save's Jon Behar also agrees with Peter that this
whole "talent bottleneck", atleast with the people they seem to be the
case and that money is more in need for them. And that they are more
strapped for Funding.

Firstly, it took me a while, but now I understand what is AI
research. It splits to three or four things. (Technical) AI safety
research (one done by ML engineers in OpenAI, MIRI etc...), AI
strategy and policy (seems to be in the same bracket both strategy and
policy) and then we have AI policy practice/implementation. This is
roughly found in 80khours [Policy guide](https://80000hours.org/articles/ai-policy-guide/#ai-policy-practitioner) and [Technical safety
research](https://80000hours.org/career-reviews/artificial-intelligence-risk-research/) and this post by [Carrick Flynn](https://www.linkedin.com/in/carrickflynn/). Ok! now for the lack
of or presence of AI safety and policy jobs. Miles Brundage in June
2017 previously from FHI and now in OpenAI (Policy) says in this
podcast--"[The world desperately needs AI strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/#transcript)"--seems to
imply that the policy research space is growing and there will be more
jobs. [Carrick Flynn](https://www.linkedin.com/in/carrickflynn/) in Sep 2017, who managed hiring for FHI in
Strategy seems to suggest the desperate need for People but not
now. Now there are very few positions due to the problems with
"disentanglement". That is the bottleneck apparently and suggests to
develop skill (somehow) and wait for the opportunities. But it goes on
to suggest that AI Strategy and Policy space is also not "Talent
Constrained". Will it be in the future? Yes there are claims and
possibly so. How long into the future I don't know. No one knows. It's
Feb 2020 now, and most of the articles on 80khours in the [strategy
space are still from 2017](https://80000hours.org/topic/priority-paths/ai-policy/), So I don't know if things changed and
if there has been that success with disentanglement. There is no sign
regarding people needing to work in the policy space.  

Back in June 2017 already, Miles Brundage was in a podcast with
80000hours titled, "[The world desperately needs AI
strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/#transcript)". In that podcast Miles informs Rob, that getting a
job is pretty competitive and that it is pretty much going to remain
like this. [Carrick Flynn](https://www.linkedin.com/in/carrickflynn/) from FHI who handled recruitment (in
2017), writes [here](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy), about the lack of jobs in AI strategy. There
is one place called the "disentanglement research" and they need
really skilled people at it, but otherwise, he asks people to hang on
until this disentanglement progresses. Such as people from policy
implementation, policy research are on hold. He also lists some broad
areas which are bottlenecked, such as knowledge of Chinese politics,
International law etc... which I am unsure how it is expected to
work. As Carrick flynn points out there are probably not many jobs and
they are going to be super competitive. If I come in once
disentanglement is done it could be fire.

> The AI strategy space is currently bottlenecked by entangled and
> under-defined research questions that are extremely difficult to
> resolve, as well as by a lack of current institutional capacity to
> absorb and utilize new researchers effectively.---[Carrick Flynn
> FHI](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy) June 2017

Although this is not clear in numbers, I get the impression that there
are "very few" jobs and more demand for disentanglement research
mainly. He even said "FHI is hiring but in limited capacity". I don't
have data on how many people applied etc... but there is some data in
general and where availble I look at the evidence. So there seems to
be some serious demand for disentanglement, but I want to take a
stance and say we are further more not TC'ed.

You don't expect Harvard to say they are talent constrained when they
pretty much take in 5% of the total applicants. And the same with
Y-combinator, they have tons of applicants in the order of 10000 and
they accept only 100-150 (1%). There are some places where EA seems to
be genuinely Talent constrained. An example would be: 


So far we have seen AI safety, Rethink serieses, TLYCS and EAF all
seem to be full a people and not having much capacity to take in new
players. Except for one concrete thing of Disentanglement that I have,
it appears for the jobs

Of course this is narrow in its view, but my point is I don't want to
slog my ass off and then find in the end that its too copetitive and
that there are no jobs. If in the end selection if I am just slightly
better than the other person what is the point? I dont know! and if
that guy can't get a job anywhere else. 


> Below are some more specific options that are among the most
> promising paths we know. Many of them are difficult to enter – you
> may need to start by investing in your skills for several years, and
> there may be relatively few positions available. However, if you
> have potential to excel in any of these paths, we encourage you to
> seriously consider it, as it may be one of your highest-impact
> options.---[High Impact Careers April 2019](https://80000hours.org/career-reviews/#our-priority-paths)

So these are not bottleneck options, ok! but why does 80khours want us
to get better and work on it? again! I was thinking maybe focussing on
bottlenecks was the think to do! This is just tooo tooo confusing for me.


## EA is not talent constrained (People says)
	
This is also proxy for will I get a job?

I stumbled upon this post by accident and it was the most popular post
(most upvotes ever) in any post seen in the EA Forum (all
time). OK. When I started getting into it, it started hitting me, my
reality was completely being shaken. Great. And for the first time I
had evidence and not words (80k) about what this god forsaken TC
meant. This sent me into a crazy spiral of evidence which allowed me
to take two steps back and probably impressed in me to test the
80khours claims from now on. Atleast 80khours claims. Those n\*\*\*\*\*
have been fucking with me for far too long. First it was CC, now it is
TC. Anyways taking a shit on 80khours is for another post. 

Many people have applied. Many good intelligent people seem to have
applied and not made it. A lot of effort goes into these
things. Mostly if you ask them, it seems like they will say ah but EA
is TC (The great term coined by 80k). And the distancing of 80khours
from theses feedback or suggestions that 80khours could potentially
offer feedback and shave years of time waste in people is not really
nice. Because they publicise themselves as some for the workld career
feedback giving institution. But they are not. They are all about the
elite. But then market your fucking ass like that. If you don't have
two oscars, this advice is not for you. Up until two years, they
wouldn't even say what they meant by young and old. They love to keep
it vague. 

User [EA applicant](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really), wrote a post on Feb 2019 which garnered the most likes
ever in a post in the EA forum. This atleast suggests that this is an
important topic. He applied to 20 posts and barely got a job after one
year and some 500 hrs of time later. He seems to have gotten a lot of
feedback from other EAs in EAOs that he is "worthy" to be in EAOs. I
so very much agree with his take on what 80khours is saying: 

> “Hey you! You know, all these ideas that you had about making the
> world a better place, like working for Doctors without Borders? They
> probably aren’t that great. The long-term future is what
> matters. And that is not funding constrained, so earning to give is
> kind of off the table as well. But the good news is, we really,
> really need people working on these things. We are so talent
> constraint… (20 applications later) … Yeah, when we said that we
> need people, we meant capable people. Not you. You suck.”

They literally said all of this. But let's not digress. 

So this EA applicant from Germany, has couple of scholarships, has 8
publications, has done many internships in the field of medicine, has
led medical refugee camps managing 50 people and has taken classes for
150 students at a time in University in Mathematics, and was ranked
16th out of 6000 people in Medical school. He applied to 20 positions
in the "long-termism, EA movement building, grant-making type" jobs
and got rejected to most of them (3 of them he didn't pursue the work
trial due to "visa issues"). Apparently he spent around 400-800 hours
in one year for this and is completely dejected that he has got none
of the jobs. He seems to have gone to atleast the 2nd stage in most
interviews. He also claims to know "several" people who went to a
great university like Oxford, were the top 5%, lead local EA chapters,
EA aligned and motivated, and 5 positions later 100%
rejections. "Several people" after this post messaged this applicant
stating that they had similar experiences.

Some may argue 5 is less number of jobs to apply for, but it seems to
be consistent that EA is not really TCed by these kind of talents who
are ready to do research, program management, operations you name
it. In fact there are more people in the comments and in other posts,
who decided based on 80khours possibly, that EAOs are going to be
their life but then it's not really TCed. There are enough "good"
applicants for them to pick up from.

Saying, I need even better talent and saying that is what you meant by
TC, is kinda not right I think. As you can always say that, for every
case, that you want even more output from people. Another student
reporting his fuckery.

> I've recently graduated from one of the top ~10 universities
> worldwide, after investing heavily in EA throughout my
> studies. While a student, EA was the biggest thing in my life. I
> read a lot, and several of my EA peers told me I stood out as
> particularly well-informed about EA topics, especially long-termist
> ones. Eventually I contributed some of my own research too. I also
> invested enormous amounts of time in student EA projects. Many
> people, including ones I thought well-informed about the talent
> landscape, fully expected that I would go work for an 'EA
> organisation'. Naively, I believed it too.
>
> Over the last seven months, I've made over 20 unsuccessful job
> applications (I keep a spreadsheet). This has increased the severity
> of my depression and anxiety. --- Anaonymousthrowaway

I tread carefully as we are mostly dealing with words here, but if
people who were well informed about the talent landscape didn't
predict him right after 20 applications, then is EA still TCed. 

Such investment above seems to favor the elite as pointed out by
Milan Griffes. Only people who the time to spend 500 hrs in a year and
without the stress of job seem to be successful (next section). 

Something that is more brutal out of all this subtexting is taht you
suck if you ETG other than quants trading. You are not worth a call
from 80khours, you suck. as pointed out by this guy:

> So instead I earn-to-give, and am constantly hit with messages (see
> above caveat! messages may not be real!) of “Why are you doing this?
> Nobody’s funding-constrained! Money isn’t real! Only talent
> constraints matter!” while knowing that if I tried to help with
> talent constraints, I would get “Sorry, we have 2,000 applicants per
> position, you’re imposing a huge cost on us by even making us
> evaluate you”.

https://physticuffs.tumblr.com/post/183108805284/slatestarscratchpad-this-post-is-venting-it

Joel Miller on applying to operations in this facebook post:
https://www.facebook.com/groups/473795076132698/permalink/1077231712455695/

etc... etc...

"wow, these people are really impressive, and I find it surprising that
they could not find a job" --- Max Daniel

Reply to max daniel's epistemic status:

But bro, the point is people like X can't contribute. Taht is it. And
we are really unsure as to what in the hell 80khours means considering
there are organizations that clearly express that they don't have
capacity. How can there be TC when there is no space to absorb. And I
don't trust it one bit. I think they are trying to generalize info and
shit goes wrong there and then they dont use examples. They just write
lectures of long notes. OK I need examples for every single claims
that I make. That is not the attitude of 80khours I think.

Sending out personalized invitations...

### Kinda people who get in

Max daniel Aaron Gertler, Luke prog etc... and what their creds are.


## Reflection to my life.

I think am at a cross roads and I very very unsure what I can excel
at. ML seems to be lucrative as atleast I would potentially have a job
even if I am not good enough for a Tech AI safety job.

The problem is the way the bottlenecks haev been framed in 80khours, I
don't really know what to do. I am unsure I am unsure how to proceed. 

Does the world need managers? how do I become one? is it also NOT TC?

Also I want evidence that something is TC or not. I dont' want to
trust words. I want someone to talk in numbers.

Wrap it up.... and prepare to post in EA blogs. and get feedback. how
is one supposed to decide how to work. Don't just tell me based on
personal fit, what ever that advice is...

## points about 80khours with evidence

The sworm career guide that is stuck with English.


## From previous article

**Someone who didn't get there?**

EA applicant aaron gertler Max daniel all from:

https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really?commentId=Aic5bcvLmunfhmnhr

**Is there any bottleneck? (evidence)**

There is no bottleneck at this moment it looks like, in that case
consider going into personal fit types? or potential in the future
types?

EA applicant talks about his 5 friends, Max daniel gets several
rejections, despite thier credentials such as: 

> However, I don’t think I am a very special case. I know several
> people who fulfil all of the following criteria:
>
> - They studied/are studying at postgraduate level at a highly
>   competitive university (like Oxford) or in a highly competitive
>   subject (like medical school)
>
> - They are within the top 5% of their course
>
> - They have impressive extracurricular activities (like leading a
>   local EA chapter, having organised successful big events,
>   peer-reviewed publications while studying, …)
>
> - They are very motivated and EA aligned
>
> - They applied for at least 5 positions in the EA community and got
>   rejected in 100% of the cases.
>
> I think I also fulfil all these criteria. Here is my CV roughly at
> the time when I was doing the applications. It sports such features
> as ranking 16th out of around 6000 German medical students, and 8
> peer-reviewed publications while studying.

> People working at EA organisations, sometimes in senior positions,
> were surprised when they heard I didn't get an offer (from another
> organisation).  But he did get several interviews.

> Regarding me being a bit of an outlier: Yes, I think so as well. I
> personally don't know anyone who applied for quite as many
> positions. I still don’t think I am a *very* special case. I also
> got several private messages in response to this post, of people
> saying they had made similar experiences. --- EA Applicant

> I know at least 2 people who unsuccessfully applied to a large
> number of 'EA jobs'. (I'm aware there are many more.) I feel
> confident that they have several highly impressive relevant skills,
> e.g. because I've seen some of their writing and/or their CVs. I'm
> aware I don't know the full distribution of their relevant skills,
> and that the people who made the hiring decisions are in a much
> better position to make them than I. I'm still left with a
> subjective sense of "wow, these people are really impressive, and I
> find it surprising that they could not find a job".---Max Daniel

> I've recently graduated from one of the top ~10 universities
> worldwide, after investing heavily in EA throughout my
> studies. While a student, EA was the biggest thing in my life. I
> read a lot, and several of my EA peers told me I stood out as
> particularly well-informed about EA topics, especially long-termist
> ones. Eventually I contributed some of my own research too. I also
> invested enormous amounts of time in student EA projects. Many
> people, including ones I thought well-informed about the talent
> landscape, fully expected that I would go work for an 'EA
> organisation'. Naively, I believed it too.
>
> Over the last seven months, I've made over 20 unsuccessful job
> applications (I keep a spreadsheet). This has increased the severity
> of my depression and anxiety.

> --- Anonymousthrowaway

But 80khours continues to argue shit like Talent constrain but where
is the talent constrain mother fucker?

People working here don't seem to have funds to grow, idhula talent
oru keda?

And more of this here:
https://physticuffs.tumblr.com/post/183108805284/slatestarscratchpad-this-post-is-venting-it

> So instead I earn-to-give, and am constantly hit with messages (see
> above caveat! messages may not be real!) of “Why are you doing this?
> Nobody’s funding-constrained! Money isn’t real! Only talent
> constraints matter!” while knowing that if I tried to help with
> talent constraints, I would get “Sorry, we have 2,000 applicants per
> position, you’re imposing a huge cost on us by even making us
> evaluate you”.


https://www.facebook.com/groups/473795076132698/permalink/1077231712455695/

Joel miller on apping to operations. 

My biggest qualm is these people from 80khours come out and say, oh
you misunderstood what we said, not that what the fuck they said was
misleading. They think giving a post of explanaiton is all they need
to do. Fuck me and all the time I and several other AEA's are
attempting to spend to find a fucking a job which will add value. 

The thought or less thought that seems to go into loose words like
career capital, bottleneck, talent constrained, is worrying.

https://forum.effectivealtruism.org/posts/2XfiQuHrNFCyKsmuZ/max_daniel-s-shortform?commentId=nRciXmjukddKadzwZ

### From another article

**2019**

https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis

"The 2019 results were very similar to those of 2018, with few
exceptions. Demand remains high for people with skills in management,
prioritization, and research, as well as experts on government and
policy."


Policy seems to have risen quite a bit since last year again for only
EA as a whole, but not for "My Org".

**2018**

https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions

If I make a claim saying I am going to look at "My Org" details only
as it captures what that that organizations need, then atleast the
orgs listed things that they want:

Operations, management, GR, and MI and hustle bustle type of vague
roles.

Although gov and policy experts are rated high on what EA needs as a
whole.





https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis

**Funding constraints** always lower than talent, but close by in the
5 point scale.







**It is pretty clear that Swe engineers are low in need (6 vs 33)**

Where as ML engineers seem to be on par with GR last year and this year!




**Generalist researcher exit opportunities**





All this maybe if you get a job then you are worth

What are the high impact careers?

https://80000hours.org/articles/high-impact-careers/#4-apply-an-unusual-strength-to-a-needed-niche

### 80khours sucks

https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience#comments

Peter Hurford suggests that the whole discussion of the EA world being
"talent constrained" seems to be bogus as he has had no problem
whatsoever to find people he can hire. But then it stands why these
idiot orgs are writing that they are talent constrained. He seems to
also be questioning the numbers to trade for x employees. And 80khours
seems to be suggesting in this article that that number includes some
extra bullshit () and might not represent the true value of your worth.

I think we need to look at this more clearly. My god! This is just
questioning what I should be doing like dw vs etg, the prime
foundation. "An organisation reporting being ‘talent constrained’ doesn’t
necessarily indicate that they are about to hire a large number of
people." --- WTF
https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on

And that if you get a job then you it is probably worth it. Man the
wording infuriates me. Give me motherfucking examples dammit. I don't
trust your fucking reasoning and playing with fucking words. Piss off
will you.

AGB seems to point out that in an already full talent pool with
serious competitiveness, if I go and fight for a spot and then there
are two outcomes. I get the job and the rest of the overflowing pool
(who did not make the cut) go to find other jobs or 

**Rewrite of the discussion on replaceability and saying people are
worth more than what they are**

I think it is a discussion for if I should work in EAO or do DS. Nam saying...

## In conclusion

I don't knwo what all those orgs in the surveys were talking
about. Does anyone though?

Considering the supposed need is for a particular type of workers (as
in the survey) might not be ideal. i.e., just looking at the DEMAND
alone is not useful. as there are 100 other or atleast 58 other GR's
for 5 positions and there is no evidence it is going to suddenly grow
like crazy that the deamand is to be met. Hence my claim of
non-bottlenecks.

It appears useful to consider how to work in AI safety due to the
claim of potential bottleneck in that region too, but place caution on
how bottlenecked it becomes.

Additionally the value of being 1% better than the previous hire
(difficult to measure), needs to be estimated to give me a drive to
actually try and beat all these GR's. There is also a fear that I
might not be working for an EAO anytime (possibly in my life?nah)

I was thinking I was always going to become a GR, but I am strongly
considering against it. but I need to check the value of what I could
be or maybe there are some REAL places where the supply is shit, which
might need me. 

More organizations should publish data like OP or EAF for each round
to allow people to understand how bad or good the scene is and how the
candidates were (some quantitative measure to compare).

Market is so competitive and there doesn't seem to be examples of TC
except for in Disentanglement as far as I know. or I have examples
for.

## points about 80khours

- english  english english... many... how many ? though

- squishy terms, career capital talent constrained

- Inability to apologize for the possible miscommunication

- Lack of ability to provide a proper reply when asked about the time
  spent by EAs 
  
- Let's not loose focus. WE want to identify what we should be
  doing. Suprisingly this post was useful with its output on GR and
  the lack of demand. Atleast teh abundance of supply.

- 0 accountability (e.g., TC has 0 examples), its like people say or
  they say and we got to take it on face value.
  
- making claims without evidence (all regard to TC). Need statements
  that I can test. 80khours is not reliable.

- trying to genenralize goddammit

**Is there anything that is talent constrained?**

All this to me appears like a really fake hype. And further to cover
what they actually meant, they said they are talking about fucking
even smarter talent. I think one and only one example I have is people
in the AI safety where "Disentanglement" is a big deal and not many
people seem to be able to do that according to one of the operations
guys from a certain EAO. 


**80k's explanation**

	An organisation reporting being ‘talent constrained’ doesn’t
necessarily indicate that they are about to hire a large number of
people." --- WTF
https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on

Benjamin todd in the same post continues to say he feels TC.


**Takeaways**

Certain jobs seem to be 0 constrained. There are not many jobs
available, EAO's are hiring slowly. 

Rob Wiblin should take questions from listeners and what topics they
want to hear more about. keiran@80000hours.org

**Examples**

And also in the same article include shit like,

> Interestingly, many of the organizations report being neither heavily
> constrained by funding or talent,...

Talk about being vague. WTF is many! Jesus.

Naming of posts, my god: Aug 2018 : Highest impact career paths

April 2019: our list of high-impact careers

I find this confusing, if something is not leading anymore, put a note
on it and deprecate it. God dang it.

And it is so fucking similar in the index. Jesus! fuck you guys!

**Diff definitions**

There seems to be more than one definition:

> Another factor is that hiring takes up a lot of senior staff time –
> you need to source candidates, train them, test them out, and many
> won’t work out. Moreover, a bad hire could easily harm morale, take
> up a lot of time, or damage the reputation of the organisation, so
> there is a lot of risk. This means that it takes a long time to
> convert funding into good new staff, creating a talent
> bottleneck. But if a potential hire takes a short amount of time to
> evaluate, train and manage, they often wouldn’t get replaced for a
> long time. --- [Working at EAO](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable) June 2017. 

Confusing fuckers.

Another definition being: 

> A cause is constrained by a type of talent, X, if adding a (paid)
> worker with talent X to the cause would create much more progress than
> adding funding equal to that person’s salary. --- [Focus on talent
> gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps)


### Clarification on talent constrained

### Why aren't there many more EA's then?

### Why aren't EA hiring like crazy ?


### Is bottleneck and talent constrained the same thing?


### EA is funding constrained

They have been making quite a fuss about working at EAOs and not
etging (as in the Why should we focus more on talent gaps)


ETG and that too as a quants person in trading is ranked 8th in their
top priority paths behind, AI safety, policy and strategy, China
specialists, working in EAOs and doing global priorities research.
80khours suggests ETG unless it is quants person in trading or
hedge-funds (It's their 8th [top priority path](https://80000hours.org/articles/high-impact-careers/#our-list-of-priority-paths)) probably due to
the potential[300k<span>$</span> average donations per year](https://80000hours.org/2017/05/how-much-do-hedge-fund-traders-earn/).
 
> If you’re able to take a job where you earn more than you need, and
> you think none of the categories above are a great fit for you, we’d
> encourage you to consider earning to give. It’s also worth
> considering this option if you have an unusually good fit for a very
> high-earning career. 

> In brief, we think our list of top problems (AI safety, biorisk, EA,
> GPR, nuclear security, institutional decision-making) are mainly
> constrained by research insights, either those that directly solve
> the issue or insights about policy solutions.

> On the other hand, there is currently more funding available than is
> being spent in these areas, so earning to give doesn’t seem like the
> key bottleneck. ---[high impact careers](https://80000hours.org/articles/high-impact-careers/)(Aug 2018)


## Very easy to get into EAO

**How easy is it to get into EAO**

It is very easy to get into EAO:

> What are the predictors of success?  Based on our experience, the
> people most likely to excel at EA organisations tend to have the
> following traits:
>
> They really care about effective altruism, and are happy to talk about
> it all day. This is one of the main things the organisations look for,
> and it can be hard if you don’t share the same level of enthusiasm
> about effective altruism as other staff.  They’re excited and
> enthusiastic about the mission of the specific organisation they work
> for. You get a lot of responsibility in these roles, and it can be
> hard to sustain the intensity and effort required to succeed without
> being excited by the mission and strategy of the organisation.
>
> They’re self-directed, able to manage their time well, they can create
> efficient and productive plans, and keep track of complex
> projects. --- [Working at EAOs](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/)

More shit like this in "how can I get these jobs at EA" at [Working at
EAOs](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#how-can-you-get-these-jobs). Such as Volunteer at EAGx, help run a local EA group,
participate in feedback and reviews etc... (why I say shit hopefully
is clear later).




## Replaceable

https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable

read it

Also some statements about
	value... https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable


## Value

EA people are valued super high
:https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on

Milan Griffes estimate on 80khours says he could make a
contribution of 97k$ tomorrow if he works in givewell
https://80000hours.org/2016/08/reflections-from-a-givewell-employee/

Calculating value is very tricky

ETG vs EA (https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/)

Milan Griffes

how much value 80khours thinks you have by asking what to pay for last
hire.





## What did I think before, what changes now to my future? 

## How hard is it to get a job in EA now?





There seems to be money, even trying to earn to give seems to be
pointless, considering at max I can be a data
scientist. Entrepreneurship and starting a non-profit could well be
things in the bank. --> based on the article talent gaps vs funding
gaps

## References

## Footnotes
Need to fix footnotes





 



[^1]: In the 2017 survey they (80khours) say,

	> On a 0-4 scale EA organisations viewed themselves as 2.5 ‘talent
	> constrained’ and 1.2 ‘funding constrained’ (average),... 
	
	In 2017 surveyed orgs seem to want Forecasting-Priorities
	capabilities, GRs, Management and operations as top 4.

	2017 survey includes:

	> The survey includes (number of respondents in parentheses): 80,000
	> Hours (3), AI Impacts (1), Animal Charity Evaluators (1), Center for
	> Applied Rationality (2), Centre for Effective Altruism (3), Centre for
	> the Study of Existential Risk (1), Charity Science: Health (1),
	> Foundational Research Institute (2), Future of Humanity Institute (3),
	> GiveWell (2), Global Priorities Institute (1), Leverage Research (1),
	> Machine Intelligence Research Institute (2), Open Philanthropy Project
	> (5), Rethink Charity (1), Sentience Institute (1) and Other (6) (who
	> were mainly researchers).

	In the 2018 survey they (80khours) say,

	> On a scale of 0 to 4, respondents saw themselves as 2.8 constrained
	> by talent and 1.5 by funding, similar to last year and consistent
	> with the donation trade-off figures.
	
	> The effective altruism community’s greatest talent needs are inthe
	> fields of operations, management, generalist research, government and
	> policy expertise, and AI/machine learning expertise... Leaders thought
	> the key bottleneck for the community is to get More dedicated people
	> (e.g. work at EA orgs, research in AI safety/biosecurity/economics,
	> etg over $1m) converted from moderate engagement. The second biggest
	> is to increase impact of existing dedicated people through e.g. better
	> research, coordination, decision-making." --- 2018 survey

	In 2018 surveyed orgs wanted Operations, Management, GRs, and AI
	technical expertise were the top 4.

	2018 survey includes: 

	> 80,000 Hours (3), AI Impacts (1), Animal Charity Evaluators (2),
	> Center for Applied Rationality (2), Centre for Effective Altruism
	> (2), Centre for the Study of Existential Risk (1), Berkeley Center
	> for Human-Compatible AI (1), Charity Science: Health (1), DeepMind
	> (1), Foundational Research Institute (2), Future of Humanity
	> Institute (2), GiveWell (1), Global Priorities Institute (2),
	> LessWrong (1), Machine Intelligence Research Institute (1), Open
	> Philanthropy Project (4), OpenAI (1), Rethink Charity (2), Sentience
	> Institute (1), SparkWave (1), and Other (5)

[^11]: > 1 = how much things cost is never a practical limiting factor for
	> you; 5 = you are considering shrinking to avoid running out of money

	> 1 = you could hire many outstanding candidates who want to work at
	> your org if you chose that approach, or had the capacity to absorb
	> them, or had the money; 5 = you can't get any of the people you need
	> to grow, or you are losing the good people you have

[^12]: Well if you think of OpenAI, yes they seemt to be havign
    billions in investment for them to burn, but just last month MIRI
    came to me asking me for money in december as they could not meet
    some 1m dollars or something... <!-- rewrite and check if necessary -->

[^13]: I think it is an error and that they were clearly not talking
about ETG as in the later paragraph of the quotes.

[^14]: For AMF, if you look at it there are only 2 people a fucking lean
	machine. They seem to want funds and only funds. They dont seem to
	want people. By that we can see that AMF wants 

	I was bat shit confused, I almost said these two are so different but
	then in the end it was not that hard, only once I used examples. You
	can't reason without examples you will feel confused. Thank You to an STM.

	jump in respect for BT. I think I should be more careful and use this
	definition example mindset to get things done. 
