---
layout: post
comments: true
title:  "An analysis on if EA is Talent constrained" 
date:    05-05-2020 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: false
---


## STM feedback

Machan,

> > BTW: http://agent18.github.io/is-ea-bottlenecked-2.html (Uyir a
> > koduthu eluthirkain;80hrs ezhuthirkain, need some meha critical
> > feedback on writing, any potential claim evidence fuckups etc...)

> I would pause immediately at the term "talent-constrained". I don't
> understand it. The first step is to describe the claim "X is
> talent-constrained" in terms of **familiar claims** so that you can
> actually test the claim against evidence. Do you mean that there is a
> low rejection rate for PhD applicants?

> A related issue is that, for the same claim, you're **switching between
> evidence in the form of surveys and evidence in the form of rejection
> rates**. If the claim is about rejection rates, then you either have the
> numbers or you don't. If you don't, you can't test that claim against
> a concrete example. If the claim is about surveys, then you'll have to
> use the survey. Right now, you're taking the same claim and mixing
> multiple kinds of evidence, such as surveys and 80k opinion posts and
> rejection rates, which left me at the end with no clear answer.

> So, split the different kinds of claims: "EA has high rejection rates"
> and "EA surveys have high percentages saying the words 'we are
> talent-constrained'". You can even make the claims more precise:
> "Operations manager roles have high rejection rates for candidates
> with 2 years of similar experience" - notice how you can immediately
> test that claim given concrete examples.

> Contrast that to "In brief, we think our list of top problems ... are
> mainly constrained by research insights". How do you test that given
> some data? Imagine if they'd said "Salaries went up by 20% last year
> but number of open questions solved in published papers went down by
> 40%". We can debate whether "number of open questions solved" has been
> a useful metric but there's no question that we can test that claim
> against evidence.

* * * * *

> On a different note, a key point that is missing from the analysis,
> here and elsewhere, is that we talk about a shortage ***for a given
> price***. We don't say that there is no supply of onions. We say there
> is no supply of onions at Rs 10/kg. When the price has eventually
> risen due to lack of supply, people have even transported onions from
> other countries to supply them for a profit.

> Saying that there is a lack of "talent" or researchers for a given
> role doesn't make much sense unless you talk about the current
> salary. But people are talking as though, no matter the salary,
> there is not enough talent in the world to do this research. People
> have in the past moved from country to country and from job to job
> for higher pay (and other desired characteristics like climate and
> family members). There are a lot of well-published PhDs and postdocs
> working on all kinds of other research areas for much less than
> six-figures and a lot of professors and researchers working for not
> too much more. Is the claim that they won't switch for a 2x salary
> or that they can't study and catch up on the slightly different
> field in a few years? If the EA organizations were "desperate" for a
> particular kind of researcher, did they raise the salary a lot? If
> they didn't have enough funds to raise salaries, then aren't
> they... "funding-constrained"? Are the two "constraints" actually
> distinct?

* * * * *

> Mission #6: For now, I recommend **rewriting the post after splitting
> the claims till you have narrow claims** that are either tested with
> examples or don't have any available examples. **Check if** you see
> any lingering confusion or **ambiguity** at the end. One week should
> be enough time.

## Entry question

Maybe instead of trying to work out if 80khours sucks or not, maybe I
should focus on identifying what jobs are TC and what jobs are
FC. Because it could give me an indication if I should work or donate
more. No idea how I would go further from there. but. Let's see. 

**Entry question**

I think I want to understand if EA orgs are able to hire people with X
years (amount) of experience or do they end up not hiring people or do
they end up hiring people with lesser experience. Because currently it
seems like atleast according to claims that they are struggling to
find the right candidates. Which I don't think is the case. 

~~Also I am looking to get into EA and these could serve as metrics but
more importantly I need replaceability then and the counterfactual
impact.~~ 

## Identifying narrow claims and test them

"EA is TC". Too vague. I see that what I am trying to do is
"holistically" look at all the evidence (rejection rates), find
someone with expected skill, making conclusions for where there is no
info and concluding. This has its cons that I don't know what is
what. I didn't even realize I was doing this. For example I was
wondering why STM was talking about rejection rates. I didn't even
think this was a thing. I didn't even split the discussion into the 4
things I could test. Atleast now it seems to be much more clear, where
I don't have evidence and what especially would be my conclusions as a
result. 

GR, G&P, GPR, Founding, ~~Soc. Skill~~, ML/AI, ~~Movt. Build~~

I want to understand if orgs are unable to find the "particularly
skilled people"

**Predicates to be used**

- Rejection rate. 
- Find people with specific skill

- Ability to find someone with the "expected skill"

- Ability to find someone within a particular cost

- ~~*want to hire but are unable to hire due to management capacity*~~

- ~~*replaceability?*~~

- ~~well established orgs vs not so well established orgs (?)~~

- supply demand

--- **General**

**Claims**: GR has high rejection rates.

**Claims**: EA Surveys have high percentage of people saying "GR is
TC"

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions.

I know what the evidence looks like. EA orgs hire or don't hire for
that particular vacancy after a hiring round.

**Claims**: As a result of not being able to find "better people" per
unit price, they settle down for something lower hires (hence they
claim so in the survey could be an explanation).

I don't have evidence for it. 

Can't say because you have 0 evidence on this. What would the evidence
look like though?

**Claims**: supply demand?

--- **Other**

**Claims**: EA is TC because there could always be someone better for
cheap (is it "FC")?

**Claims**: EA is TC because they want someone at a particular cost
(operations cost, management costs, salary, etc...)

**Claims**: EA orgs want to hire more and have the funding to do it,
but are unable to hire more people?

### OTHER

does not mean they can't hire more.. as a whole they still need
more...???

Chai and other startups that shut down because they didn't have a
co-founder etc...

3 people interviewed for a position.

GiveWell haveing way too much cash for these niggas

## All about FC
### predicates
	
**Predicates**

- didn't raise enough during fundraising
- was not able to hire additional people because of lack of money and
  not management to support the new hires
### Surveys

**Claims**: EA orgs are "TC compared to FC" according to surveys

**Example**: 2019 survey score 3.8 vs 2.4 (Avg of ~33 responses)

**Definition**: checks out

**Checklist**: True.
 
--- 

**Claims**: Global poverty and Animal EA orgs are "FC compared to TC"
according to surveys

**Example**: 2019 doesn't have this split, but 2018 survey seems to
have it.  2.6 vs 3.6

**Definition**: Does not check out

**Checklist**: False.
 
---

### Lack of funding

**Claims**: EA orgs in Longtermism that want to grow are unable to
hire more researchers due to lack of funding

**Example**: OpenAI has a billion euros to spend and 100 people in
counting. MIRI seems to be meeting its target

I don't have an example where say OPP wanted to grow and
were stopped by their lack of funding. They seem to be happy with
their funding. they infact never write about funding. 

On the other hand you see fundraisers organized by MIRI, they seem to
be able to meet them (2018)

I think asking the orgs themselves is the way to go. 

**Definition**: -

**Checklist**: -
 
---

**Claims**: Longtermism EA orgs' fundraiser does not turn out to be
successful 

**Example**: "Given our $6.8M budget for 2020, and the cash we
currently have on hand, raising $1M in this fundraiser will put us in
a great position for 2020. Hitting $1M positions us with cash reserves
of 1.25–1.5 years going into 2020, which is exactly where we want to
be to support ongoing hiring efforts and to provide the confidence we
need to make and stand behind our salary and other financial
commitments." 

"While we’re quite uncertain about how large we’ll ultimately want to
grow, we plan to continue growing the research team at a similar rate
over the next two years, and so expect to add around ten more research
staff by the end of 2021." --- [2019 fundraiser](https://intelligence.org/2019/12/02/miris-2019-fundraiser/)

They were [400k`$` short](https://intelligence.org/2020/02/13/our-2019-fundraiser-review/) of making that Million in that
month. Their [2018 fundraiser was 250k short](https://intelligence.org/2019/02/11/our-2018-fundraiser-review/) which ran for 5
weeks.

However OPP never does Fundraising, they seem to be supported by Cari
Tuna and Dustin Moskowitz.

**Definition**: At least in this case. 

**Checklist**: True.
 
---

**Claims**: Global health EA orgs that want to grow are unable to grow
due to lack of funding

**Example**: 

> Based at least on my recent hiring for Rethink Priorities, I can
> definitely confirm this is true, at least for us. We ended up
> completely overwhelmed with high-quality applicants beyond our
> wildest dreams. As a result we're dramatically scaling up as fast as
> we can to hire as many great applicants as we can responsibly,
> taking on a bunch of risk to do so. Even with all of that additional
> effort, we still had to reject numerous high-quality candidates that
> we would've otherwise loved to work with, if only we had more
> funding / management capacity / could grow the team even faster
> without overwhelming everyone.

> The Life You Can Save's Jon Behar, [agrees with Peter](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB). He adds
> that it's not the lack of talent but the lack of money to add new
> staff which is the bottleneck for TLYCS.

**Definition**: checks out

**Checklist**:  True.

---

**Claims**: EAs with poor hiring rounds don't write them out.

**Example**:  -

**Definition**: - 

**Checklist**: -
 

## Claims
### GR in GPR (4)

**Claims**: GR jobs have high rejection rates.

**Example**: At OPP's 2018 hiring round for GRs, the rejection rate
was greater than [95% of "strong resumes" according to OPP](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting). Less
than 5% got the job.

At [EAF's November 2018 hiring round](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) they wanted to hire 1 GR
([for grant evaluation](https://ea-foundation.org/open-position-research-analyst/)) and 1 operations person. 66 people applied
withing 2 weeks and 2 people were selected. 97 % rejection rate.

**Definition**: Rejection rates at Y-combinator in 2017
98.37%. Rejection rate at Harvard is 94.7% in 2019. These are some of
the most competitive places people want to get into. And OPP and EAF
seems to be in the same realm.

**Checklist**: True

---

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more GR people"

**Example**: In the [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis) survey, GR got the most votes for, out
23 other "talents" for the question "What types of talent do you
currently think [your organization...] will need more of over the next
5 years?  "

**Definition**: Checks out. 1/23

**Checklist**: True  

---

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in GR at the end of the round.

**Example**: Both at OPP's and EAF's evaluation, (they found atleast 2
times more people than needed for trails, trialed them out and) have
selected people who they think fit.

**Definition**: Checks out. They were able to fill the positions for GR.

**Checklist**: True.

---

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower hires while hiring
GRs. 

**Example**:  I don't have any example of people stating that they
settled for someone with lower qualifications be it in GR or anything.

**Definition**: better could mean based on yoe or skill level something.

**Checklist**: Unknown

---

### Operations

**Claims**: Operations jobs have high rejection rates.

**Example**: At [EAF's November 2018 hiring round](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) they wanted to
hire 1 GR ([for grant evaluation](https://ea-foundation.org/open-position-research-analyst/)) and 1 operations person. 66
people applied withing 2 weeks and 2 people were selected. 97%
rejection rate.

**Definition**: Rejection rates at Y-combinator in 2017
98.37%. Rejection rate at Harvard is 94.7% in 2019. These are some of
the most competitive places people want to get into. And OPP and EAF
seems to be in the same realm.

**Checklist**: True  

---

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more Operations people"

**Example**: In the [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis) survey, Operations got the second most
votes for, out 23 other "talents" for the question "What types of
talent do you currently think [your organization...] will need more of
over the next 5 years?"

**Definition**: Checks out 2/23

**Checklist**: True

---

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in Operations at the end of the
round.

**Example**: -

**Definition**: -

**Checklist**: Unknown

--- 

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower hires while hiring
GRs. 

**Example**: -

**Definition**: -

**Checklist**: Unknown
 
---
 
### AI

**Claims**: DR jobs have high rejection rates.

**Example**: Miles Brundage in [The world desperately needs AI
strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/) (June 2017) says that the jobs are "competitive"

**Definition**: -

**Checklist**: Unknown

---

**Claims**: AI Strategy and Policy jobs have high rejection rates.

**Example**: [Carrick from FHI](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy) (Sep 2017) who worked in the
recruiting side of FHI suggests that "extremely talented people" will
not be able to contribute directly.

**Definition**: Although this is tempting to think of as high
rejection rates, I don't think we should.

**Checklist**: Unknown

---

**Claims**: ML Engineers have high rejection rates.

**Example**: -

**Definition**: -

**Checklist**: Unknown

---

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more AI/ML people"

**Example**: Not per say DR or AI policy or AI strategy, but another
term "ML/AI". In the [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis) survey, Operations got the second most
votes for, out 23 other "talents" for the question "What types of
talent do you currently think [your organization...] will need more of
over the next 5 years?"

**Definition**: checks out

**Checklist**: Unknown
 
---

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in DR at the end of the round.

**Example**: Per say not a vacancy or a hiring round. But [Carrick
from FHI](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy) in 2017 wrote that if you cleared the bar for DR then you
will get a job and asked people to reach out to FHI. 

**Definition**: Looks like they are unable to fill positions in DR.

**Checklist**: False atleast in the region of Sep 2017
 
---

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower while hiring
AI. 

**Example**: -

**Definition**: -

**Checklist**: Unknown

---

### Entrepreneurs

**Claims**: Entrepreneurial jobs have high rejection rates.

**Example**: More than 2k applications for 15-20 spots this year at
the [Charity Entrepreneurship's incubation program](https://forum.effectivealtruism.org/posts/fNRSGinhWqPZtuo3T/application-process-for-the-2019-charity-entrepreneurship). (Last year it
was at 140 applications for the same number of spots.)

**Definition**: 1% reject rate is "high"

**Checklist**: True

---

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more Entrepreneurial people"

**Example**: In the [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis) survey, founders got the 4th most votes
for, out 23 other "talents" for the question "What types of talent do
you currently think [EA a whole...] will need more of over the next 5
years?"

**Definition**: 

**Checklist**: 

---

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in X at the end of the round.

**Example**: Last year with 140 people they were already "just" able
to fill up the positions they had left. This year with 2000 people it
should not be that hard.

**Definition**: Checks out

**Checklist**: True

---

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower hires while hiring. 

**Example**: Not the case with CE. Their leader clearly says, "We have
an absolute bar more so than a relative one so if the top 15 people
had not applied we would not have run the program as opposed to
running it with the next best 15".

the point is we are trying to see if that is actually the case after a
hiring round that they settle for somthing lesser and hence claim TC.

**Definition**: checks out

**Checklist**: False.

### Research and sr. staff in Global Poverty alleviation

**Claims**: GR jobs have high rejection rates.

**Example**: -

**Definition**: -

**Checklist**: 

---

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more GR people"

**Example**: In the [2019](https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis) survey, GR got the most votes for, out
23 other "talents" for the question "What types of talent do you
currently think [your organization...] will need more of over the next
5 years?  "

**Definition**: Checks out. 1/23

**Checklist**: True  

---

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in GR at the end of the round.

**Example**: 

> I’ve certainly had no problem finding junior staff for Rethink
> Priorities, Rethink Charity, or Charity Science (Note: Rethink
> Priorities is part of Rethink Charity but both are entirely separate
> from Charity Science)… and so far we’ve been lucky enough to have
> enough strong senior staff applications that we’re still finding
> ourselves turning down really strong applicants we would otherwise
> really love to hire.---[Peter Hurford says in the 2019 survey](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC)

The Life You Can Save's Jon Behar, [agrees with Peter](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB).

**Definition**: Checks out. They were able to fill the positions for GR.

**Checklist**: True.

---

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower hires while hiring
GRs. 

**Example**:  

> I’ve certainly had no problem finding junior staff for Rethink
> Priorities, Rethink Charity, or Charity Science (Note: Rethink
> Priorities is part of Rethink Charity but both are entirely separate
> from Charity Science)… and so far we’ve been lucky enough to have
> enough strong senior staff applications that we’re still finding
> ourselves turning down really strong applicants we would otherwise
> really love to hire.---[Peter Hurford says in the 2019 survey](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC)

The Life You Can Save's Jon Behar, [agrees with Peter](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB).

**Definition**: better could mean based on yoe or skill level something.

**Checklist**: False

### Policy
### template

**Claims**: GR jobs have high rejection rates.

**Claims**: EA Surveys has a lot of votes from orgs saying "they need
more GR people"

**Claims**: While searching to fill up a particular vacancy EA orgs
are unable to fill the positions in GR at the end of the round.

**Claims**: As a result of not being able to find "better people" per
unit price, EA orgs settle down for something lower hires while hiring
GRs. 





## Entry question

I would like to know if EA Orgs are able to hire people with specific
skill-sets (e.g., researcher with 2 years of experience) for a given pay
(e.g., 70k`$`). 

I would like to know if EA orgs have a "lot" of "good candidates" to
choose from.

## Too many definitions

We keep hearing "[EA is TC](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/) in X", "[EA is more TC than FC](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/)",
"[EA is bottlenecked in X](Maybe split these into Longtermism, Global poverty and AEA?)", "It is better to try to work at an EA
org, than do for ETG" etc...  What is this TC though?

**Definition 1**

80k defines TC in "[Why you should work on Talent gaps](https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps)" (Nov 2015)
as,

> For some causes, additional money can buy substantial progress. In
> others, the key bottleneck is finding people with a specific skill
> set. This second set of causes are more “talent constrained” than
> “funding constrained”; we say they have a “talent gap”.

So, a cause is TC if finding people with a specific skill set, proves
to be difficult. The difficulty I assume is in the lack of those
skilled people, and not some process/management constraint[^3]. "[EA
Concepts](https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/)", clears this confusion up with a better worded
"example":

> Organization A: Has annual funding of $5m, so can fund more staff,
> and has been actively hiring for a year, but has been unable to find
> anyone suitable... Organization A is more talent constrained than
> funding constrained...

**Definition 1.1**

When orgs hire "lesser people", as "better people" are not available,
can also be considered TC according to one EA.

**Definition 2**  

TC seems to also stand as a proxy for other things most notably used
by people from 80000hours themselves. [Benji talks about it here](https://forum.effectivealtruism.org/posts/Z9x56yiX2ceRZnKTR/a-naive-analysis-on-if-ea-is-talent-constrained?commentId=uS7YvonDGRfrznaZq):
"These roles (referring to policy roles in Govt.) are all ‘talent
constrained’, in the sense that hundreds of people could take these
positions (in govt.) without the community needing to gain any
additional funding". That seems quite different from what TC meant in
Definition 1.

**Definition 3**  

In addition, imagine an org that isn't able to hire researchers
because of "insufficient upper management people", "don't want to grow
too fast", "some inability to asses and deploy the available talent
now". Such an org can also say they are TC.

**Definition 4**

And when an org that doesn't have funding to hire new staff, it could
claim that they are TC because they are unable to hire new staff.

--- <!-- NoT TC rhetoric -->

Based on the above we write the following claims:

**Claims**: EA orgs able to find people ~~with specific skills~~ at the
end of the hiring round.

<!-- Talent pool based on experience of people in the fields. -->

**Claims**: EA orgs are not ending up hiring lesser people than what
they had intended to at the end of hiring round

<!-- RR and Talent pool based on experience -->

**Claims**: EA orgs have a "lot of good candidates" to choose from.

<!-- Using RR and Talent pool based on experience. -->

**Claims**: There are a lot of vacancies in Govt./ Academia which are
usually not taken by EA people.

--- <!-- Not FC rhetoric -->

**Claims**: EA orgs are unable to hire people due to lack of money

**Claims**: EA orgs are unable to hire people due to reasons such as
"insufficient upper management people", "don't want to grow too fast",
"some inability to asses and deploy the available talent now"

**Claims**: EA orgs are unable to raise intended amount during
fundraisers


1-4 for different X's

5,6,7 for maybe split these into Longtermism, Global poverty and AEA?

So let's forget that term TC and focus on the more familiar predicates
as discussed above in "EA is TC in X". What is X though?

---

In "EA is TC in X",  TC could stand for any of these 5 definitions (or
even more that I am unaware of) and we would like to get to the bottom
of it. But before that what is X?

## Opinion posts

A way to arrive at this X, is to look at **[top problem profiles](https://80000hours.org/articles/high-impact-careers/#our-list-of-priority-paths)**
and check what the claimed "bottlenecks" are. For example, AI is a
"top problem area" according to 80000hours. In the [profile on shaping
AI](https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/#what-can-you-do-to-help) (March 2017), we see that 80k calls for people to help in AI
Technical research, AI Strategy and Policy, Complimentary roles and,
Advocacy and Capacity building. So basically EVERYTHING IN AI except
ETG, is TC (it appears). In the problem profile on [GPR](https://80000hours.org/problem-profiles/global-priorities-research/#what-is-most-needed-to-solve-this-problem) (July
2018), 80k suggests that they mainly need researchers trained in math,
econ, phil etc... Also needed are academic managers and operations
staff. A very similar story for [working at EA orgs](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#what-skills-are-the-organisations-most-short-of) as well. In
the post on [High Impact Careers](https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories) (August 2018), 80k suggests
**priority career paths** and that they are constrained by research
insights across top problems like AI safety, Biorisk, GPR, Nuclear
security etc...

In **focused bottleneck posts** for Operations and AI Strategy just
the title already informs how "TC" the situation is:

- [The world desperately needs AI strategists](https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/) (June 2017)

	Here, other than the title, I didn't really understand the
    "desperate need for AI strategists". Miles expects that "many"
    jobs would open up in the "future" and also suggests that the jobs
    are competitive.
	
- [Why operations management is one of the biggest bottlenecks in
  effective altruism](https://80000hours.org/articles/operations-management/#which-traits-do-you-need) (March 2018)
  
  80k updated this post one year later saying that the post is
  "somewhat out of date", and that the job market has changed over the
  last year. Moving on.
  
So now that we have X and the definition of TC, we can start testing
these claims. "Luckily" for us we have the surveys from 80000hours and
CEA for the last three years.
   
## Surveys

**The surveys** from 2017 to 2019 try to provide information on "what
sort of talent the EA orgs and EA as a whole would need more of, in
the next 5 years?". 80000hours seems to think that this question
sounds like a proxy to "Where is EA specifically TC?", as evidenced
[here](https://80000hours.org/articles/high-impact-careers/#our-list-of-priority-paths)[^7] and [here](https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#what-skills-are-the-organisations-most-short-of)[^8].

But, such a survey seems to give info on the forecast of demand of
GRs, operation people etc... It doesn't say whether the demand is met
or not. It doesn't seem like this question in the survey can answer
any of the 7 claims we had in mind. If the survey was about "which
jobs are you able to find less than 3 people to hire who meet your
expectations", then I think it could answer the first claim.

Nevertheless the survey provides X's to test with. The top 7 results
(out of 20 or so) of the survey are below:

{:.tablestyletwo}

|   | 2019      |
|---|-----------|
| 1 | GR        |
| 2 | Oper.     |
| 3 | Mngment   |
| 4 | ML        |
| 5 | Econ/math |
| 6 | HighEA\*  |
| 7 | GPR       |

\* High level overview of EA  
\*\*\* Government and Policy 

---

Aggregating the X's we have so far.

1. AI tech research, AI Strategy and policy, Advocacy and Capacity
building, complementary roles.

2. Researchers/GRs and policy solutions in EA, GPR

3. Researchers and policy solutions in Bio-security, nuclear security,
institutional decision making

4. Survey: GRs, Operations, Management, Econ/Math researchers, Global
Priorities Research in EA orgs 

## Finding the right people

**Claims**: EA orgs are able to hire enough people at the end of the
hiring round.

**Example**: 

[OPP hired 5 GR people](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting). They wanted to hire 5 people
as well.

[EAF set out to hire 1 GR and 1 operations](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) personnel and ended up
doing that.

[RP RC CS](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC#tojT8rKhwCz9rfJbB) & [TLYCS](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB#tojT8rKhwCz9rfJbB) when they hire junior and senior staff
(researchers I think): "I’ve certainly had no problem finding junior
staff for Rethink Priorities, Rethink Charity, or Charity Science
(Note: Rethink Priorities is part of Rethink Charity but both are
entirely separate from Charity Science)…  and so far we’ve been lucky
enough to have enough strong senior staff applications that we’re
still finding ourselves turning down really strong applicants we would
otherwise really love to hire."

CE accepted 17 people to its incubation program to found charities and
had space for roughly 20 (via email)in 2019. However the number of
applicants has risen by more than 10 times this year from 140 last
year. So they expect this year to hire enough people.

**Definition**: So far looking at GR, Research, and operations they
seem to satisfy the claim. However as of last year atleast, CE's
available jobs were not filled. But in 2020 the situation is bound to
be different. Regarding the rest of the positions I have no idea.

---

**Claims**: ~~EA orgs do not accept "lower hires" than what they set out
to get.~~ EA orgs seem happy their recent hires

**Example**: Unfortunately, all I have is testimonials to comment on
the quality of candidates, from which we need to infer. I could be
specific saying X years of experience but I don't have any examples
for it.

For this I want to suggest to look at their reactions about how
satisfied they are with the these guys are happy with thier current
hires. it looks like.

OPP said they got more than 100s of good resumes for the GR
positions. In the end they were expecting multiple people from the
pool who had missed the 5 positions, to exceed in OPP in the future

[RP RC CS Personnel Peter said](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=s9wuF9QQgjfHvfPAB),"Based at least on my recent hiring
for Rethink Priorities, I can definitely confirm this is true, at
least for us. We ended up completely overwhelmed with high-quality
applicants beyond our wildest dreams. As a result we're dramatically
scaling up as fast as we can to hire as many great applicants as we
can responsibly, taking on a bunch of risk to do so. Even with all of
that additional effort, we still had to reject numerous high-quality
candidates that we would've otherwise loved to work with, if only we
had more funding / management capacity / could grow the team even
faster without overwhelming everyone."

[TLCYS seems to agree with what Peter said](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB).

CE in an email said that they have an absolute bar and wouldn't take
anyone if they didn't pass that bar.

**Definition**: It appears that all orgs above seem to not have
settled for something lower than what they set out to get. 

---

**Claims**: ~~There are a lot of good candidates~~ There were atleast
2x people in the trial work round (finals) of each hiring round, as
the number of hired.

**Example**: 

OPP had 17 people in the trial round while hiring 5 people

EAF had 4 people in the trial round while hiring 2 people

CS in 2019 only had lesser people than they were planning to
hire. They had about 17 people for ~20 positions. But then again we
should remember that in 2020 they have had more than 10times the
applications.

**Definition**: Checks out for OPP and EAF, But not for CE type of
orgs.

**Claims**: There are more candidates orgs would like to hire but
cannot.

**Example**: 

OPP said they got more than 100s of good resumes for the GR
positions. In the end they were expecting multiple people from the
pool who had missed the 5 positions, to exceed in OPP in the future

[RP RC CS Personnel Peter said](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=s9wuF9QQgjfHvfPAB),"Based at least on my recent hiring
for Rethink Priorities, I can definitely confirm this is true, at
least for us. We ended up completely overwhelmed with high-quality
applicants beyond our wildest dreams. As a result we're dramatically
scaling up as fast as we can to hire as many great applicants as we
can responsibly, taking on a bunch of risk to do so. Even with all of
that additional effort, we still had to reject numerous high-quality
candidates that we would've otherwise loved to work with, if only we
had more funding / management capacity / could grow the team even
faster without overwhelming everyone."

[TLCYS seems to agree with what Peter said](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=tojT8rKhwCz9rfJbB).

CE in an email said that they have an absolute bar and wouldn't take
anyone if they didn't pass that bar atleast as of 2018.

**Definition**: Checks out for most except CE.

 
## Acceptance Rates and high quality pool

**Claims**: EA orgs have high rejection rates

**Example**: 

The hiring rounds that I can get my hand on were the following: [GRs
to OPP in 2018](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting), [GR and Operations to EAF in 2018](https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round) and [CE in
2018](https://forum.effectivealtruism.org/posts/fNRSGinhWqPZtuo3T/application-process-for-the-2019-charity-entrepreneurship) and 2019. Reaching out to orgs such as MIRI didn't help get
more info.

| Year | Org | position                    |    AR |
|------|-----|-----------------------------|------:|
| 2018 | OPP | GR                          |   <5% |
| 2018 | EAF | GR  & Operations            |    3% |
| 2018 | CE  | CE entrepreneurship program |  8.9% |
| 2019 | CE  | CE Entrepreneurship program |   <1% |
| 2019 | CE  | Internship Mental Health    | <2.5% |

**Definition**: 

It appears that EA orgs performing hiring rounds have high rejection
rates. For high rejection rates I imagine the rejection rates of
Y-combinator ([1.6% in 2017](https://theatlas.com/charts/BJwZHZlgZ)) or Harvard like institutions ([4.7%
to 6.9%](https://www.google.com/search?sxsrf=ALeKk019oY5Itumrdq_fR2vkl6oGMUPHXQ%3A1589708513303&ei=4QbBXqX5EYOykwW-zrvIAQ&q=harvard+acceptance+rates&oq=harvard+acc+rates&gs_lcp=CgZwc3ktYWIQAxgAMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yBggAEAcQHjIGCAAQBxAeMgYIABAHEB4yCAgAEAgQBxAeMggIABAIEAcQHjIICAAQCBAHEB46BAgAEEdQlhRY8hZg4hxoAHACeACAAXyIAY4CkgEDMi4xmAEAoAEBqgEHZ3dzLXdpeg&sclient=psy-ab).

**Claims**: ~~Talent pool is strong~~ Orgs had to turn away candidates
even though they would have liked to work with them.

**Example**: 

[OPP (GR)](https://www.openphilanthropy.org/blog/reflections-our-2018-generalist-research-analyst-recruiting): "I suspect that multiple candidates that we were not able to take
on in our most recent round have the potential to excel in roles at
Open Philanthropy in the future... more than a hundred applicants had
very strong resumes and seemed quite aligned with our mission — but
our current ability to immediately assess and deploy this base of
available talent is weak,..."

RP (Jr. Researcher) by email: "The next candidate was roughly as good
as the person we hired"

[RP RC CS](https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC#tojT8rKhwCz9rfJbB): " I’ve certainly had no problem finding
junior staff for Rethink Priorities, Rethink Charity, or Charity
Science (Note: Rethink Priorities is part of Rethink Charity but both
are entirely separate from Charity Science)… and so far we’ve been
lucky enough to have enough strong senior staff applications that
we’re still finding ourselves turning down really strong applicants we
would otherwise really love to hire."

[FHI in 2017](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy): "Accordingly, a large majority of people interested
in this cause area, even extremely talented people, will find it
difficult to contribute directly, at least in the near term."


| Org      | Position               | Talent Pool/ReR (gut feel)             |
|----------|------------------------|----------------------------------------|
| OPP      | GR (5x)                | 100s of strong resumes.                |
|          |                        | Talent Pool is strong.                 |
|          |                        | Multiple candidates have the potential |
|          |                        | to exceed.                             |
| RP       | Jr. Researcher         | The next candidate was roughly as good |
|          |                        | as the person we hired.                |
| RP RC CS |                        | Had to turn away several good hires    |
|          |                        | we would have liked to work with       |
| TLYCS    | Jr. Researcher         | Similar to RC                          |
| FHI 2017 | AI strategy and Policy | Even Extremely talented people         |
|          |                        | will not be able to contribute         |
|          |                        | in AI strategy and Policy              |
| CE 2019  |                        | **Didn't have to turn away**           |
| CE 2020  | Incubation program     | Possibly replaceable due to the        |
|          |                        | large number of apps                   |


**Definition**: 

**Checklist**: 
 

Atleast the above seems to suggest that a good percentage of people
seem to find that there are more than
Looking at the rejection rates in combination with the quality pool
suggest the number of people worthy of getting hired. 

I don't know how to write this out further. Should I maybe leave it at
the point of rejection rates. I don't know what to conclude.

## Many jobs in govt/academia (struggling) **Start here pandian**

So we would like to know if there are a lot of vacancies in govt. What
does lot mean? I think lot means that there are very few "EA-aligned"
people working in govt. There are many agencies and academia so there
must be a lot of jobs currently. If non-"ea-identified people" get in, then it
could not be as impactful as ea people.

**Claims**: There are a lot of jobs currently(last 3 months) for AI
Policy in Govt. and Academia.

About [10 jobs identified as per 80000hours job board](https://80000hours.org/job-board/ai-safety-policy/) in the last
three months including all types of senior roles, non-profits and
interns too that had to do with Policy.

DOD JAIC No

DeepMind No

OpenAI 1 Policy manager 

DoD JAIC which was expected to hire 200 people has about 40 people
(per linkedin), and of which only 10 people seem to be in policy
conservatively. 5 per year per agency across all seniorities.

**Claims**: AEAs will have more impact than people who take up these
jobs compared to other people who are taking up these jobs.

No example.

**Claims**: People pursuing AI Public Policy currently are few

Given that there are perhaps a dozen people currently pursuing **US AI
public policy careers focused on advanced AI systems**, there is room
for far more people to pursue this option.

Dozen people currently working full time on AI policy challenge (seems
relevant to long term AI Policy)

**Claims**: We needs 100s of people in the future

Not possible to test.

---

## unable to hire more people due to lack of money

neartermism

Only TLYCS is the org I know that is unable to hire new staff due to 

PH from RP CS RC says he would like funding/mangement capacity/ he
could grow further.

longtermism

OPP doesn't seem to say lack of money is the problem but other things
are 

CE explicitly mentions that they don't need money atleast last year.

## unable to hire more people due to other factors

OPP for sure ...

## unable to raise intended amount during fundraisers

MIRI, GiveWell

## Able to absorb more money

giveWell charities can absorb 100m`$`  

https://www.givewell.org/charities/amf



## Dump

**Mathivanan**

Add the part about replaceability and GiveWell ... Later ???

---

In this post, discussions are focused on *Orgs that are TC* and not
*Causes that are TC*. When I read that [AI strategy is TC with the
lack of "Disentanglement Research" (DR)](https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy), I don't know what to do
about it. But if I know FHI and many other orgs are TC in DR, then I
could potentially upskill in DR, and close the talent gap. So looking
at causes for me, is less helpful, less concrete and is not what I
have set out to understand.

I care about jobs, if they are really TC, how competitive are they
are, Are EA orgs really unable to hire people etc...

   
## Criticism

so i tried asking people for help. some info how they feel about new
hires etc.. But alomst no one is able to pay me any info what so
ever. So how am I to go about it?
Huh?

## Conclusion

I am unsure how to conclude. I have presented the evidence as
shown. And for the things I am interested in such as GR or research in
EA orgs, it appears that they are able to get their candidates as
needed.

It almost seems wise to me to actually donate on a DS job considering
that there is plenty of talent in GR and 

The mistake I made in the previous post is that I didn't really split
and test for the different predicates. Hell i internally just saw the
rejection rates (didn't know if it was high or low), and had one
definition in mind and assumed 80000hours fucked ups. I 

More over, I confused all sorts of evidence for different predicates
all together.  Give example...

I used the surveys as claims. But in this post they were interpreted
completely differently.

The need to split into familiar terms is much appreciated. A lot of
itmes I kept asking myself if this predicate sounded like TC. Jesus
that is not what I should do. I should instead check the predicate
against things like, "are people able to find jobs, are EAs finding
the people they need, is the demand for jobs meeting the supply of
personnel etc..."

Something I didn't know how to deal with was people giving me random
claims such as people of lesser skills were hired because they
couldn't find the people they wanted. I didn't know how to deal with
it. I should take the hypothesis and try to see if I can test it. 

80ks Benji said that they are TC in the way that there are many govt
positions. I am alsmot sure I just accepted in on Face value, without
realizing that that is a different definition that what was already
there. I merely just accepted that this meant TC. Right now I dont'
want to use that word anymore. Its so confusing.

Whenever there is confusion I would like to look at the defintion of
the predicate. I am afraid that is causing me a lot of confusion. Same
thing happened with "many jobs in govt." claim.


---

When I heard an example that DoD JAIC was looking for 100s of people,
I was like wow, this is what he meant. The power of an example. I
remember even thinking that I knew a couple of positions that are
TC. e.g., DR in FHI and policy jobs in Govt. But is it TC? This
particular part is rather convoluted. Everytime I feel like I am
around TC I get confused. Like its an abstract term and I am comparing
and checking if definitions mean TC. WTF does that even mean?

Anyways my point is I take things at face value I shouldn't. What I or
others are trying to understand is that if there are jobs that
desperately need to be filled by EA people. And looking at the many
jobs in govt, many agencies, many academia institutions doesn't cut it
enough. On top of many jobs, there must be less EA people getting
those jobs at the moment. So the claim should be There are jobs in
govt that are not being taken up by EA souls. But others who have no
inclination towards making the world better. 

## Reflection

I forget to check the example against the definition correctly. In the
[last post](http://agent18.github.io/is-ea-bottlenecked-3.html), I mainly looked only at the first definition. So the
claim was "EA orgs are able to find people with specific skills at the
end of the hiring round". For this what I needed was to check hiring
rounds and if they hired those specific skills' people that they
needed. What I did implicitly is look at the rejection rates, number
of people who applied, comments on the how good the talent pool was,
how many people made it to the work trials etc... And somehow
"holistically" got the impression that EA orgs are able to find the
people they set out to need. It looks to me that I answered the claim
by "FEEL". I seem to have factored in rejection rates, but I had no
idea of what rejection rate was high or low. I looked at how many
people made it to the work trials and whatever I saw was "good enough"
somehow. I should have been explicit about all these proxies and
should have tested them separately.

Secondly, I forget that when I make claims about the demand for
onions, that I should look at the demand for onions for a given
price. For the claim, "EA orgs have a lot of candidates to choose
from", I could look at the Rejections Rates and brush off the
claim. But it appears that it is merely not enough to look at RR, but
RR out of a set of good candidates or perhaps RR separately and that a
"good number of candidates" were "good". I am missing 'skils per
70k`$`', 'rejection rate per x years of experience or per set of "good
candidates"'. It took me a while to realize this (2 hrs). And
understood why this was in the beginning: "RR for Phd candidates".

Thirdly, I am too soon to judge an example as satisfying the
claim. When I heard an example that DoD JAIC was looking for 100s of
people for the claim, "EA needs people in AI Policy", I was like wow,
this is a great example, showing that there are many jobs in the govt,
for EA people. The assumption I made was that EA-identified people
make "much better impact" at these positions than other people (which
I am not sure is true). Additionally, Dod JAIC was looking for all
sorts of people, not just AI Policy people. 2 years since they seem to
have hired 40 people (as per LinkedIn) and a conservative estimate
suggests that there would be 10 people in policy out of that across
all seniorities. 

Fourthly, I was unable to communicate how and where the survey could
be better. Aaron told me that the survey already asks the very
question I am trying to answer. What more can a survey do. I agreed
with him. 

Fifthly, I forget I am out here to try to get the truth, not fucking
finish an essay that STM will not spit at. I really wish I paid
attention to how I was getting the truth. In the beginning it was just
looking at the definitions and checking them, but what I truly wanted
which hit me in  the end was this systematic thinking. For example,
First you check if people are hired. Second you check if these people
are as good as they set out to be. Third you check if there are many
of these people. That's it. Simple. building up. 

Sixthly, the discussion with many jobs in AI policy is so deep, been
spending hours and hours on it but yet I took it on face value when I
first saw it.

## thinking about rejection rates vs surveys

## given price DISCUSSION

## Mathivanan

Based on reading 80k for years I formed the impression as shared by
[EA applicant](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really):

> Hey you! You know, all these ideas that you had about making the
> world a better place, like working for Doctors without Borders?
> They probably aren’t that great. The long-term future is what
> matters. And that is not funding constrained, so earning to give is
> kind of off the table as well. But the good news is, we really,
> really need people working on these things. We are so talent
> constrained...--- [EA applicant in the EA Forum](https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really)

And looking at the *277 karma* this post got (*the highest of any post
on the Forum*), it might appear that a "lot of people" share(d) this
sentiment that EA orgs could potentially be seriously Talent
Constrained (TC).

A few months back I stumbled upon some articles in the [EA forum](https://forum.effectivealtruism.org/)
and to my surprise it appeared that some EA orgs were suggesting that
they were not TC. Until this point I don't think it occurred to me
that 80k' claims (particularly "EA is TC") could be wrong or I didn't
understand them, or they got lost in translation, or that I should
test it. Nevertheless, having seen orgs say otherwise, it felt like a
good idea to dig into it at least now.



## Rewriting the post

## todo

- Introduction (x)
- Opinions (x)
- Survey Says (x)
- Aggregaytion (x)
- Its a predicate situation (x)
- Evidence based protocol (?)
- Conclusion(?)
- reply to an STM (?)
- shit on 80000hours (?)

- rewrite the whole thing (2hrs)
- one last read (1hrs)
- spell check and finale(1hrs)
- write email to STM (1hr)
