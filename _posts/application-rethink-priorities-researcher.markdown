## Feedback from Happier
Lives Institute on things missing

Check **Happier Lives Institute feedback** on what I should have done
for that other question

> Your answer to the first part (internal validity) was really
> excellent (and one of the best).
>
> Your answer to the second part was weaker (this was true for
> almost every candidate). I would have loved to see some 'meta'
> comments on the overall strategy, e.g: What is going to be
> difficult about getting this information? What can we do to
> address these difficulties? What are the trade-offs we are
> having to make? What will the nonprofit's perspective be? As a
> manager, it's really helpful to be presented with a plan, but
> also why you reached this plan, with pointers to the decisions
> you've made and alternatives you could have taken.
>
> The fact you have less experience in the nonprofit/mental health
> sector also factored slightly into the decision (generally we
> choose ability over experience, but in this case, we have little
> time to train someone).

## Statistics

1. **Inferences to population** can be drawn if you pick from a random
   sample
   
   If you pick a set of tennis players at random, your conclusion
   holds for the entire tennis player population.
   
2. **Causal inference can be drawn** if you split the sample randomly
   into control and treatment group.

	Taking a bunch people at the mall (not at random), and assigning
    them randomly to control and treatment group.

3. **Confounding variables**:

4. **Good internal validity**: Blinding, random selection,
   randomization, study protocol, no experimental manipulation, e.g.,
   giving treatment to smokers only.
   
5. **Threaten internal validity**: Attrition, experimenter bias
   (eliminated through blinding), historical events, long time
   studies, repeated testing using same test, selection bias (motivation)
   
6. **External validity**: Replication, field experimentation, clear
   definition of inclusion and exclusion criteria defining the
   population, re-weighting groups that are not similar.

7. **Blinding**: double blind reviewers are less likely than single
   blind reviewers to accept papers from famous authors, top
   universities, and top companies.
   
**Dalys**

Lost years due to disability or death

https://www.charityentrepreneurship.com/blog/what-are-dalys-and-are-they-a-good-metric

**Internal validity**

[Link](https://web.archive.org/web/20210218051508/https://www.verywellmind.com/internal-and-external-validity-4584479
).

## All applications

Happier Lives Institute, Charity Entrepreneurship internship, and
Program Manager at OPP.

## application

https://web.archive.org/web/20210614134506/https://rethinkpriorities.applytojob.com/apply/hMArA0IVxM/Staff-Researcher-Global-Health-And-Development

## Questions to prep for

1. how to select based on study

2. What are the steps you would take

## Resume recycle what I sent for OPP

## stuff I wrote while biking

1. Cost per unit saved + uncertainty + age
Estamatws of other people and volunteers working... Compared to another place

Meta will the cost remain the same, what drives the cost..

1. Strength of evidence

Rcts
Assessing similarity or applicability of rct in another location.... Compare and let know uncertainty...

Future. Plans for evaluation

What to do when they are not random?

1. What is intervention who is it targetted toward
4.scalability neglectedness how many people can they reach

Willingness of people, 

1. Counterfactual estimates?
2. Which orgs are good? 
Dimension how you will calculate it and uncertainty? What are the difficulties

## final skeleton when exposed to 3 studies

1. Randomization (of treatment and control)

2. Random sample (from a distinct population)

3. systematic bias (one sex, one country, education level, recruitment
   strategy, reaches only people actively looking for help)
   
4. Confounding variables, season, time, historical events anything else?

5. Comment on blinding, long time studies, replication, existence of
   selection bias

6. Attrition rate from selection until the end

7. Long term effects

8. comparing initial set of people and attrition people

9. malpractices: less imputation, double blinded, experimenter bias,
   selection bias 

10. improvement suggestions: 

## What will I do in a given case (skeleton)

**Give meta comments**
- What is going to be difficult about getting this information? 
- What can we do to address these difficulties? 
- What are the trade-offs we are having to make? 
- What will the nonprofit's perspective be?
- As a manager, it's really helpful to be presented with a plan, but
also why you reached this plan, with pointers to the decisions you've
made and alternatives you could have taken.

**Dimensions**


1. Does it work in general?

	- effectiveness of intervention in general
	- populations targeted by said ORG and their characteristics
	- evidence that orgs giving the intervention work
		- reaches people intended
		- People use said intervention
		- it works in the long run


2. What do you get for your dollar?

	- cost per unit saved (DALY?)
	
	- other advantages not considered in cost (For example, our model
      does not include the short-term impact of non-fatal cases of
      malaria prevented on health or productivity,)

3. Scalability/neglectedness or current reach

	- Demand for the intervention, Current supply of intervention
	- current available funding
	- expected funding
	- Spending opportunities identified
	
4. counterfactual estimates

	- how does it compare to GiveWells best charities

5. Other factors

	- long lasting?
	- processes in place? (supply chain)
	- transparency
	
	

	
