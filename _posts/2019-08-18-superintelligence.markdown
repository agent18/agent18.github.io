---
layout: post
comments: true
title:  "Superintelligence wat waaat!"
date:    18-08-2019 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: false
---

## Mission #9. 

**Mail dated Aug 13,**

Great job on spending 29 hours in a week! *I recommend measuring rate
of phrases per hour.*

Overall, I didn't see you take on Superintelligence, which was the
mission. Please work on either that or stuff you feel *confused*
about. *Only failures matter* (apart from maintenance of existing
performance).

Note down patterns of failure, such as "X prefers A to B". Spend, say,
half your time searching for and practicing on examples of those
types. You can spend the rest of your practice time on new examples,
from which you will hopefully find other patterns of failure.

**Mail dated June 24,**

Mission #9: Your mission, should you choose to accept it, is to
concretely analyze the key claims in the book Superintelligence by
Nick Bostrom (the book mentioned in the Elon Musk tweet above). He's a
PhD at Oxford who's been writing about AI safety along with guys like
Eliezer for nearly two decades. The book has detailed arguments and
examples about all the topics like possible paths to
"superintelligence" (whatever that means), types of
"superintelligence", the control problem, etc.

No need to write "Question: " - doesn't seem to have changed your
answers.

Don't have to go sentence by sentence; *look at one key claim for each
section, usually the one in the first few paragraphs*, or one for each
paragraph if you feel it's an important section. For example:

> CHAPTER 2 Paths to superintelligence
>
> Machines are currently far inferior to humans in general
> intelligence. Yet one day (we have suggested) they will be
> superintelligent. How do we get from here to there? This chapter
> explores several conceivable technological paths. We look at
> artificial intelligence, whole brain emulation, biological
> cognition, and human-machine interfaces, as well as networks and
> organizations. We evaluate their different degrees of plausibility
> as pathways to superintelligence. The existence of multiple paths
> increases the probability that the destination can be reached via at
> least one of them.

The key claim is "How do we get from here to there? Answer: Artificial
intelligence, whole brain emulation, ..."

Feedback checklist:

1. Could it be that this claim has no any example at all? For example,
   "civilization is at stake".

2. Could this claim be false? Remember the "there is no doubting"
   example.

3. Does this claim say anything about "best" (need to compare against
   the entire set) or "most" (need to show it's the majority in the
   set) or "no" (need to show that nothing in the set matches)?

4. Did you stick to examples that are in the chapter itself? That way
   you don't have to search online for too long.

5. Did you use a running example for a technical phrase? There will be
   lots of new phrases in the book, like "convergent instrumental
   value" and "orthogonality thesis". Whenever you see them, you
   should recall whatever running example you've used.

6. If this is an "if-then" claim, did you either get a concrete
   example or mark it as having no example?

Short names: none; false; best; chapter; running; if-then.

Please refer to the checklist after every claim analysis to ensure
you're not making old mistakes. If you want to add to the checklist
based on mistakes found in past feedback, that's great.

## Feedback list used in this essay

## Chapter 1 History (22)

one key claim per section
For now I don't know which are my failures. 

In an attempt to keep the fire going. I would like to focus on 10
phrases an hour?

Let's see how that goes and refine this shit accordingly. I am
ready. Pandindian pandian.

- black for claims
- red for examples
- blue for conclusions
- yellow highlight for other "interesting stuff"

### Growth modes and big history (23)

> (History at the largest scale)[1], seems to exhibit (a sequence of
> distinct growth modes)[2], each much more rapid than (its predecessor)[3].

**Claims**: [1] seems to exhibit [2], each much more rapid than [3].

**Subject**: [2] exhibited in [1].

**Predicate**: much more rapid than [3]. 

**Example**: "A few hundred thousand years ago, in early human (or
hominid) prehistory, growth was so slow that it took on the order of
one million years for human productive capacity to increase
sufficiently to sustain an additional one million individuals living
at subsistence level. By 5000 bc, following the Agricultural
Revolution, the rate of growth had increased to the point where the
same amount of growth took just two centuries. Today, following the
Industrial Revolution, the world economy grows on average by that
amount every ninety minutes."

**Definition**: checks out.

**Checklist**: yes; true; none; chapter; not-running; none  

"However, the case for tak- ing seriously the prospect of a machine
intelligence revolution need not rely on curve-fitting exercises or
extrapolations from past economic growth. As we shall see, there are
stronger reasons for taking heed."

### Great expectations (2)

> (Machines matching humans in general intelligence)[1]—that is,
> possessing com- mon sense and an effective ability to learn, reason,
> and plan to meet complex information-processing challenges across a
> wide range of natural and abstract domains—have been expected since
> (the invention of computers in the 1940s)[2].

**Claims**: [1] has been expected since [2].

**Subject**: When [1] has been expected

**Predicate**:  since [2].

**Example**: *No example of someone expecting in 1940 in the book.*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none; ""  

> From the (fact that some individuals have overpredicted artificial
> intelligence in the past)[1], however, it does not follow that (AI is
> impossible or will never be developed)[2].

**Claims**: From [1], [2] does not follow.

**Subject**: The future as a result of [1].

**Predicate**: [2] wont happen.

**Example**: *No examples for future*

**Definition**: 

**Checklist**: no; neither; none; not-chapter; not-running; none; "predictions of the future";   

> The main reason (why progress has been slower than expected)[1] is that
> (the technical difficulties of constructing intelligent machines have
> proved greater than the pioneers foresaw)[2].

*because*

**Summary**

"The AI pioneers for the most part did not countenance the possibility that
their enterprise might involve risk.11 They gave no lip service—let alone seri-
ous thought—to any safety concern or ethical qualm related to the creation of
artificial minds and potential computer overlords: a lacuna that astonishes even
against the background of the era’s not-so-impressive standards of critical tech-
nology assessment."

### Seasons of hope and despair (6)

> In the (six decades since this brash beginning)[0], (the field of
> artificial intelligence)[1] has been through (periods of hype and
> high expectations alternating with periods of setback and
> disappointment)[2].

**Claims**: Since [0], [1] has been through [2].

**Subject**: [1], since [0]. 

**Predicate**: has been through [2]. 

**Example**: After the Dartmouth meeting, researchers built systems
like the Logic Theorist, which was able to prove most of the theorams
in the second chapter of WhiteHead and Russell's Principia
Mathematica, and even came up with one prood that was much more
elegant than the original.

Post 1970, funding decreased and skepticism increased.

*This seems to be the best one can do while giving examples. There are
claims in the example, but atleast we can ask the author what exactly
he meant when needed to investigate further.*

**Definition**: checks out!

**Checklist**: yes; true; none; chapter; not-running; none; 


**Combinatorial explosion**

> (The methods)[1] that produced (successes in the early demonstration systems)[2] often
> proved difficult to (extend to a wider variety of problems or to harder problem
> instances)[3].

**Claims**: [1] that produced [2] often proved [3].

**Subject**: Extension to a harder problem instances based on [2],

**Predicate**: often proved to be difficult

**Example**: "For instance, to prove a theorem that has a 5-line long
proof in a deduction system with one inference rule and 5 axioms, one
could simply enumerate the 3,125 possible combinations and check
each one to see if it delivers the intended conclusion", based on the
exhaustive search method.

"Proving a theorem with a 50-line proof does not take ten times longer
than proving a theorem that has a 5-line proof: rather, if one uses
exhaus- tive search, it requires combing through 5 50 ≈ 8.9 × 10 34
possible sequences—which is computationally infeasible even with the
fastest supercomputers."

**Definition**: checks out

**Checklist**: yes; true; often; chapter; not-running; none;  

**Summary?**

Graphical models and Bayesian statistics have become a shared focus of
research in many fields, including machine learning, statistical
physics, bioinformatics, combinatorial optimization, and communication
theory.


### State of the art (5)

> (Artificial intelligence)[1] already (outperforms human intelligence in many domains)[2].

**Claims**: [1] already does [2].

**Subject**: [1]. 

**Predicate**: already does [2]. 

**Example**: "2010: IBM’s Watson defeats the two all-time- greatest
human Jeopardy! champions, Ken Jennings and Brad Rutter. 51 Jeopardy!
is a tel- evised game show with trivia questions about history,
literature, sports, geography, pop culture, science, and other
topics. Questions are presented in the form of clues, and often
involve wordplay." --- Games

There are not other examples of [1] already [2], in the section. 

**Definition**: Does not check out, assuming gaming is just one domain
I need atleast one other domain where [1] has already [2].

**Checklist**: yes; false; many; chapter; not-running; none; "lack of examples"  

> These achievements might not seem impressive today. But this is
> because (our standards for what is impressive)[1] keep adapting to the
> (advances being made)[2].

**Claims**: [1] keep adapting to the [2]. 

**Subject**: [1] 

**Predicate**: keep adapting to [2]. 

**Example**: In late fifties: "if one could devise a successful chess
machine one would seem to have penetrated to the core of human
intellectual endeavor."

I don't know anyone who is amazed by a chess AI today. However

**Definition**: checks out!

**Checklist**: yes; false; none; not-chapter; not-running; none; "not
sure if this is because type of not"


### opinions about the future of machine intelligence (4)

> Progress on two major fronts—towards a more solid statistical and
> information- (theoretic foundation for machine learning on the one
> hand)[1], and (towards the practical and commercial success of various
> problem-specific or domain-specific applications on the other)[2]—has
> restored to AI research (some of its lost prestige)[3].

**Claims**: Progress on [1], and [2], has restored [3] to AI research.

**Subject**: Progress on [1] and [2].

**Predicate**: has restored [3] to AI research.

**Example**: *No examples in the section*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none; "no
examples in section" 

> One result of (this conservatism)[1] has been (increased concentration on
> “weak AI”—the variety devoted to providing aids to human thought—and
> away from “strong AI”—the variety that attempts to mechanize
> human-level intelligence)[2].

**Claims**: result of [1] has been [2].

**Subject**: Result of [1].

**Predicate**: has been [2]. 

**Example**: *no examples in the section*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none;
"not sure if this is because type"  


> (Expert opinions about the future of AI)[1] vary (wildly)[2]. 

**Claims**: [1] varies [2].

**Subject**: [1].

**Predicate**: varies [2].

**Example**: A survey documented [here](https://intelligence.org/files/PredictingAI.pdf) shows the prediction of
HLAI of "experts", ranging from 2020 to 2100.

**Definition**: checks out.

**Checklist**: yes; true; none; not-chapter; not-running; none  

**Summary**

Small sample sizes, selection biases, and—above all—the inherent unreliability
of the subjective opinions elicited mean that one should not read too much into
these expert surveys and interviews. They do not let us draw any strong conclu-
sion. But they do hint at a weak conclusion. They suggest that (at least in lieu of
better data or analysis) it may be reasonable to believe that human-level machine
intelligence has a fairly sizeable chance of being developed by mid-century, and
that it has a non-trivial chance of being developed considerably sooner or much
later; 



## Chapter 2 Paths to Superintelligence (26).
### Artificial intelligence (8)

> How do we get from here to there? AI is a conceivable technology
> path.

**Claims**: AI is a conceivable technology path to go from current to superintelligent.

**Subject**: AI

**Predicate**: is a conceivable technology path to go from current to superintelligent.

**Example**: ~~"blind evolutionary processes can produce human-level
general intelligence, since they have already done so at least
once. Evolutionary processes with foresight—that is, genetic programs
designed and guided by an intelligent human programmer—should be able
to achieve a similar outcome with far greater efficiency."~~

*These are reasons, more claims. You can't give examples for "could be"*

**Definition**: Also, what does conceivable even mean? How
would I know if it is conceivable. How would I know the definition?

**Checklist**: no; neither; none; not-chapter; not-running; none;
"future with no ex"; "definition unclear"

> (Evolutionary processes with foresight—that is, genetic programs)[1]
> designed and guided by (an intelligent human programmer)[2]—should be
> able to achieve a (similar outcome with far greater efficiency)[3].

**Claims**: [1] designed and guided by [2] should be able to achieve
[3].

**Subject**: [1] designed and guided by [2].

**Predicate**: should be able to achieve [3].

**Example**: ~~"If we were to simulate 10^25 neurons over a billion
years of evolution (longer than the existence of nervous systems as we
know them), and we allow our computers to run for one year, these
figures would give us a requirement in the range of 10^31–10^44
FLOPS. For comparison, China’s Tianhe-2, the world’s most powerful
supercomputer as of September 2013, provides only 3.39×10 16 FLOPS. In
recent decades, it has taken approximately 6.7 years for commodity
computers to increase in power by one order of magnitude. Even a
century of continued Moore’s law would not be enough to close this
gap"~~
 
*"Should" is hard to get an example for*, *This again talks about
some prediction for the future*

*If we assume the calculations scratched out above as evidence, then we
see the evolution is not possible within this century. But any
calculation is not an example, just like we don't consider [Elizebeth
Warren's statement](https://www.forbes.com/sites/zackfriedman/2019/06/17/elizabeth-warren-student-loan-debt-forgiveness/#60261e105e7b) of voiding all student debt and countering for
it via increasing taxes for the ultra millionaires*. 

*It's never been done before.*

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none;
"should"; "future with no ex";

> Another way of arguing for the (feasibility of artificial
> intelligence)[1] is by pointing to the (human brain )[2] and
> suggesting that we could use it as (a template for a machine
> intelligence)[3].

**Claims**: [1] can be done by using [2] as [3].

**Subject**: [1] using [2] as [3].

**Predicate**: can be done.

**Example**: ~~whole brain simulation, taking inspiration from brain,
neuromorphic approaches, recursive self-improvement~~

*There is no example for being superintelligent or even close to
superintelligent, let alone with whole brain emulation or taking
inspiration from the functioning of the brain*

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none;
"future with no ex"


**Summary**

"Lot of ways" to make SI from AI but there are currently 0 examples
for it in the section.

### Whole brain emulation (6)

**Claims**: We get from current to superintelligent by using Whole
brain Emulation.

**Subject**: That which will lead us from current to superintelligent

**Predicate**:  is  Whole brain emulation

**Example**: ~~"No brain has yet been emulated. Consider the humble
model organism Caenorhabditis elegans, which is a transparent
roundworm, about 1 mm in length, with 302 neurons. The complete
connectivity matrix of these neurons has been known since the
mid-1980s, when it was laboriously mapped out by means of slicing,
electron microscopy, and hand-labeling of specimens..."~~

There is no example of even a small organism whose brain is emulated currently.

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none;
"future with no ex"  

**Summary**

"Nevertheless, compared with the AI path to machine intelligence, whole
brain emulation is more likely to be preceded by clear omens since it
relies more on concrete observable technologies and is not wholly
based on theoretical insight."

### Biological cognition (8)

**Claims**: We get from current to superintelligent by using
biological cognition.

**Subject**: That which will lead us from current to superintelligent

**Predicate**: biological cognition

**Example**: ~~"Pre-implantation genetic diagnosis has already been
used during in vitro fertilization procedures to screen embryos
produced for monogenic disorders such as Huntington’s disease and for
predis- position to some late-onset diseases such as breast cancer."~~

**Definition**: -

**Checklist**: No; neither; none; not-chapter; not-running; none;
"future with no ex"  

### Brain-computer interfaces (4)

**Claims**: We get from current to superintelligent by using
Brain-computer interfaces.

**Subject**: That which will lead us from current to superintelligent

**Predicate**: brain-computer interfaces

**Example**: ~~"Impressive work on the rat hippocampus has dem-
onstrated the feasibility of a neural prosthesis that can enhance performance in a
simple working-memory task."~~

~~"This prosthesis can not only restore function when the normal
neural connection between the two neural areas is blockaded, but by
sending an especially clear token of a particular memory pattern to
the second area it can enhance the performance on the memory task
beyond what the rat is normally capable of."~~

**Definition**: -

**Checklist**: no; true; none; not-chapter; not-running; none; "future with no ex"  

### Networks and Organizations (4)

> (Another conceivable path to superintelligence)[1] is through the (gradual
> enhancement of networks and organizations that link individual
> human minds with one another and with various artifacts and bots)[2]

**Claims**: [1] is through [2].

**Subject**: [2].

**Predicate**: is [1].

**Example**: -

**Definition**: -

**Checklist**: no; true; none; not-chapter; not-running; none; "future
with no ex"

### Conclusion

There are many "possible paths". But all of them seem to be
predictions based on what all needs to be done. The author is claiming
that the gap to Superintelligence can be fixed if we do XYZ. For
example, they claim cyborgization of man will lead to
Superintelligence. Yet, the examples we see are the ones where
patients are able to communicate by moving a cursor on a
screen. Another example, was the rat whose performance was "enhanced"
in a simple working-memory task. What I fail to see is an example
showing glimmers of Superintelligence, i.e., something that can do
**many things** at **much higher performance** than current
humans/rats/whatever.

Yes computers can beat the shit out of humans in games. Great. but we
do not seem to consider this as super-intelligence. Based on the
examples I see above, the claims seem to not be met. Agree or
disagree? if so why? Everyone "could do" everything in theory, but
when testing a claim, we want examples. This is very similar to people
claiming "human civilization is at risk due to AI".

## Chapter 3

> This chapter identifies (3 different forms of Superintelligence)[1],
> and argues that they are, (in a practically relevant sense,
> equivalent)[2], practically relevant sense, equivalent. We also
> show that the (potential for intelligence in a machine substrate)[2] is
> vastly greater than (in a biological substrate)[4].

**Claims**: [1] are [2].

**Subject**: [1].

**Predicate**: are [2].

**Example**: ~~Superintelligence in any of these forms could, over
time, develop the technology necessary to create any of the others.~~

I don't have any examples for this other than a claim to support
this. And I have no way of testing this "example claim" as well, as it
has SI as subject, for which I have zero examples.

**Definition**: -

**Checklist**: yes; false; none; not-chapter; not-running; none  

**Claims**: [3] is greater than [4].

**Subject**: [3] compared to [4].

**Predicate**: is greater.

**Example**: ~~"Biological neurons operate at a peak speed of about 200
Hz, a full seven orders of magnitude slower than a modern
microprocessor (~ 2 GHz)"~~

There are several more "advantages for digital intelligence", but I
don't think it helps. Because, "potential" seems to be talking about
the future, I don't think I can test it. Just like I can't test "I
have the potential to become CEO one day". However I can test "Sundar
Pichai" has the potential to become the CEO of Google".

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none; "future with no ex" 

> (Many machines and nonhuman animals)[1] already perform (at superhuman
> levels)[2] in (narrow domains)[3]. Bats interpret sonar signals better than
> man, calculators outperform us in arithmetic, and chess programs
> beat us in chess.

**Claims**: [1] already perform [2] in [3].

**Subject**: What [1], does.

**Predicate**: perform at [2] in [3].

**Example**: "Google’s AI AlphaGo has done it again: it’s defeated Ke
Jie, the world’s number one Go player, in the first game of a
three-part match."

**Definition**: I don't understand the definition "superhuman
levels". If we assume it means way better than the average human, then
yes the definition checks out.

**Checklist**: yes; neither; none; not-chapter; not-running; none;
"definition unclear" 

### Speed Superintelligence

> Because of this apparent time dilation of the material world, a
> (speed superintelligence)[1] would prefer to (work with digital
> objects)[2].

**Claims**: [1] would prefer to [2].

**Subject**: What [1] does.

**Predicate**: would prefer to [2].

**Example**: No example

**Definition**: Also no idea how to test would prefer to

**Checklist**: no; neither; none; not-chapter; not-running; none;
"future with no ex"; "would prefer to"  

> (The speed of light)[1] becomes an (increasingly important
> constraint)[2] as (minds get faster)[3], since (faster minds face
> greater opportunity costs in the use of their time for traveling or
> communicating over long distances)[4]. Light is roughly a million
> times faster than a jet plane, so it would take a digital agent with
> a mental speedup of 1,000,000× about the same amount of subjective
> time to travel across the globe as it does a contemporary human
> journeyer. Dialing somebody long distance would take as long as
> getting there “in person,” though it would be cheaper as a call
> wouldrequire less bandwidth.

*I don't understand what they are trying to say here with this
paragraph. Why would it take a digital agent with a mental speedup of
one millx, about the same amount of "subjective time" to travel across
the globe as it does a contemporary human journeyer. What is
subjective time even mean?*

**Claims**: [1] becomes [2] as [3], ~~since [4].~~

**Subject**: [1] as [3].

**Predicate**: becomes [2]. 

**Example**: No examples here.

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none; "no
examples"; '

### Collective Superintelligence

> (Collective intelligence)[1] excels at (solving problems that can be
> readily broken into parts)[2] such that (solutions to sub-problems
> can be pursued in parallel and verified independently)[3]. Tasks
> like building a space shuttle or operating a hamburger franchise
> offer myriad opportunities for division of labor: different
> engineers work on different components of the spacecraft; different
> staffs operate different restaurants.

**Claims**: [1] excels at [2] such that [3].

**Subject**: What [1] does.

**Predicate**: excels at [2] such that [3].

**Example**: People working together on building a space shuttle at
say NASA.

**Definition**: Does it excel though? compared to what? *Not sure if
the claim is not testable or if the definition is unclear or I am
supposed to assume something to compare it with.*

**Checklist**: yes; neither; none; not-chapter; not-running; none; "A
excels at B"; "failed"  

> Collective superintelligence could be either loosely or tightly
> integrated.  To illustrate a case of loosely integrated collective
> superintelligence, imagine a planet, MegaEarth, which has the same
> level of communication and coordination technologies that we
> currently have on the real Earth but with a population one million
> times as large. With such a huge population, the total intellectual
> work- force on MegaEarth would be correspondingly larger than on our
> planet. Suppose that a scientific genius of the caliber of a Newton
> or an Einstein arises at least once for every 10 billion people:
> then on MegaEarth there would be 700,000 such geniuses living
> contemporaneously, alongside proportionally vast multitudes of
> slightly lesser talents. (New ideas and technologies)[1] would be
> developed at (a furious pace)[2], and (global civilization on
> MegaEarth)[3] would constitute (a loosely integrated collective
> superintelligence.)[4]

**Claims**: [1] would be developed at [2] and [3] would constitute
[4].

**Subject**: What [1] would develop at

**Predicate**: [2].

**Example**: *Would be*

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none; "would be"; "future with no ex"  

**Claims**: [3] would constitute [4].

**Subject**: What [3] would.

**Predicate**: constitute [4].

**Example**: "would"

**Definition**: Not sure if I have an example I would be able to test
if it constitute [4]. I don't think I know what [4] could look like. I
have a feeling.

**Checklist**: yes; false; none; not-chapter; not-running; none;
"future with no ex"; "would"; "definition unclear";"failed" 

### Quality Superintelligence

> (Such examples)[0] show that (normal human adults)[1] have a range of
> (remarkable cognitive talents)[2] that are not (simply a function of
> possessing a sufficient amount of general neural processing power)[3] or
> (even a sufficient amount of general intelligence: specialized
> neural circuitry is also needed.)[4]

*This one I read a few times, and had no idea wtf NB is talking
about. NB is making me furious in many cases, just by not providing
examples and hanging on to abstract bullshit. Such a bastard he
is. How does he expect people to read this shit? especially if they
don't have a background on this and worst of all, he seems to have
extensively used the thesaurus to sound cool. So many words I had to
look up. Why not write it like Harry Potter? huh? why not? eugenics,
affliction, adduced, intractable, circumscribed, "dogs walking on hind
legs, docility"*


**Claims**: [0] shows that [1] have a range of [2] that are not [3]

**Subject**: [1].

**Predicate**: have range of [2] that are not [3].

**Example**: *People with autism spectrum disorders who may have
striking deficits in "social cognition" while function well in other
"cognitive domains"*

This above is hardly an example. Let's consider [this](https://youtu.be/zNGjdYY7WVE?t=142), where we
see a guy with autism making highly detailed drawings of scenery, for
an actual example to test the predicate on.

**Definition**: *how are these "examples" even talking about normal
human adults?*. *For sure the example doesn't seem to hint at giving
any information on [3]. I probably have to go deep into the subject to
test this example.*

**Checklist**: yes; false; none; not-chapter; not-running; none; "no
example in chapter"; 

**Claims**: [1] have a range of [2] that are not [4].

ditto!

*He just loves to use labels after labels* *Sufficient?* *How do I
determine that?*

### Direct and indirect reach

> (Superintelligence in any of these forms)[1] could, over time,
> develop (the technology necessary to create any of the
> others)[2]. The (indirect reaches of these three forms of
> superintelligence)[3] are therefore (equal)[4]. In that sense, the
> (indirect reach of current human intelligence)[5] is also in the same
> equivalence class, under the supposition that we are able eventually
> to create some form of superintelligence.

**Claims**: [1] could over time develop [2].

**Subject**: [1] over time.

**Predicate**: could develop [2].

**Example**: *Could*. Also *I have no example for [1].*

**Definition**: -

**Checklist**: no; neither; none; not-chapter; not-running; none;
"future with no ex"; "could"

**Claims**: [3] are all equal.

**Subject**: [3].

**Predicate**: are all equal.

**Example**: *No example for subject*

**Definition**: - 

**Checklist**: no; neither; none; not-chapter; not-running; none;
"No example"; 

**Claims**: [5] also same as [3].

**Subject**: [5].

**Predicate**: also same as [3]. 

**Example**: no example

**Definition**: don't understand the predicate either.

**Checklist**: no; neither; none; not-chapter; not-running; none; "no
ex"

> And one can speculate that the (tardiness and wobbliness of
> humanity’s progress)[1] on (many of the “eternal problems” of philosophy)[2]
> are due to the (unsuitability of the human cortex for philosophical
> work.)[3]

**Claims**: [1] on [2] are due to [3].

**Subject**: [1] on [2]. 

**Predicate**: are due to [3].

**Example**: *because* + *no example*

**Definition**: 

**Checklist**: no; neither; none; not-chapter; not-running; none; "no example"

### Sources of advantage for digital intelligence

> Minor changes in (brain volume)[1] and (wiring)[2] can have (major
> consequences)[3].

**Claims**: Minor changes in [1] and [2] can have [3].

**Subject**: Minor changes in [1] and [2]. 

**Predicate**: can have [3].

**Example**: ~~"intellectual and technological achievements of humans
with those of other apes"~~ The scratched part is not an example.

**Definition**: -

**Checklist**: yes; false; none; not-chapter; not-running; none;
"hard"; "causation type?"; "failed"


## Data science stuff

### Attempt 1 

- what jblevins said... look at something and identify where you suck


## Notes

- I feel that I am not taking too seriously every single sentence,
  unless it is claims of importance.. For example they talk abotu IJ
  GOOd an what he expects to happen in the future.
  
  Who cares? What are the claims? are there examples for it? moving on!
## decide the plan today!

## Statistics

| chapter | time | phrases | dist | claims | pages | mins/phr | mins/page |
|---------|------|---------|------|--------|-------|----------|-----------|
| 2.2     | 10   | 2       | 1    | 1      | (6)   | 5        |           |
| 2.3     | 60   |         | 5    |        | 8     |          | 7.5       |
| 2.3     | 21   | 2       | 0    |        | (8)   | 10       |           |
| 2.4     | 20   |         | 1    |        | 4     |          | 6.25      |
| 2.5     | 15   |         | 1    |        | 3     | 5        |           |
| 2.4 2.5 | 20   |         | 2    |        |       | 4        |           |
| 3       | 27   |         |      |        | 5     |          | 5.4       |
| 3       | 60   |         | 13   |        | 6     |          | 10        |
| 3       | 159  | 34      | 9    |        |       | 4.67     |           |

	
do excercise
## todo

- stm reply ages back on less wrong!
- work on failures
- which content to work on? the book or jblevins stuff?

- **identify failures from previous post and check if we failed?**

Identify patterns and inform failure! Make simple statistic on number
of failures over 133 claims.. type of failures and claims.


