---
layout: post
comments: true
title:  "Superintelligence wat waaat!"
date:    18-08-2019 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: false
---

## Mission #9. 

**Mail dated Aug 13,**

Great job on spending 29 hours in a week! *I recommend measuring rate
of phrases per hour.*

Overall, I didn't see you take on Superintelligence, which was the
mission. Please work on either that or stuff you feel *confused*
about. *Only failures matter* (apart from maintenance of existing
performance).

Note down patterns of failure, such as "X prefers A to B". Spend, say,
half your time searching for and practicing on examples of those
types. You can spend the rest of your practice time on new examples,
from which you will hopefully find other patterns of failure.

**Mail dated June 24,**

Mission #9: Your mission, should you choose to accept it, is to
concretely analyze the key claims in the book Superintelligence by
Nick Bostrom (the book mentioned in the Elon Musk tweet above). He's a
PhD at Oxford who's been writing about AI safety along with guys like
Eliezer for nearly two decades. The book has detailed arguments and
examples about all the topics like possible paths to
"superintelligence" (whatever that means), types of
"superintelligence", the control problem, etc.

No need to write "Question: " - doesn't seem to have changed your
answers.

Don't have to go sentence by sentence; *look at one key claim for each
section, usually the one in the first few paragraphs*, or one for each
paragraph if you feel it's an important section. For example:

> CHAPTER 2 Paths to superintelligence
>
> Machines are currently far inferior to humans in general
> intelligence. Yet one day (we have suggested) they will be
> superintelligent. How do we get from here to there? This chapter
> explores several conceivable technological paths. We look at
> artificial intelligence, whole brain emulation, biological
> cognition, and human-machine interfaces, as well as networks and
> organizations. We evaluate their different degrees of plausibility
> as pathways to superintelligence. The existence of multiple paths
> increases the probability that the destination can be reached via at
> least one of them.

The key claim is "How do we get from here to there? Answer: Artificial
intelligence, whole brain emulation, ..."

Feedback checklist:

1. Could it be that this claim has no any example at all? For example,
   "civilization is at stake".

2. Could this claim be false? Remember the "there is no doubting"
   example.

3. Does this claim say anything about "best" (need to compare against
   the entire set) or "most" (need to show it's the majority in the
   set) or "no" (need to show that nothing in the set matches)?

4. Did you stick to examples that are in the chapter itself? That way
   you don't have to search online for too long.

5. Did you use a running example for a technical phrase? There will be
   lots of new phrases in the book, like "convergent instrumental
   value" and "orthogonality thesis". Whenever you see them, you
   should recall whatever running example you've used.

6. If this is an "if-then" claim, did you either get a concrete
   example or mark it as having no example?

Short names: none; false; best; chapter; running; if-then.

Please refer to the checklist after every claim analysis to ensure
you're not making old mistakes. If you want to add to the checklist
based on mistakes found in past feedback, that's great.

## Feedback list used in this essay

## Chapter 1 History (22)

one key claim per section
For now I don't know which are my failures. 

In an attempt to keep the fire going. I would like to focus on 10
phrases an hour?

Let's see how that goes and refine this shit accordingly. I am
ready. Pandindian pandian.

- black for claims
- red for examples
- blue for conclusions
- yellow highlight for other "interesting stuff"

### Growth modes and big history (23)

> (History at the largest scale)[1], seems to exhibit (a sequence of
> distinct growth modes)[2], each much more rapid than (its predecessor)[3].

**Claims**: [1] seems to exhibit [2], each much more rapid than [3].

**Subject**: [2] exhibited in [1].

**Predicate**: much more rapid than [3]. 

**Example**: "A few hundred thousand years ago, in early human (or
hominid) prehistory, growth was so slow that it took on the order of
one million years for human productive capacity to increase
sufficiently to sustain an additional one million individuals living
at subsistence level. By 5000 bc, following the Agricultural
Revolution, the rate of growth had increased to the point where the
same amount of growth took just two centuries. Today, following the
Industrial Revolution, the world economy grows on average by that
amount every ninety minutes."

**Definition**: checks out.

**Checklist**: yes; true; none; chapter; not-running; none  

"However, the case for tak- ing seriously the prospect of a machine
intelligence revolution need not rely on curve-fitting exercises or
extrapolations from past economic growth. As we shall see, there are
stronger reasons for taking heed."

### Great expectations (2)

> (Machines matching humans in general intelligence)[1]—that is,
> possessing com- mon sense and an effective ability to learn, reason,
> and plan to meet complex information-processing challenges across a
> wide range of natural and abstract domains—have been expected since
> (the invention of computers in the 1940s)[2].

**Claims**: [1] has been expected since [2].

**Subject**: When [1] has been expected

**Predicate**:  since [2].

**Example**: *No example of someone expecting in 1940 in the book.*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none; ""  

> From the (fact that some individuals have overpredicted artificial
> intelligence in the past)[1], however, it does not follow that (AI is
> impossible or will never be developed)[2].

**Claims**: From [1], [2] does not follow.

**Subject**: The future as a result of [1].

**Predicate**: [2] wont happen.

**Example**: *No examples for future*

**Definition**: 

**Checklist**: no; neither; none; not-chapter; not-running; none; "predictions of the future";   

> The main reason (why progress has been slower than expected)[1] is that
> (the technical difficulties of constructing intelligent machines have
> proved greater than the pioneers foresaw)[2].

*because*

**Summary**

"The AI pioneers for the most part did not countenance the possibility that
their enterprise might involve risk.11 They gave no lip service—let alone seri-
ous thought—to any safety concern or ethical qualm related to the creation of
artificial minds and potential computer overlords: a lacuna that astonishes even
against the background of the era’s not-so-impressive standards of critical tech-
nology assessment."

### Seasons of hope and despair (6)

> In the (six decades since this brash beginning)[0], (the field of
> artificial intelligence)[1] has been through (periods of hype and
> high expectations alternating with periods of setback and
> disappointment)[2].

**Claims**: Since [0], [1] has been through [2].

**Subject**: [1], since [0]. 

**Predicate**: has been through [2]. 

**Example**: After the Dartmouth meeting, researchers built systems
like the Logic Theorist, which was able to prove most of the theorams
in the second chapter of WhiteHead and Russell's Principia
Mathematica, and even came up with one prood that was much more
elegant than the original.

Post 1970, funding decreased and skepticism increased.

*This seems to be the best one can do while giving examples. There are
claims in the example, but atleast we can ask the author what exactly
he meant when needed to investigate further.*

**Definition**: checks out!

**Checklist**: yes; true; none; chapter; not-running; none; 


**Combinatorial explosion**

> (The methods)[1] that produced (successes in the early demonstration systems)[2] often
> proved difficult to (extend to a wider variety of problems or to harder problem
> instances)[3].

**Claims**: [1] that produced [2] often proved [3].

**Subject**: Extension to a harder problem instances based on [2],

**Predicate**: often proved to be difficult

**Example**: "For instance, to prove a theorem that has a 5-line long
proof in a deduction system with one inference rule and 5 axioms, one
could simply enumerate the 3,125 possible combinations and check
each one to see if it delivers the intended conclusion", based on the
exhaustive search method.

"Proving a theorem with a 50-line proof does not take ten times longer
than proving a theorem that has a 5-line proof: rather, if one uses
exhaus- tive search, it requires combing through 5 50 ≈ 8.9 × 10 34
possible sequences—which is computationally infeasible even with the
fastest supercomputers."

**Definition**: checks out

**Checklist**: yes; true; often; chapter; not-running; none;  

**Summary?**

Graphical models and Bayesian statistics have become a shared focus of
research in many fields, including machine learning, statistical
physics, bioinformatics, combinatorial optimization, and communication
theory.


### State of the art (5)

> (Artificial intelligence)[1] already (outperforms human intelligence in many domains)[2].

**Claims**: [1] already does [2].

**Subject**: [1]. 

**Predicate**: already does [2]. 

**Example**: "2010: IBM’s Watson defeats the two all-time- greatest
human Jeopardy! champions, Ken Jennings and Brad Rutter. 51 Jeopardy!
is a tel- evised game show with trivia questions about history,
literature, sports, geography, pop culture, science, and other
topics. Questions are presented in the form of clues, and often
involve wordplay." --- Games

There are not other examples of [1] already [2], in the section. 

**Definition**: Does not check out, assuming gaming is just one domain
I need atleast one other domain where [1] has already [2].

**Checklist**: yes; false; many; chapter; not-running; none; "lack of examples"  

> These achievements might not seem impressive today. But this is
> because (our standards for what is impressive)[1] keep adapting to the
> (advances being made)[2].

**Claims**: [1] keep adapting to the [2]. 

**Subject**: [1] 

**Predicate**: keep adapting to [2]. 

**Example**: In late fifties: "if one could devise a successful chess
machine one would seem to have penetrated to the core of human
intellectual endeavor."

I don't know anyone who is amazed by a chess AI today. However

**Definition**: checks out!

**Checklist**: yes; false; none; not-chapter; not-running; none; "not
sure if this is because type of not"


### opinions about the future of machine intelligence (4)

> Progress on two major fronts—towards a more solid statistical and
> information- (theoretic foundation for machine learning on the one
> hand)[1], and (towards the practical and commercial success of various
> problem-specific or domain-specific applications on the other)[2]—has
> restored to AI research (some of its lost prestige)[3].

**Claims**: Progress on [1], and [2], has restored [3] to AI research.

**Subject**: Progress on [1] and [2].

**Predicate**: has restored [3] to AI research.

**Example**: *No examples in the section*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none; "no
examples in section" 

> One result of (this conservatism)[1] has been (increased concentration on
> “weak AI”—the variety devoted to providing aids to human thought—and
> away from “strong AI”—the variety that attempts to mechanize
> human-level intelligence)[2].

**Claims**: result of [1] has been [2].

**Subject**: Result of [1].

**Predicate**: has been [2]. 

**Example**: *no examples in the section*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none;
"not sure if this is because type"  


> (Expert opinions about the future of AI)[1] vary (wildly)[2]. 

**Claims**: [1] varies [2].

**Subject**: [1].

**Predicate**: varies [2].

**Example**: A survey documented [here](https://intelligence.org/files/PredictingAI.pdf) shows the prediction of
HLAI of "experts", ranging from 2020 to 2100.

**Definition**: checks out.

**Checklist**: yes; true; none; not-chapter; not-running; none  

**Summary**

Small sample sizes, selection biases, and—above all—the inherent unreliability
of the subjective opinions elicited mean that one should not read too much into
these expert surveys and interviews. They do not let us draw any strong conclu-
sion. But they do hint at a weak conclusion. They suggest that (at least in lieu of
better data or analysis) it may be reasonable to believe that human-level machine
intelligence has a fairly sizeable chance of being developed by mid-century, and
that it has a non-trivial chance of being developed considerably sooner or much
later; 



## Chapter 2 Paths to Superintelligence (26).
### Artificial intelligence (8)

> How do we get from here to there? AI is a conceivable technology
> path.

**Claims**: AI is a conceivable technology path to go from current to superintelligent.

**Subject**: AI

**Predicate**: is a conceivable technology path to go from current to superintelligent.

**Example**: ~~"blind evolutionary processes can produce human-level general
intelligence, since they have already done so at least once. Evolutionary processes
with foresight—that is, genetic programs designed and guided by an intelligent
human programmer—should be able to achieve a similar outcome with far greater
efficiency."~~ 

*These are reasons, more claims. You can't give examples for "could",
for the future.*

**Definition**: What the hell does conceivable even mean? How would I
know if it is conceivable. How would I know the definition? huh? What
is the 

**Checklist**: No; neither; none; not-chapter; not-running; none; "The
future of nothing"; "definition unclear"


> (Evolutionary processes with foresight—that is, genetic programs)[1]
> designed and guided by (an intelligent human programmer)[2]—should be
> able to achieve a (similar outcome with far greater efficiency)[3].

**Claims**: [1] designed and guided by [2] should be able to achieve




### Whole brain emulation (6)
### Biological cognition (8)
### Brain-computer interfaces (4)
### Networks and Organizations (4)
## Notes

- I feel that I am not taking too seriously every single sentence,
  unless it is claims of importance.. For example they talk abotu IJ
  GOOd an what he expects to happen in the future. 
  
  Who cares? What are the claims? are there examples for it? moving on!
## decide the plan today!

## Statistics


