---
layout: post
comments: true
title:  "Superintelligence wat waaat!"
date:    18-08-2019 
categories: posts
tags: DP, feedback, examples
permalink: /:title.html
published: false
---

## Mission #9. 

**Mail dated Aug 13,**

Great job on spending 29 hours in a week! *I recommend measuring rate
of phrases per hour.*

Overall, I didn't see you take on Superintelligence, which was the
mission. Please work on either that or stuff you feel *confused*
about. *Only failures matter* (apart from maintenance of existing
performance).

Note down patterns of failure, such as "X prefers A to B". Spend, say,
half your time searching for and practicing on examples of those
types. You can spend the rest of your practice time on new examples,
from which you will hopefully find other patterns of failure.

**Mail dated June 24,**

Mission #9: Your mission, should you choose to accept it, is to
concretely analyze the key claims in the book Superintelligence by
Nick Bostrom (the book mentioned in the Elon Musk tweet above). He's a
PhD at Oxford who's been writing about AI safety along with guys like
Eliezer for nearly two decades. The book has detailed arguments and
examples about all the topics like possible paths to
"superintelligence" (whatever that means), types of
"superintelligence", the control problem, etc.

No need to write "Question: " - doesn't seem to have changed your
answers.

Don't have to go sentence by sentence; *look at one key claim for each
section, usually the one in the first few paragraphs*, or one for each
paragraph if you feel it's an important section. For example:

> CHAPTER 2 Paths to superintelligence
>
> Machines are currently far inferior to humans in general
> intelligence. Yet one day (we have suggested) they will be
> superintelligent. How do we get from here to there? This chapter
> explores several conceivable technological paths. We look at
> artificial intelligence, whole brain emulation, biological
> cognition, and human-machine interfaces, as well as networks and
> organizations. We evaluate their different degrees of plausibility
> as pathways to superintelligence. The existence of multiple paths
> increases the probability that the destination can be reached via at
> least one of them.

The key claim is "How do we get from here to there? Answer: Artificial
intelligence, whole brain emulation, ..."

Feedback checklist:

1. Could it be that this claim has no any example at all? For example,
   "civilization is at stake".

2. Could this claim be false? Remember the "there is no doubting"
   example.

3. Does this claim say anything about "best" (need to compare against
   the entire set) or "most" (need to show it's the majority in the
   set) or "no" (need to show that nothing in the set matches)?

4. Did you stick to examples that are in the chapter itself? That way
   you don't have to search online for too long.

5. Did you use a running example for a technical phrase? There will be
   lots of new phrases in the book, like "convergent instrumental
   value" and "orthogonality thesis". Whenever you see them, you
   should recall whatever running example you've used.

6. If this is an "if-then" claim, did you either get a concrete
   example or mark it as having no example?

Short names: none; false; best; chapter; running; if-then.

Please refer to the checklist after every claim analysis to ensure
you're not making old mistakes. If you want to add to the checklist
based on mistakes found in past feedback, that's great.

## Feedback list used in this essay

## Chapter 1 History (22)

one key claim per section
For now I don't know which are my failures. 

In an attempt to keep the fire going. I would like to focus on 10
phrases an hour?

Let's see how that goes and refine this shit accordingly. I am
ready. Pandindian pandian.

- black for claims
- red for examples
- blue for conclusions
- yellow highlight for other "interesting stuff"

### Growth modes and big history (23)

> (History at the largest scale)[1], seems to exhibit (a sequence of
> distinct growth modes)[2], each much more rapid than (its predecessor)[3].

**Claims**: [1] seems to exhibit [2], each much more rapid than [3].

**Subject**: [2] exhibited in [1].

**Predicate**: much more rapid than [3]. 

**Example**: "A few hundred thousand years ago, in early human (or
hominid) prehistory, growth was so slow that it took on the order of
one million years for human productive capacity to increase
sufficiently to sustain an additional one million individuals living
at subsistence level. By 5000 BC, following the Agricultural
Revolution, the rate of growth had increased to the point where the
same amount of growth took just two centuries. Today, following the
Industrial Revolution, the world economy grows on average by that
amount every ninety minutes."

**Definition**: checks out.

**Checklist**: yes; true; 

---

<!-- "However, the case for taking seriously the prospect of a machine -->
<!-- intelligence revolution need not rely on curve-fitting exercises or -->
<!-- extrapolations from past economic growth. As we shall see, there are -->
<!-- stronger reasons for taking heed." -->

### Great expectations (2)

> (Machines matching humans in general intelligence)[1]—that is,
> possessing common sense and an effective ability to learn, reason,
> and plan to meet complex information-processing challenges across a
> wide range of natural and abstract domains—have been expected since
> (the invention of computers in the 1940s)[2].

**Claims**: [1] has been expected since [2].

**Subject**: When [1] has been expected

**Predicate**:  since [2].

**Example**: *No example of someone expecting in 1940 in the book.*

**Definition**: -

**Checklist**: yes; neither; 
*no-example*;

---

> From the (fact that some individuals have overpredicted artificial
> intelligence in the past)[1], however, it does not follow that (AI is
> impossible or will never be developed)[2].

**Claims**: AI is not impossible or could be developed in the future

**Checklist**: no; neither;
*future-with-no-ex*;

---

**Claims**: From [1], [2] does not follow.

**Subject**: The future as a result of [1].

**Predicate**: [2] wont happen.

**Example**: *no-example*; Do not know if it is possible to give an
example for this.

**Definition**: -

**Checklist**: no; neither;;;; if
*no-example*; *failed*; *If-A-B-does-not-follow*; *failed* (don't know
if it is possible to give example for this)

---

> The main reason (why progress has been slower than expected)[1] is that
> (the technical difficulties of constructing intelligent machines have
> proved greater than the pioneers foresaw)[2].

*because*

**Summary**

"The AI pioneers for the most part did not countenance the possibility
that their enterprise might involve risk. They gave no lip service—let
alone serious thought—to any safety concern or ethical qualm related
to the creation of artificial minds and potential computer overlords:
a lacuna that astonishes even against the background of the era’s
not-so-impressive standards of critical technology assessment."

### Seasons of hope and despair (6)

> In the (six decades since this brash beginning)[0], (the field of
> artificial intelligence)[1] has been through (periods of hype and
> high expectations alternating with periods of setback and
> disappointment)[2].

**Claims**: Since [0], [1] has been through [2].

**Subject**: [1], since [0]. 

**Predicate**: has been through [2]. 

**Example**: After the Dartmouth meeting, researchers built systems
like the Logic Theorist, which was able to prove most of the theorems
in the second chapter of WhiteHead and Russell's Principia
Mathematica, and even came up with one proof that was much more
elegant than the original.

Post 1970, funding decreased and skepticism increased.

*This seems to be the best one can do while giving examples. There are
claims in the example, but atleast we can ask the author what exactly
he meant when needed to investigate further.*

**Definition**: checks out!

**Checklist**: yes; true; 

---

<!-- **Combinatorial explosion** -->

> (The methods)[1] that produced (successes in the early demonstration
> systems)[2] often proved difficult to (extend to a wider variety of
> problems or to harder problem instances)[3].

**Claims**: [1] that produced [2] often proved [3].

**Subject**: Extension to harder problems based on [2],

**Predicate**: often proved to be difficult

**Example**: "For instance, to prove a theorem that has a 5-line long
proof in a deduction system with one inference rule and 5 axioms, one
could simply enumerate the 3,125 possible combinations and check
each one to see if it delivers the intended conclusion", based on the
exhaustive search method.

"Proving a theorem with a 50-line proof does not take ten times longer
than proving a theorem that has a 5-line proof: rather, if one uses
exhaustive search, it requires combing through `5^50 ≈ 8.9 × 10^34`
possible sequences—which is computationally infeasible even with the
fastest supercomputers."

**Definition**: checks out!

**Checklist**: yes; true; 
*often*; *failed*

---

<!-- **Summary** -->

<!-- Graphical models and Bayesian statistics have become a shared focus of -->
<!-- research in many fields, including machine learning, statistical -->
<!-- physics, bioinformatics, combinatorial optimization, and communication -->
<!-- theory. -->

### State of the art (5)

> (Artificial intelligence)[1] already (outperforms human intelligence in many domains)[2].

**Claims**: [1] already does [2].

**Subject**: [1]. 

**Predicate**: already does [2]. 

**Example**: "2010: IBM’s Watson defeats the two all-time-greatest
human Jeopardy! champions, Ken Jennings and Brad Rutter. Jeopardy!
is a televised game show with trivia questions about history,
literature, sports, geography, pop culture, science, and other
topics. Questions are presented in the form of clues, and often
involve wordplay." --- Games

There are not other examples of [1] already [2], in the section. 

**Definition**: Checks out for one domain (gaming) atleast!

**Checklist**: yes; true;

---

> These achievements might not seem impressive today. But this is
> because (our standards for what is impressive)[1] keep adapting to the
> (advances being made)[2].

**Claims**: [1] keep adapting to the [2]. 

**Subject**: [1] 

**Predicate**: keep adapting to [2]. 

**Example**: In late fifties: "if one could devise a successful chess
machine one would seem to have penetrated to the core of human
intellectual endeavor."

I don't know anyone who is amazed by a chess AI today. 

**Definition**: checks out!

**Checklist**: yes; true

---

### opinions about the future of machine intelligence (4)

> Progress on two major fronts—towards a more solid statistical and
> (information-theoretic foundation for machine learning on the one
> hand)[1], and (towards the practical and commercial success of
> various problem-specific or domain-specific applications on the
> other)[2]—has restored to AI research (some of its lost
> prestige)[3].

**Claims**: Progress on [1], and [2], has restored [3] to AI research.

**Subject**: Progress on [1] and [2].

**Predicate**: has restored [3] to AI research.

**Example**: *No examples in the section*

**Definition**: -

**Checklist**: yes; neither; 
*no-example* 

---

> One result of (this conservatism)[1] has been (increased
> concentration on “weak AI”—the variety devoted to providing aids to
> human thought—and away from “strong AI”—the variety that attempts to
> mechanize human-level intelligence)[2].

**Claims**: result of [1] has been [2].

**Subject**: Result of [1].

**Predicate**: has been [2]. 

**Example**: *no examples in the section*

**Definition**: -

**Checklist**: yes; neither; 
*no-example* 

---


> (Expert opinions about the future of AI)[1] vary (wildly)[2]. 

**Claims**: [1] varies [2].

**Subject**: [1].

**Predicate**: varies [2].

**Example**: A survey documented [here](https://intelligence.org/files/PredictingAI.pdf) shows the prediction of
HLAI of "experts", ranging from 2020 to 2100.

**Definition**: checks out.

**Checklist**: yes; true; none; not-chapter; not-running; none  

---

**Summary**

Small sample sizes, selection biases, and—above all—the inherent unreliability
of the subjective opinions elicited mean that one should not read too much into
these expert surveys and interviews. They do not let us draw any strong conclu-
sion. But they do hint at a weak conclusion. They suggest that (at least in lieu of
better data or analysis) it may be reasonable to believe that human-level machine
intelligence has a fairly sizeable chance of being developed by mid-century, and
that it has a non-trivial chance of being developed considerably sooner or much
later; 



## Chapter 2 Paths to Superintelligence (26).
### Artificial intelligence (8)

> How do we get from here to there? AI is a conceivable technology
> path.

**Claims**: AI is a conceivable technology path to go from current to superintelligent.

**Subject**: AI

**Predicate**: is a conceivable technology path to go from current to superintelligent.

**Example**: ~~"blind evolutionary processes can produce human-level
general intelligence, since they have already done so at least
once. Evolutionary processes with foresight—that is, genetic programs
designed and guided by an intelligent human programmer—should be able
to achieve a similar outcome with far greater efficiency."~~

*Crossed out are reasons, they are more claims. You can't give
examples for "could be"*

**Definition**: Also, what does conceivable even mean? How
would I know if it is conceivable. How would I know the definition?

**Checklist**: no; neither; 
*future-with-no-ex*; *definition-unclear*;

---

> (Evolutionary processes with foresight—that is, genetic programs)[1]
> designed and guided by (an intelligent human programmer)[2]—should be
> able to achieve a (similar outcome with far greater efficiency)[3].

**Claims**: [1] designed and guided by [2] should be able to achieve
[3].

**Subject**: [1] designed and guided by [2].

**Predicate**: should be able to achieve [3].

**Example**: 

"~~If we were to simulate 10^25 neurons over a billion years of
evolution (longer than the existence of nervous systems as we know
them), and we allow our computers to run for one year, these figures
would give us a requirement in the range of 10^31–10^44 FLOPS. For
comparison, China’s Tianhe-2, the world’s most powerful supercomputer
as of September 2013, provides only 3.39×10 16 FLOPS. In recent
decades, it has taken approximately 6.7 years for commodity computers
to increase in power by one order of magnitude. Even a century of
continued Moore’s law would not be enough to close this gap~~"
 
<!-- *If we assume the calculations scratched out above as evidence , then we -->
<!-- see the evolution is not possible within this century. But any -->
<!-- calculation is not an example, just like we don't consider [Elizebeth -->
<!-- Warren's statement](https://www.forbes.com/sites/zackfriedman/2019/06/17/elizabeth-warren-student-loan-debt-forgiveness/#60261e105e7b) of voiding all student debt and countering for -->
<!-- it via increasing taxes for the ultra millionaires*.  -->

*"Should" is hard to get an example for*. *This again talks about some
prediction for the future. We are not interested in calculations, we
are interested for now (for some reason) in examples*

**Definition**: -

**Checklist**: no; neither; 
*because-should-due-to*; *future-with-no-ex* 

---

> Another way of arguing for the (feasibility of artificial
> intelligence)[1] is by pointing to the (human brain)[2] and
> suggesting that we could use it as (a template for a machine
> intelligence)[3].

**Claims**: [1] can be done by using [2] as [3].

**Subject**: [1] using [2] as [3].

**Predicate**: can be done.

**Example**: ~~whole brain simulation, taking inspiration from brain,
neuromorphic approaches, recursive self-improvement~~

*Take inspiration all you want. Show me the money (examples)!*

**Definition**: -

**Checklist**: no; neither; 
"future with no ex"


**Summary**

"Lot of ways" to make SI from AI but there are currently 0 examples
for it in the section.

### Whole brain emulation (6)

**Claims**: We get from current to superintelligent by using Whole
brain Emulation.

**Subject**: That which will lead us from current to superintelligent

**Predicate**:  is  Whole brain emulation

**Example**: ~~"No brain has yet been emulated. Consider the humble
model organism Caenorhabditis elegans, which is a transparent
roundworm, about 1 mm in length, with 302 neurons. The complete
connectivity matrix of these neurons has been known since the
mid-1980s, when it was laboriously mapped out by means of slicing,
electron microscopy, and hand-labeling of specimens..."~~

There is no example of even a small organism whose brain is emulated
currently.

**Definition**: -

**Checklist**: no; neither; 
"future with no ex"  

**Summary**

"Nevertheless, compared with the AI path to machine intelligence, whole
brain emulation is more likely to be preceded by clear omens since it
relies more on concrete observable technologies and is not wholly
based on theoretical insight."

### Biological cognition (8)

**Claims**: We get from current to superintelligent by using
biological cognition.

**Subject**: That which will lead us from current to superintelligent

**Predicate**: biological cognition

**Example**: ~~"Pre-implantation genetic diagnosis has already been
used during in vitro fertilization procedures to screen embryos
produced for monogenic disorders such as Huntington’s disease and for
predisposition to some late-onset diseases such as breast cancer."~~

**Definition**: -

**Checklist**: No; neither;
*future-with-no-ex* 

### Brain-computer interfaces (4)

**Claims**: We get from current to superintelligent by using
Brain-computer interfaces.

**Subject**: That which will lead us from current to superintelligent

**Predicate**: brain-computer interfaces

**Example**: ~~"Impressive work on the rat hippocampus has
demonstrated the feasibility of a neural prosthesis that can enhance
performance in a simple working-memory task."~~

~~"This prosthesis can not only restore function when the normal
neural connection between the two neural areas is blockaded, but by
sending an especially clear token of a particular memory pattern to
the second area it can enhance the performance on the memory task
beyond what the rat is normally capable of."~~

**Definition**: -

**Checklist**: no; true; 
*future-with-no-ex* 

### Networks and Organizations (4)

> (Another conceivable path to superintelligence)[1] is through the (gradual
> enhancement of networks and organizations that link individual
> human minds with one another and with various artifacts and bots)[2]

**Claims**: [1] is through [2].

**Subject**: [2].

**Predicate**: is [1].

**Example**: -

**Definition**: -

**Checklist**: no; neither;
*future-with-no-ex* 

### Conclusion

There are many "possible paths". But all of them seem to be
predictions based on what all needs to be done. The author is claiming
that the gap to Superintelligence can be fixed if we do XYZ. For
example, they claim cyborgization of man will lead to
Superintelligence. Yet, the examples we see are the ones where
patients are able to communicate by moving a cursor on a
screen. Another example, was the rat whose performance was "enhanced"
in a simple working-memory task. What I fail to see is an example
showing glimmers of Superintelligence, i.e., something that can do
**many things** at **much higher performance** than current
humans/rats/whatever.

Yes computers can beat the shit out of humans in games. Great. But we
do not seem to consider this as super-intelligence. Everyone "could
do" everything in theory, but when testing a claim, we want
examples. This is very similar to people claiming "human civilization
is at risk due to AI".

## Chapter 3

> This chapter identifies (3 different forms of Superintelligence)[1],
> and argues that they are, (in a practically relevant sense,
> equivalent)[2], practically relevant sense, equivalent. We also
> show that the (potential for intelligence in a machine substrate)[3] is
> vastly greater than (in a biological substrate)[4].

**Claims**: [1] are [2].

**Subject**: [1].

**Predicate**: are [2].

**Example**: ~~Superintelligence in any of these forms could, over
time, develop the technology necessary to create any of the others.~~

I don't have any examples for this other than the crossed-out claim to
support this. And I have no way of testing this crossed-out claim as
well, as it has SI as subject, for which I have zero examples.

**Definition**: -

**Checklist**: no; neither;
*future-with-no-ex* 

---

**Claims**: [3] is greater than [4].

**Subject**: [3] compared to [4].

**Predicate**: is greater.

**Example**: ~~"Biological neurons operate at a peak speed of about 200
Hz, a full seven orders of magnitude slower than a modern
microprocessor (~ 2 GHz)"~~

There are several more "advantages for digital intelligence", but I
don't think it helps. Because, "potential" seems to be talking about
something that could exist and doesn't exist currently. I don't think
I can test it with an example. Just like I can't test "I have the
potential to become CEO one day". However I can test "Sundar Pichai"
has the potential to become the CEO".

**Definition**: -

**Checklist**: no; neither; 
*future-with-no-ex* 

---

> (Many machines and nonhuman animals)[1] already perform (at superhuman
> levels)[2] in (narrow domains)[3]. Bats interpret sonar signals better than
> man, calculators outperform us in arithmetic, and chess programs
> beat us in chess.

**Claims**: [1] already perform [2] in [3].

**Subject**: What [1], does.

**Predicate**: perform at [2] in [3].

**Example**: "Google’s AI AlphaGo has done it again: it’s defeated Ke
Jie, the world’s number one Go player, in the first game of a
three-part match."

**Definition**: If we assume "superhuman" means way better than the
average human, then yes the definition checks out.

**Checklist**: yes; neither;  

### Speed Superintelligence

> Because of this apparent time dilation of the material world, a
> (speed superintelligence)[1] would prefer to (work with digital
> objects)[2].

**Claims**: [1] would prefer to [2].

**Subject**: What [1] does.

**Predicate**: would prefer to [2].

**Example**: No example

**Definition**: Also no idea how to test "would prefer to"

**Checklist**: no; neither; none; not-chapter; not-running; none;
*future-with-no-ex*; *would-prefer-to*;

---

> (The speed of light)[1] becomes an (increasingly important
> constraint)[2] as (minds get faster)[3], since (faster minds face
> greater opportunity costs in the use of their time for traveling or
> communicating over long distances)[4]. Light is roughly a million
> times faster than a jet plane, so it would take a digital agent with
> a mental speedup of 1,000,000× about the same amount of subjective
> time to travel across the globe as it does a contemporary human
> journeyer. Dialing somebody long distance would take as long as
> getting there “in person,” though it would be cheaper as a call
> wouldrequire less bandwidth.

*I don't understand what they are trying to say here with this
paragraph. Why would it take a digital agent with a mental speedup of
one millx, about the same amount of "subjective time" to travel across
the globe as it does a contemporary human journeyer. What is
subjective time even mean?*

**Claims**: [1] becomes [2] as [3], ~~since [4].~~

**Subject**: [1] as [3].

**Predicate**: becomes [2]. 

**Example**: No examples here. Talking about hypothetical situations.

**Definition**: -

**Checklist**: yes; neither; 

### Collective Superintelligence

> (Collective intelligence)[1] excels at (solving problems that can be
> readily broken into parts)[2] such that (solutions to sub-problems
> can be pursued in parallel and verified independently)[3]. Tasks
> like building a space shuttle or operating a hamburger franchise
> offer myriad opportunities for division of labor: different
> engineers work on different components of the spacecraft; different
> staffs operate different restaurants.

**Claims**: [1] excels at [2] such that [3].

**Subject**: What [1] does.

**Predicate**: excels at [2] such that [3].

**Example**: People working together on building a space shuttle at
say NASA.

**Definition**: Does it excel though? compared to what? Speed
superintelligence perhaps. But I have no examples of speed
superintelligence*

**Checklist**: yes; neither;
*future-with-no-ex*;

---

> Collective superintelligence could be either loosely or tightly
> integrated.  To illustrate a case of loosely integrated collective
> superintelligence, imagine a planet, MegaEarth, which has the same
> level of communication and coordination technologies that we
> currently have on the real Earth but with a population one million
> times as large. With such a huge population, the total intellectual
> work- force on MegaEarth would be correspondingly larger than on our
> planet. Suppose that a scientific genius of the caliber of a Newton
> or an Einstein arises at least once for every 10 billion people:
> then on MegaEarth there would be 700,000 such geniuses living
> contemporaneously, alongside proportionally vast multitudes of
> slightly lesser talents. (New ideas and technologies)[1] would be
> developed at (a furious pace)[2], and (global civilization on
> MegaEarth)[3] would constitute (a loosely integrated collective
> superintelligence.)[4]

**Claims**: [1] would be developed at [2] and [3] would constitute
[4].

**Subject**: What [1] would develop at

**Predicate**: [2].

**Example**: *Would be*

**Definition**: -

**Checklist**: no; neither; 
*because-should-due-to*; *future-with-no-ex*;

---

**Claims**: [3] would constitute [4].

**Subject**: What [3] would.

**Predicate**: constitute [4].

**Example**: "would"

**Definition**: -

**Checklist**: yes; false; 
*future-with-no-ex*; 

### Quality Superintelligence

> (Such examples)[0] show that (normal human adults)[1] have a range of
> (remarkable cognitive talents)[2] that are not (simply a function of
> possessing a sufficient amount of general neural processing power)[3] or
> (even a sufficient amount of general intelligence: specialized
> neural circuitry is also needed.)[4]

<!-- *This one I read a few times, and had no idea wtf NB is talking -->
<!-- about. NB is making me furious in many cases, just by not providing -->
<!-- examples and hanging on to abstract bullshit. Such a bastard he -->
<!-- is. How does he expect people to read this shit? especially if they -->
<!-- don't have a background on this and worst of all, he seems to have -->
<!-- extensively used the thesaurus to sound cool. So many words I had to -->
<!-- look up. Why not write it like Harry Potter? huh? why not? eugenics, -->
<!-- affliction, adduced, intractable, circumscribed, "dogs walking on hind -->
<!-- legs, docility"* -->


**Claims**: [0] shows that [1] have a range of [2] that are not [3]

**Subject**: [1].

**Predicate**: have range of [2] that are not [3].

**Example**: *People with autism spectrum disorders who may have
striking deficits in "social cognition" while function well in other
"cognitive domains" say like painting, playing the piano etc...*

This above is hardly an example. Let's consider [this](https://youtu.be/zNGjdYY7WVE?t=142), where we
see a guy with autism making highly detailed drawings of scenery, for
an actual example to test the predicate on.

**Definition**: I think I am pondering too much about the
predicate. Its a string of words and I don't think it is specific
enough like in law when people say haebus corpus. I consider [2] to be
talking about things in the context of superintelligence and deem
everything we have seen in the earth as not superintelligence.

**Checklist**: yes; false;; not-chapter.
*failed* 

---

**Claims**: [1] have a range of [2] that are not [4].

ditto! Too many labels that I don't have examples for. Sufficient
general intelligence? What does that mean? I give up. I don't see the
point in pondering this out.

*failed* 

***General rant: ***

*This one I read a few times, and had no idea wtf NB is talking
about. NB is making me furious in many cases, just by not providing
examples and hanging on to abstract bullshit (sufficient amount of
general intelligence, specialized neural circuitry), i.e., things I
have 0 examples for. Such a bastard he is. How does he expect people
to read this shit? especially if they don't have a background on this
and worst of all, he seems to have extensively used the thesaurus to
sound cool. So many words I had to look up. Why not write it like
Harry Potter? huh? why not?  eugenics, affliction, adduced,
intractable, circumscribed, "dogs walking on hind legs", docility*

---

### Direct and indirect reach

> (Superintelligence in any of these forms)[1] could, over time,
> develop (the technology necessary to create any of the
> others)[2]. The (indirect reaches of these three forms of
> superintelligence)[3] are therefore (equal)[4]. In that sense, the
> (indirect reach of current human intelligence)[5] is also in the same
> equivalence class, under the supposition that we are able eventually
> to create some form of superintelligence.

**Claims**: [1] could over time develop [2].

**Subject**: [1] over time.

**Predicate**: could develop [2].

**Example**: *Could*. Also *I have no example for [1].*

**Definition**: -

**Checklist**: no; neither;
*future-with-no-ex*; *could*

---

**Claims**: [3] are all equal.

**Subject**: [3].

**Predicate**: are all equal.

**Example**: *No example for subject*

**Definition**: - 

**Checklist**: no; neither; 
*no-example* 

---

**Claims**: [5] also same as [3].

**Subject**: [5].

**Predicate**: also same as [3]. 

**Example**: no example

**Definition**: don't understand the predicate either.

**Checklist**: no; neither;
*no-example*; *definition-unclear* 

---

> And one can speculate that the (tardiness and wobbliness of
> humanity’s progress)[1] on (many of the “eternal problems” of
> philosophy)[2] are due to the (unsuitability of the human cortex for
> philosophical work.)[3]

**Claims**: [1] on [2] are due to [3].

**Subject**: [1] on [2]. 

**Predicate**: are due to [3].

**Example**: *because* + *no example*

**Definition**: 

**Checklist**: no; neither;
*big-gigantic-cluster-fuck*

### Sources of advantage for digital intelligence

> Minor changes in (brain volume)[1] and (wiring)[2] can have (major
> consequences)[3].

**Claims**: Minor changes in [1] and [2] can have [3].

**Subject**: Minor changes in [1] and [2]. 

**Predicate**: can have [3].

**Example**: ~~"intellectual and technological achievements of humans
with those of other apes"~~ *no-example* 

**Definition**: -

**Checklist**: yes; false; 
*no-example*;


## Data science stuff

### Attempt 1: things to do

- Joshua Starmer (StatQuest) 

I generally look at the wikipedia articles on each subject and then
just use google in general to see what comes up. One good source is
Penn State Statistics:
https://newonlinecourses.science.psu.edu/stat414/node/287/

- Statistical sleuth

R Book: https://cran.r-project.org/web/packages/Sleuth3/

Book: https://drive.google.com/open?id=1DLpuj4MDfwWV3NIBMgGtv5j5aOAK4Ks3

or look at stuff in R-learning notes and pick them and see where you
understand and go deeper.

Plan is to search for patterns for 10 hrs atleast! 

(knitr)

### Doing the first chapter of Stat sleuth

one key claim atleast per section just like pandian studied the super
intelligence.

## Chapter 1: Statistical sleuth
### 1.1.1

**Claims**: Rewards increase productivity, skill, creativity (in general)

**Subject**: What rewards do.

**Predicate**: increase productivity, skill creativity. (general predicate)

**Example**: A study by Teresa Amabile takes people with "considerable
experience" in creative writing and assigns them randomly to two groups;
Intrinsic and Extrinsic groups.

The Intrinsic group of 24 were made to rank statements which were
focused on "triggering" intrinsic motivation using statements such as
"you get a lot of pleasure out of reading something good that you have
written".

The extrinsic group of 23 were made to rank statements which was
focused on "triggering" extrinsic motivation using statements such as
"You have heard of cases where one bestselling novel or collection of
poems has made the author financially secure".

After ranking statements all subjects were asked to write a poem on
Haiku style about "laughter" and were subjectively rated by 12 poets
on a 40 point scale.

| Sample size | I/E       | Avg.  | SD   |
|-------------|-----------|-------|------|
| 24          | Intrinsic | 19.88 | 4.44 |
| 23          | Extrinsic | 15.74 | 5.25 |

The two sided t-test p-value=0.005, under the null-hypothesis.

**Definition**: As this was a randomized experiment, one may infer
causation. The p-value is super low, suggesting that there is a high
chance that the questionnaires affect the creativity scores of
writers. 

If the questionnaires are ASSUMED to be "rewards", then this example
matches the definition.

**Caveats**

- This experiment allows to infer causation between questionnaires and
  creativity score.
- Inference to other populations other than the writers involved in
  this experiment is purely speculative.

**Checklist**: yes; true; *example-matching-subject*; *time* (46mins);


--- 

### 1.1.2

Did a bank disciminatorily pay higher starting salaries to
men than to women? Not-sure (says the book). There could be other
factors.

**Claims**: The bank paid disciminatorily towards women.

**Subject**: What the bank did.

**Predicate**:  discriminatory pay...

**Example**: "mean starting salary for males is estimated to be
<span>$</span>560 to <span>$</span>1080 larger than the mean starting
salary for females for the same position (entry level clerical
employees)".

- one sided p-value <0.00001 from a two sample t-test
- CI is 560 to 1080 dollars

**Definition**: It is not possible to conclude with just the CI and
the p-value as there could be other confounding variables, such as
"initial years of experience".

**WOW**: *This is a common conclusion that causation cannot be
established with observation studies like the above.*

**Checklist**: yes; false; 
*example-matching-definition*;*failed*

---

**Claims**: It is not possible to establish causation with observation
studies because there could always be confounding variables

**Example**: 

*I need more information to use the same observational study as in the
previous claim*

In a 22 year study on the effect of vitamins on death
rates: "The raw differences in death risks for consumers of folic
acid, vitamin B6, magnesium, zinc, copper, and multivitamins are NOT
statistically significant."

Confounding variables: "Supplement users had a lower prevalence of
diabetes mellitus, high blood pressure, and smoking status; a lower
BMI and waist to hip ratio, and were less likely to live on a
farm. Supplement users had a higher educational level, were more
physically active and were more likely to use estrogen replacement
therapy. Also, supplement users were more likely to have a lower
intake of energy, total fat, and monounsaturated fatty acids,
saturated fatty acids and to have a higher intake of protein,
carbohydrates, polyunsaturated fatty acids, alcohol, whole grain
products, fruits, and vegetables."

When all the measured parameters were controlled for: "Of the 15
supplements that the study tracked, researchers found consuming seven
of these supplements were linked to a statistically significant
INCREASE in death risk (p-value < 0.05): multivitamins (increase in
death risk 2.4%), vitamin B6 (4.1%), iron (3.9%), folic acid (5.9%),
zinc (3.0%), magnesium (3.6%), and copper (18.0%)."

**Source**: https://statisticsbyjim.com/basics/observational-studies/

**Definition**: Raw results suggest that there is the consumption of
certain vitamins do not affect the death rate. However controlling for other
"confounding variables", it shows that there is a statistically
significant (p-value <0.05) increase in death rates. 

*I wanted an example where it showed what happens when you control for
confounding variables and you don't control for them, so had to search
outside. The book didn't have it. It was an important claim so I had
to spend time on it!*

**Checklist**: yes; true; ; not-chapter

---

### 1.2.1
nn
**Claims**: Causal inference can be justified by proper use of random
mechanisms

**Subject**: Causal inference by "proper" use of random mechanisms
(aka randomized experiments)

**Predicate**: can be "justified"

**Example**: We take the same creativity example from last time where
a randomization of the "selected participants" led to the choice in
intervention; one with intrinsic group and the other with extrinsic
group.  

**Definition**: The example could have been "justified", if this
"statistical analysis" matched the reality. But that is not part of
the examples or info I see in the book. I currently don't have one
example.

**Checklist**: yes; neither; 
*no-example*; 

---

**Claims**: (The chance---that the randomization turned out in such a way
that the intrinsic motivation group received many more of the
naturally creative writers)[1]---is incorporated into (the statistical
tools that are used to express uncertainty.)[2]

**Subject**: [1]. 

**Predicate**: is incorporated in [2].

**Example**: We think of the creativity study from earlier. The
difference in averages from the sample was 4.14. 

It is possible that there was actually no difference between the
creativity scores of the two groups but just by chance the intrinsic
group had the best creativity scorers. 

This chance is calculated by: Taking all the people (along with their
group scores) and considering all possible randomizations of group
assignment. How often we get 4.14 is [1]. For the given case with 1000
randomizations we get a >4.14 only 4 times. This is 0.004

The p-value is 0.005 (based on "statistical tools that are used to
express uncertainty").

**Definition**: [1] is 0.004 and [2] is 0.005. Checks out.

**Checklist**: yes; false; 
*example-matching-subject*; *time*; ("seemed mighty hard and convoluted")

---

**Claims**: Is there any (role at all for observational data in serious
scientific inquiry)[1]? Yes.

**Claims**: Establishing causation is not always the goal

**Subject**: [1].

**Predicate**: is there.

**Example**: A study was conducted with 10 American men of Chinese
descent and 10 American men of European descent to examine the blood
pressure-reducing drug. The result was that the men of Chinese
ancestry tended to exhibit a different response to the drug. 

**Definition**: This does not prove causal inference that being of
Chinese descent is responsible for the difference. In fact, it could
be diet or a particular gene or something. Nevertheless, the study
provided "important" information to the doctors prescribing the drug
to people from these populations.

**Checklist**: yes; true; 

---

**Claims**: Establishing causation may be done in other ways whilst
still using observational studies.

**Subject**: Establishing causation using observational studies

**Predicate**: may be done.

**Example**: Radiation biologists counted chromosomal aberrations in a
sample of Japanese atomic bomb survivors who received radiation from
the blast, and compared these to counts on individuals who were far
enough from the blast. Although the data is purely observational, the
researchers are certain that higher counts in the radiation group can
only be due to radiation. And has thus been used to estimate the
dose-response relationship between radiation and chromosomal
aberration.

**Definition**: seems to check out.

**Reflection**: Lets make a thought experiment at observational
studies on smoking. So they look at several people who smoke and don't
smoke. Look for signs of lung cancer in both. See that people who
smoke have higher chances of lung cancer. 

You can control for race by sticking to the same race

You can control for diet by sticking to people who are nonvegetarians 

You can control for weight by sticking to people of a certain weight
class

You can control for ancestry by sticking to people of a certain
ancestry

I guess you need to keep controlling everything. 

As the author said a while ago, it is impossible to go to causation
from observational studies.

What if you saw 100k people and saw that 70k had a chance of cancer of
50% and 30k who didn't smoke had a chance of 20%.

Maybe as a result of social anxiety one gets lung cancer. If you
haven't measured this confounding variable you cannot claim causation
based on correlation.

Isn't this randomization enough? Is this randomization? I guess not.

But how would a randomization study look like though?

I guess you would take 200 people, use a chance mechanism to separate
them into two groups and feed one cigarettes and the other no
cigarettes. The "only" difference between these two groups seems to be
the smoking and its effects.


I still can't wrap my head around the fact that you cannot do this
with already existing data of tons and tons of people and smoking.
Lets come back after the next claim.

<!-- Needs to be refined -->
**Checklist**: yes; true;

---

**Claims**: (Analysis of observational data)[1] may lend evidence toward
(causal theories and suggest the direction of future research)[2].

**Subject**: [1] 

**Predicate**: may lend evidence towards [2].

**Example**: Many observational studies indicated an association
between smoking and lung cancer, but causation was accepted only after
decades of OS, experimental studies on laboratory animals and a
scientific theory for the carcinogenic mechanism of smoking. 

**Definition**: It seems that those observational studies were the
first straw for further investigation. 

**Checklist**: yes; true; 

### 1.2.2

**Claims**: Inference to populations can be justified by the proper
use of random mechanisms.
<!-- Come back -->

> (Inferences to populations)[1] can be drawn from (random
> sampling studies)[2], but not (otherwise)[3].

**Claims**: [1] can be drawn from [2].

**Subject**: [1] from [2].

**Predicate**: can be drawn.

**Example**: 

	## Population
	> n <- 100000
	> x1 <- runif(n/3,1,100) # gen n/3 random numbers from 1-100
	> x2 <- runif(n/3,500,600)
	> x3 <- runif(n/3,900,1000)
	> x  <- c(x1,x2,x3)
	
	> mean(x)
	[1] 517.0248
	
	## Sample
	
	> mean(x[sample(1:length(x),100,replace=T)])
	[1] 548
	[1] 531
	[1] 529
	

**Definition**: The sample mean is very close (6%) from the actual
mean of the population. 

**Checklist**: yes; true;;not-chapter;

---

**Claims**: [1] cannot be drawn from non [2].

**Subject**: [1] from non [2].

**Predicate**: cannot be drawn

**Example**: Same example as above.

	## Population
	> n <- 100000
	> x1 <- runif(n/3,1,100) # gen random numbers from 1-100
	> x2 <- runif(n/3,500,600)
	> x3 <- runif(n/3,900,1000)
	> x  <- c(x1,x2,x3)
	
	> mean(x)
	[1] 517.0248
	
	## Sample
	> mean(x[1:1000])
	[1] 50.7674
	

**Definition**: When sampling is not random we don't seem to be able
to match infer to population.

*Cannot seems to imply never. If that is the case, then this claim is
false, because randomly it can so happen that the sample picked not in
a random order can still be random in the population*

**Checklist**: yes; true;; not-chapter;

---

**Claims**: (Random sampling)[1] ensures that (all sub-populations are
represented in the sample in roughly the same mix as in the overall
population)[2]

**Subject**: [1].

**Predicate**: ensures that [2].

**Example**: We take the same example as above,

	## Population
	> n <- 100000
	> x1 <- runif(n/3,1,100) # gen random numbers from 1-100
	> x2 <- runif(n/3,500,600)
	> x3 <- runif(n/3,900,1000)
	> x  <- c(x1,x2,x3)


Looking at the mean of the population and the mean of
the sample, implies that the sample is a "decent" mix of the
population, courtesy of [1].

	> mean(x)
	[1] 517.0248
	
	## Sample
	
	> mean(x[sample(1:length(x),100,replace=T)])
	[1] 548
	[1] 531
	[1] 529

To suggest that [1], ensures for [2] and that it does not by chance,
we toggle [1]. We take the first 100 numbers and find that it doesn't
represent the population.
	
	> mean(x)
	[1] 517.0248
	
	## Sample
	> mean(x[1:1000])
	[1] 50.7674

**Definition**: 

Atleast there is one example where using random
sampling seems to enable inference to population and where if we
remove it, we don't get the inference to population. Checks out!

**Checklist**: yes; true;; not-chapter; 
*ensures*; *unsure*; *missed-comparison*; :);

---

**Claims**: (Random selection)[1] has a chance of producing
(non-representative sample)[2]

**Subject**: Chance of [1] producing [2].

**Predicate**: >0

**Example**: 

	## Population
	> n <- 100000
	> x1 <- runif(n/3,1,100) # gen random numbers from 1-100
	> x2 <- runif(n/3,500,600)
	> x3 <- runif(n/3,900,1000)
	> x  <- c(x1,x2,x3)
	
	> mean(x)
	[1] 517.0248
	
When I sampled from `X` 10000 times the mean was less than 400 once.

	[1] 381.0892


**Definition**: Non-representative sample is off by 25%. [1] seems to
have a chance of producing [2] `=1/10000`. This seems to happen in
this case once in 10000 times. Checks out.

**Checklist**: yes; true;; not-chapter

### 1.2.3
> Statistical analysis is used to make statements from available data
> in answer to questions of interest about some broader context than
> the study at hand. No such statement about the broader context based
> on available data can be made with absolute certainty.

**Claims**: (No such statement about broader context based on
available data)[1] can be made with (absolute certainty)[2]

**Subject**: [1] 

**Predicate**: can be made with [2].

**Example**: ~~The same creativity study. The creative study concluded
that 'creative writers are able to write better with intrinsic
motivation'. Generalizing~~ 

*No example in the book*

**Definition**: -

**Checklist**: yes; neither; none; not-chapter; not-running; none;
*no-example*; *time*;

---

**Claims**: (Every statement)[1] includes some measure of uncertainty.

**Subject**: What [1] includes.

**Predicate**: includes some measure of uncertainty.

**Example**: We think of the same creativity example. Here we saw at
the beginning that the average for the intrinsic group was higher than
the extrinsic group by 4 points (for that particular sample). There is
a chance that it so happened that most of the best creative writers
were in the intrinsic group. So we don't really know if the intrinsic
group is better than extrinsic group or that the chance mechanism made
the grouping skewed such that most of the creative people are at the
intrinsic group.

We look at a **null hypothesis:** 'No difference between intrinsic and
extrinsic group creativity averages'.

Randomization gives a chance of 0.4% to observe a value >4, under the
null hypothesis. So under the null hypothesis getting a value >4 is
about 0.4% (this is also the p-value).

*Not dealing with "every" but attempting to provide one example.*

**Definition**: p-value is the measure of uncertainty.

**Checklist**: yes; true; every; not-chapter; running; none  
*example-matching-definition*; *unsure*; *time*; (is 0.4% a measure of
uncertainty?)

---

**Claims**: (Chance mechanisms)[1] enable (the investigator to calculate
measures of uncertainty to accompany inferential conclusions)[2]. 

**Subject**: What [1] does.

**Predicate**: enables [2].

**Example**: We think of a coin toss which was used in the creativity
study. We see that using it allowed to compute the p-value of 0.4% for
the null hypothesis. This measure of uncertainty (0.4%) is noted along
with the null hypothesis.

*Am I also supposed to show that not having [1], does not lead to
[2].*

**Definition**: ~~checks out.~~ I am confused. I don't know how to
check the claim

**Checklist**: yes; true; none; not-chapter; not-running; none  
*example-matching-definition*; *failed*; *time*; *enable*

<!-- ??? come back -->

---

**Claims**: (Conclusions from C&E studies))[1] can be quite strong, even
if (observed pattern cannot be inferred to hold in some general
population (self-selected))[2].

**Subject**: If [2], then [1]

**Predicate**: can be quite strong.

**Example**: For [1] we think of the conclusion from the Creativity
study, that the creativity of those specific set of writers depends on
the type of intervention (intrinsic or extrinsic) based on p-value
under null hypothesis.

For [2], in this case the samples are selected based on people volunteering to
participate in the study which implies lack of inferentiability to
some general population.

**Definition**: Not sure why they should be quite strong.

**Checklist**: yes; neither; 
*definition-unclear*; *failed*; (unsure if I have done justice to the
claim).

<!-- ??? come back -->

*What is the general population here?*

---

> For (observational studies)[1] the (lack of truly random
> samples)[2] is more worrisome, because making an inference about some
> larger population is usually the goal.

**Claims**: [1] has [2].

**Example**: We think of the 'sex discrimination by a bank' study. The
units selected for the study are part of a bank. There is nothing
random about it.

**Definition**: There was just an already available set of data. That was
it. Hence the example checks out with [2].

**Checklist**: yes; true; 
*example-matching-definition*; *time*; (hard one didn't understand the
predicate or its definition to be able to check.)

*If the sampling is random is when you can infer about some larger
population (remember the 3 sets of numbers example about inference to
population). If there is no random sampling then making an inference
about some larger population might not be right.*

*If we are interested in *

---

**Claims**: For [1], [2] is more worrisome

**Checklist**: yes; false;
*no-example*;

---

> In (observational studies)[1], obtaining (random samples from the
> populations of interest)[2] is often impractical or impossible and
> inference based on assumed models may be better than no inference at
> all.

**Claims**: In [1], obtaining [2] is often impractical or impossible

**Subject**: [2] in [1]. 

**Predicate**:  is often impractical to obtain.

**Example**: In the Vitamin study discussed earlier, it appears that
the population of interest is the whole world. Taking random samples
from this population of interest (aka [2]), implies that we select
random people in the world and ask them to discuss their lives with us
over 22 years. But this is impractical as not everyone is willing to
participate in the study. The next "best" thing we have is that people
volunteer to the study.

**Definition**: I.E, we are unable to have [2].


**Checklist**: yes; true;; not-chapter; 
*often*; *unsure* ; *example-matching-subject*; *unsure*;
*subject-predicate-split*; *time*

---

### 1.3.1 Probability model for randomized experiments

**Claims**: (The chance mechanism for randomizing units to treatment
groups)[1] ensures that every subset of (24 subjects gets the same
chance of becoming the intrinsic group)[2].

**Subject**: What [1] ensures.

**Predicate**: ensures [2].

**Example**: With 24 black cards and 23 red cards shuffled, we are able to
segregate people to the intrinsic and extrinsic group

*Looks like a question on permutation and combination. I don't know
the answer to this.*

**Definition**: checks out.

**Checklist**: yes; true; ; not-chapter;
*example-matching-definition*; *unsure*; *time*; *A-ensures-B*;
*unsure*; *missed-comparison*; *unsure*; *probability*; *failed* 

### 1.3.2 Test for treatment effect in creative study

> (The value of this test statistic is close to or far from zero? The
> answer)[1] to that question comes from what is known about how the
> (test statistic might have turned out in other randomization outcomes)[2]
> (if there were no effect of the treatments)[3]

**Claims**: What is known about [2], is the answer to [1], if [3].

**Subject**: What is known about [2], if [3].

**Predicate**: is the answer to [1].

**Example**: In the creativity study problem, it is known that the
test statistic (difference in average between both groups) of greater
than 4 is obtained only 4 times over 1000 randomized groups, under the
*null hypothesis* (no effect of the intrinsic treatment).

**Definition**: We are able to observe that the test statistic is far
away from 0 in a histogram (looking like a bell curve), as values
greater than 4 appear once over 1000 randomizations (0.4%).

**Checklist**: yes; true;

---

**Claims**: It is possible to determine what test statistic values
would have occurred had the randomization process turned out
differently.

**Example**: In the creativity study, under the null hypothesis---that
the difference between the extrinsic and intrinsic treatments was
nothing---we now posses 47 creativity scores with which we can compute
different test statistics for other randomizations.

For current randomization the test statistic is 4. For another
randomization shown in the book the test statistic is 2.07. It is
possible to generate the test statistic for all combinations.

**Definition**: checks out!

**Checklist**: yes; true;

---

> That conclusion (that the null hypothesis is wrong) could be
> incorrect, however, because the randomization is capable of
> producing such an extreme.

**Claims**: (The conclusion that the null hypothesis is wrong)[1], could be
(incorrect)[2].

**Subject**: What [1] could be.

**Predicate**: could be [2].

**Example**: *In order to see the claim to be true, I would need to
look at the actual reality and compare it with the null hypothesis. At
this point I don't have an example*

**Definition**: -

**Checklist**: yes; neither;; 
*no-example*;

---

> The smaller the (p-value)[1], the more unlikely it is that (chance
> assignment)[2] is responsible for the (discrepancy between
> groups)[3], and (the greater the evidence that the null hypothesis
> is incorrect)[3].

**Claims**: The smaller the [1], the more unlikely is that [2] is
responsible for [3].

**Subject**: Consequences of smaller [1].

**Predicate**: the more unlikely is that [2] is responsible for [3].

**Example**: 

I don't think this is a claim I can give an example for. I just know
[1] is the same as [2] is res for [3].

<!-- ??? come back -->

**Definition**: -

**Checklist**: yes; false; er; *missed-comparison*; *almost*; *time* ;
*example-matching-subject*; *unsure*; *subject-predicate-split*;
*unsure*; (don't know how to give a fucking example for this! where
the subject and predicate stop nam saying?)

*I don't know if I can give example. as in if the example is talking
about reality of which I don't have an example*

*I was struggling with the pvalue drawing histogram and thinking about
it abstractly, what would hapen when p value is >50%... imagining the
example quickly put things into perspective. 3 and above, 4 and
above... why was I taking the greater half of the area became clear.*

### 1.4 Measuring Uncertainty in Observational studies

**Claims**: (Uncertainty measures in Observational studies)[1] are
identical to those of the (randomization test (used in C&E studies to
establish C))[2]. 

**Subject**: [1].

**Predicate**: are identical to [2] 

**Example**: For the 'sex discrimination study', we use the p-value,
under the null hypothesis that: the salaries were provided to the two
groups at random i.e., the salaries were shuffled amongst the
different groups.

For the 'creativity study', we use the p-value, but for a different
form of null hypothesis, where: the creativity scores of the person
remained with them, but the people were shuffled amongst different
groups.

**Definition**: checks out that they both seem to have identical
measures aka p-value for a null hypothesis.

**Checklist**: yes; true; 

### 1.4.2 Testing for a difference in the Sex Discrimination Study

> In the sex discrimination study, there is no interest in the
> starting salaries of some larger population of individuals who were
> never hired, so a (random sampling model)[1] is not
> (relevant)[2]. It makes no (sense)[3] to view (the sex of these
> individuals)[4] as (randomly assigned)[5]. Neither the random
> sampling nor the randomized experiment model applies.

**Claims**: [1], is not [2] in the context of observational studies.

**Subject**: [1] 

**Predicate**: is not [2] in the context of observational studies.

**Example**: -

**Definition**: -

**Checklist**: yes; neither;;
*no-example*; *failed*; *subject-predicate-split*; *failed*;
(initially I had [1] in the context of [2].)

*Made error first time and corrected it in the next round. Claim was
wrongly constructed and examples given for.*

*how to give an example for things that don't make sense* ^^

---

**Claims**: [1] is not [2] in the case of the sex discrimination
study.

**Checklist**: yes; neither;
*no-example*; *failed*; (*no idea how the example could look*)

---

**Claims**: (Randomized experiment model)[1] does not applies to
(observational studies)[2].

**Example**: -

**Definition**: -

**Checklist**: yes; true; 
*no-example*; *failed* 

### 1.5

> The stem and leaf diagrams show the centers, spreads and shapes of
> distributions in the same way histograms do.

**Claims**: ^^

**Subject**: Comparison of stem-and-leaf diagrams vs histograms

**Predicate**: show the centers shapes and distributions in the same way.

**Example**: Image 1.10 in the book, shows the stem and leaf diagram
for the creativity study. If you rotate it 90 degrees clockwise it
looks like it has the Y and X axis of a histogram. If you increase the
histogram bins to show each integer of score then they coincide
exactly in shape.

<!-- image !!! -->
**Definition**: checks out.

**Checklist**: yes; true;


### 1.5.4 

> In (sampling units such as lakes of different sizes)[1], it is sometimes
> useful to allow (larger units to have higher probabilities of being
> sampled than smaller units)[2].

**Claims**: In [1], it is sometimes useful to allow [2].

**Subject**: While [1], how often [2] is useful.

**Predicate**: is sometimes useful.

**Example**: *No examples in the chapter.*

**Definition**: -

**Checklist**: yes; neither;;
*subject-predicate-split*; *almost-failed*; ("it is B"); *no-example*; 

### 1.5.5

> (Close examination of the results of randomization of random
> sampling)[1] can usually expose ways in which (the chosen sample is
> not representative)[2]. The (key)[3], however is not to abandon (the
> procedure when its result is suspect)[4].

**Claims**: [1] can usually expose ways in which [2].

**Subject**: What [1], exposes

**Predicate**: exposes ways in which [2].

**Example**: - 

**Definition**: -

**Checklist**: yes; false; 
*no-example*;

---

**Claims**: Not to abandon [4], is key.

**Subject**: Consequences of not abandoning [4].

**Predicate**: is key

**Example**: -

**Definition**: - 

**Checklist**: yes; neither; 
*no-example*;

---

> If (randomization were abandoned)[5], there would be no way to
> express (uncertainty accurately)[6].

**Claims**: If [5], there would be no way to express [6].

**Subject**: If [5], ways to express [6].

**Predicate**: do not exist

**Example**: *No idea how the example will look*

**Definition**: 

**Checklist**: yes; false; 
*no-way-to-do-X*; *failed*; *no-example*; *failed*;

### 1.6 

> (Randomized experiments)[1] eliminate (this problem (of
> confounding variables))[2] by ensuring that differences between groups
> (other than those of the assigned treatments) are due to chance
> alone. Statistical measures of uncertainty account for this chance.

**Claims**: [1] eliminate [2].

**Subject**: What [1], eliminates.

**Predicate**: eliminates [2].

**Example**: *I again think that the only way to give an example for
these claims is by taking an example and comparing it to
reality. That's how we know we eliminate the problem. For example, I
would take the creativity study and then show the effect of
confounding variables when randomized and when not randomized.*

**Definition**: -

**Checklist**: yes; neither; 
*no-example*; *failed* (because I don't know how the example is
expected to look).

> When the model corresponds to the planned use of randomization or
> random sampling, it provides a firm basis for drawing inferences.

How would I know if something provides a firm basis for drawing
inferences, only if I get feedback from reality.

**Checklist**: yes; neither;
*no-example*; *failed* (I don't know if what I suspect above is true.)


## Chapter 2

### 2.0 t-distributions

> The t-tools are useful in regression and analysis of variance
> structures


<!-- ?? come back later -->

> The t-tools are derived under random sampling models when
> populations are normally distributed.

**Example**: -

**Definition**: -

**Checklist**: not-sure;neither
*no-example*; *failed*; (am I even expected to give an example, not
sure how it would look.)

<!-- ??? come back later -->

> The resulting tools also find applications as approximations to
> randomization tests.

<!-- Dealt with later -->

<!-- come back and show it working if necessary ??? -->

<!-- ??? come back to it later. -->

### 2.1.1 Bumpus's data

> As evidence in support of (natural selection)[1], he presented
> (measurements on house sparrows brought to the Anatomical Laboratory
> of Brown university after an uncommonly severe winter storm)[2].

**Claims**: [2] is evidence in support of [1].

**Example**: Difference in lengths between the armbone of 24 adult
male sparrows that perished and 35 adult males that survived. two
sided p-value is 8%.

**Definition**: A p-value of 8% seems to suggest a only a small chance that
the null hypothesis is true. This seems to be evidence in support of
natural selection, NOT PROOF.

**Checklist**: yes; true; 
*example-matching-definition*; *time*; *unsure*;

### 2.1.2 Anatomical Abnormalities Associated with Schizophrenia

> Are there any physiological indicators associated with
> schizophrenia? Yes.

**Claims**: ^^

**Example**: Paired difference of hippocampus volume between 15 sets
of twins (there by controlling for genes and socioeconomic
differences):

- average : 0.199cm^3
- SD : 0.238
- p-value : 0.6%

**Definition**: This p-value seems to suggest that the null
hypothesis (that there is not difference between hippocampus volume of
the twins), has a low chance of being true. In other words there seems
to be a good chance that there are physiological indicators associated
with schizophrenia.

**Checklist**: yes; true;

---

### 2.2.1 One-sample t-tools and paired t-test

> The mean of the sampling distribution of the average is also mu, the
> (standard deviation of the sampling distribution)[1] is (sigma by
> root n)[2]. The (shape of the sampling distribution)[3] is more
> nearly normal than is the (shape of the population
> distribution)[4]. The last fact comes from the Central limit
> theorem.

**Claims**: [1] is [2].

**Example**: Randomly sampled in R 10000 numbers from Poisson with
lambda=1 (doesn't look normal at all) and these are the findings:

- n_sample=100
- sd(population)/sqrt(100)=0.10008 [2] 
- sd(sampling distribution of the average)=0.1004 [1] 

**Definition**: Checks out!

**Checklist**: yes; true;; not-chapter

---

**Claims**: [3] is more nearly normal than is [4].

**Example**: In the above case I took a poisson distribution with
lambda=1; No one in their right mind would say it looks normally
distributed.

Contrast that to the sampling distribution of the average and it looks
like a bell curve for the example mentioned in the previous claim.

**Definition**: checks out!

**Checklist**: yes; true; 

---

> The (standard deviation in the sampling distribution of an average)[1],
> denoted by SD(Y_bar), is the (typical size of (Y_bar-mu))[2], the error
> in using Y_bar as an estimate of mu. This standard deviation gets
> smaller as the sample size increases.

**Claims**: [1] is [2].

**Example**: 

SD(Y_bar) = 0.10008
Ybar-mu = 1.02-1.0045 = 0.0155

**Definition**: I don't think it checks out. I suspect I made a
mistake with understanding what they meant by "typical size of
(Ybar-mu)". Also if you look at it Ybar can take any value in the
whole sampling distribution depending on chance so you will never have
the same "Ybar-mu"

**Checklist**: yes; false; 
*definition-unclear*;

---

### 2.2.2 The standard error of an average in Random sampling

### 2.2.3 The T-ratio based on a sample average (start from here)

> If the (sampling distribution of the estimate)[1] is normal, then
> the (sampling distribution of Z)[2] is (standard normal)[3], where
> the mean is 0 and the standard deviation is 1.

Z = (estimated mean - Mean of population)/SD(estimate)

**Claims**: If [1] is normal, then [2] is [3].

**Example**: We go further with the same example we have seen till now
where a population is setup using `rpois`.

[1] looks normal (visually, like a bell curve). Now we compute
sampling distribution of Z and determine SD and mean.

mean = 0.009
SD = 1

**Definition**: Standard normal is defined by SD=1 and mean=0, i.e.,
checks out.

*I feel that this is too abstract. I am afraid I am not dealing with a
real example but some abstract thing.*

**Checklist**: yes; false; none; not-chapter; running; if-then
*because-should-due-to*; *unsure*;

<!-- > If the (standard deviation of the estimate)[1] is known, this permits -->
<!-- > (an understanding of the likely size of the estimation -->
<!-- > error)[2]. Consequently (useful statements)[3] can be made about the (amount -->
<!-- > of uncertainty with which questions about the parameter can be -->
<!-- > resolved)[4]. -->

<!-- **Claims**: If [1] is known, this permits an understanding of [2]. -->

<!-- *come back later maybe we see examples ahead* -->

<!-- **Claims**: [3] about [3] can be made. -->

<!-- *come back later, maybe we see examples ahead* -->

> The t-ratio does not have a standard normal distribution, because
> there is extra variability due to estimating the standard deviation

**Subject**: t-ratio

**Predicate**: does not match standard normal distribution

**Example**: We take a Poisson's distribution with 10000 random
values and `lambda=1`. `pop.mu=0.995` & `pop.sd=0.99`.

t-ratio = (estimate-parameter)/std.error

In our case, t-ratio = `(sample.mn-population.mn)/std.error`. 

We take 100 samples and 10 units per sample. We compute the tratio and
display its mean and sd():

mean : 0.08
sd : 1.16

The mean and sd for Zratio are:

mean: 0.069
sd: 1.00

**Definition**: For a std normal mean=0; and sd=1; There will always
be an error in the final value. To understand how much error still
allows the distribution to be called normal, it seems to be
worthwhile to have a look at the Zratio which is expected to be
std.normal if the sampling distribution is normally distributed (which
is the case here).

Just looking at the t-ratio we see that it is not std normal as is the
Z-ratio.

**Checklist**: yes; true; none; not-chapter;
*example-matching-definition*; *time*; (I misread the claim and spent
53 mins pondering my ass off)

> The fewer the (degrees of freedom)[1], the greater is (the extra
> variability)[2], due to (estimating the standard deviation)[3]. 

**Claims**: The fewer the [1], the greater the [2], due to [3].

**Checklist**: yes; neither.
*because-should-due-to*; *almost-missed*

---

**Claims**: The fewer the [1], the greater is [2].

**Example**: 

With 9 dofs the t-ratio sd: 1.2

with 99 dofs the t-ratio sd: 1.06

**Definition**: checks out!

**Checklist**: yes; true; none; not-chapter; running; none;

---

> Under some conditions, however, the sampling distribution of the
> t-ratio is known.

**Claims**: Same as below.

> if Y_bar is the average in a random sample of size n from a normally
> distributed population, the sampling distribution of its t-ratio is
> described by a student's t-distribution on n-1 degrees of freedom. 

**Claims**: If [1], [2] is described by [3].

**Example**: We take a normally distributed population using `rnorm`
of size 100000 and compute the t-ratio for a sampling distribution
with sample size 10. We take 10000 samples and the t-ratios are
computed. We take a population of 10000 based on `rt` which samples
from a t-distribution. We compute the mean and sd of the t-dist with
n-1 dofs=9. the mean and sd are computed.

|      | zratio | tratio | xt    |
| ---  | ---    | ---    | ---   |
| mean | -0.003 | 0.0012 | 0.005 |
| sd   | 1.009  | 1.15   | 1.13  |
|      |        |        |       |

**Definition**: There is a close match between the standard deviations
but the match between the means don't seem to exist. I am not able to
place where the error is.

**Checklist**: yes; false; 
*example-matching-definition*; *failed*; (one of us is wrong and it is
most likely me.)

---

> Histograms for t-distributions are symmetric about zero. For large
> degrees of freedom, t-distributions differ very little from the
> standard normal. For smaller dofs, they have longer rails than normal.

*Seem to be simple enough to test with come R-code. Not going to work
on it as I am interested in failures.*

### 2.2.4 Unraveling the t-ratio

> if the (sample produces one of the 95% most likely t-ratios)[1], then mu
> is (expected to be) (between 0.067 and 0.331)[2]. <-- This is in the case that sample
> mean is 0.199 and SE is 0.0615 and is part of the Schizophrenia study
> in 2.1.2.

*I don't think I can prove this without the "expected to be". So I
added it. At max I can comment on it based on the t-distribution.*

**Subject**: if [1], what mu is (expected to be).

**Predicate**: [2] 

**Example**: We come back to the twins study where one of the twins is
schizophrenic.

Here the estimate average of differences between the volume is 0.199
cm^3. The SE is determined to be 0.0615. 

We know that we are expecting a t-distribution with 14
degrees of freedom. We look at the 2.5th percentile and 97.5th
percentile (95% most likely values). The t-ratios are -2.145 and
+2.145. This gives us possible values of mu if the sample was drawn
with the 95% most likely values.

`-2.145<(0.199-mu)/0.615<2.145`

This gives 0.067 and 0.331

**Definition**:  Check!

**Checklist**: yes; true; 
*example-matching-definition*; *time* 

---

> (A 95% confidence interval)[1] will contain (the parameter)[2] if
> (the t-ratio from the observed data happens to be one of the those
> in the middle 95% of the sampling distribution)[3]. Since 95% of all
> possible pairs of samples lead to such t-ratios, the procedure of
> constructing a 95% confidence interval is successful in capturing
> the parameter of interest in 95% of its applications. It is
> impossible to say (whether it is successful or not in any particular
> application)[5].

**Claims**: if [3], [1] will contain [2].

**Subject**: if [3], what [1] will contain.

**Predicate**: will contain [2].

**Example**: We take a population of mean 0 and sd 1. From which we
take a sample of 100 units.

For [1] we take a random sample where we compute our expected 95%
confidence interval for the mean. We compute it as follows:

``` R
## compute sample, se and q
x.sam <- x[sample(1:length(x),size=n.sample)]
se <- sd(x.sam)/sqrt(n.sample)
q <- qt(0.975,df=n.sample-1) ## 95% quantiles

## Computing 95%CI
mean(x.sam) + q*se
mean(x.sam) - q*se
```

`-0.011 to 0.34`

For [3] we need to use the `pop.mean` and check if the tratio actually
lies in the middle 95%. With the below code we get the t-ratio as
`1.85`. This is within the middle 95% t-sampling distribution for
dof=99, i.e., `-1.98 to 1.98`.

``` R
tratio <- (mean(x.sam)-0)/sd(x.sam)*sqrt(n.sample)
tratio
```
*took me 3-4 hrs mygod! Seems so simple, but even on the second
revision of this post it took me 10mins to make sure I did the right
thing. The 3-4 hrs was mainly because I wanted to give an example
such that I showed [3] but at the ends of the 95% band. I have still
not figured out how to do it.* 

<!-- *splitting it helped attacking this claim* *as I write this I realize -->
<!-- I don't know what this 95% CI is, in the light that I was planning to -->
<!-- skip this or that I thought this was too easy. If I wanted to learn -->
<!-- this, I would look at solving more questions and that would be enough -->
<!-- it appears* -->

<!-- *I can't remember the amount of time I have been staring at this and I -->
<!-- still don't understand. I am unable to even point to my -->
<!-- confusion. Whereas I went to khan academy and life already seems much -->
<!-- simpler. I can blame two things the book, and/or my technique of -->
<!-- claims. I have having serious doubts to the value of this technique* -->

**Definition**: We thus see that the CI (`-0.011 to 0.34`) contains
the mean (the population mean/parameter `0`), when the t-ratio is
within the middle 95% of the t-sampling distribution. I checked this
for a couple of random samples and it checked out for all.

*To show if, I probably need to toggle?*

**Checklist**: yes; true;
*example-matching-definition*; *time* 

---

**Claims**: To say [5] is impossible.

*No idea how to go about this*

**Checklist**: yes; neither;
*impossible*; *failed*;

---

### 2.3 t-ratio for two-sample inference

Nothing

### 2.3.1 Sampling dist of the diff between 2 independent sample averages

> The spread of the sampling distribution will be smaller with larger
> sample sizes. The sampling distribution is approximately normal, and
> will be more so with larger sample sizes. As was the case in Section
> 2.2.1, (the theoretical results about the sampling distribution of
> Y2-Y1)[1] are insufficient for (making inferential statements)[2],
> because SD(Y1_bar-Y2_bar), the standard deviation of this sampling
> distribution, depends on unknown parameters.

**Claims**: [1] are insufficient for [2].

**Subject**: [1] for making [2]. 

**Predicate**: are insufficient.

**Example**: For [1] we think of, "The sampling distribution is
approximately normal, and will be more so with larger sample sizes"

**Definition**: *I don't understand [2].*

**Checklist**: yes; neither; 
*definition-unclear*;

### 2.3.2 SE for diff of 2 averages

> However, (comparing averages)[1] provides a (complete analysis)[3]
> only if (all other features of the two distributions are
> similar)[2]. Therefore assume in the following that the two
> populations have equal standard deviations: sigma1 = sigma2 = sigma

**Subject**: if [2], then what [1], provides.

**Predicate**: provides [3].

**Example**: *No example provided*. 

For example if I take the sigma1 != sigma2, then I probably get 

**Definition**: *Also definition unclear*

**Checklist**: yes; neither.
*no-example*; *definition-unclear* (not sure atall what this [3] could
be)

---

### 2.3.3 CI for diff between pop means

>If the populations are normally distributed, this t-ratio has a
>t-distribution with n1 + n2 -2 degrees of freedom.

I skip this. This is simple to test that can be simulated in R. 

> Now a (statement about the likely values for the t-ratio from the
> distribution)[1] can be translated into a statement about (the
> plausible values for mu2-mu1)[2].

**Subject**: [1] translating to [2].

**Predicate**: can be translated.

**Example**: For the Bumpus data of the birds that died vs survived,
we look at the Humerus length. 

For [1], we think of 95% middle t-ratios from the t-distribution with
57 dofs: 2.002 and -2.002.

For [2], we think computing the possible values of the mean using [1].

We have difference in sample mean `(Y2_bar-Y1_bar)=0.01008`, along
with the `SE(Y2_bar-Y1_bar)=0.00567`. 

t-ratio = `(estimate-mean_under_null_hypothesis)/SE`

We can use the same t-ratio formula to compute the
mean-under-null-hypothesis for the extremes which is in this case:

`-0.00127 < mean-under-null-hypothesis < 0.02143`. 

**Definition**: checks out, I guess!

**Checklist**: yes; true;
*example-matching-definition*; *unsure*

---

>There is a trade-off between the level of confidence and the width of
>the confidence interval. The level of confidence can be specified to
>be large by the user (and a (high confidence level)[1] is
>(good)[2]). but only at the expense of having (wider interval)[3]
>(which is (bad)[4] since the interval is less specific in answering
>the question of interest).

**Claims**: [1] is good.

**Checklist**: yes; neither;
*no-example*; *failed*; (as it is important)

**Claims**: [3] is bad.

**Checklist**: yes; neither;
*no-example*; *failed*; (as it is important) 

--------------------------- Continue from here---------------

### 2.3.4 Testing a hypothesis about diff between means


> The p-value may be based on a probability model induced by random
> assignment in a randomized experiment (section 1.3.2) or on a
> probability model induced by random sampling from populations, as
> here.

> If the p-value is small, then either the hypothesis is correct---and
> the sample happened to be one of those rare ones that produce such
> an unusual t-ratio---or the hypothesis is incorrect. Although it is
> impossible to know which of these two possibilities is true, the
> p-value indicates the probability of the first of these results.

**Claims**: It is impossible to know which of these...

**Checklist**: yes; neither;
*impossible*; *failed*;

---

> The smaller the p-value, the stronger is the evidence that the
> hypothesis is incorrect. A large p-value implies that the study is
> not capable of excluding the null hypothesis as a possible
> explanation for how the data turned out. A possible wording in this
> case is "the data are consistent with the hypothesis being true". It
> is wrong to conclude that the null hypothesis is true.

*I can take two samples in R and empirically show that the smaller the
p-value, the stronger the evidence that the hypothesis is incorrect. I
skip this for now.*

### 2.3.5 The Mechanics of p-value computation
### 2.4 inferences in a two-treatment randomized experiment

> Chapter 2 has thus far discussed inference procedures whose
> motivation stems from considerations of random sampling from
> populations that are conceptual, infinite, and normally
> distributed. While there seems to be considerable difference between
> the situations, it turns out that the (t-distribution uncertainty
> measures discussed in this chapter)[1] are (useful approximations to
> both the randomization and the random sampling uncertainty measures
> for a wide range of problems)[2]. The practical consequence is that
> t-tools are used for many situations that do not conform to the
> strict model upon which the t-tools are based, including data from
> randomized experiments. Conclusions from randomized experiments,
> however, are phrased in the language of treatment effects and
> causation, rather than differences in population means and
> association.

**Claims**: t-tools are derived under random sampling models, when
populations are normally distributed.

**Subject**: How T-tools are derived.

**Predicate**: derived under random sampling models, when populations
are normally distributed.

**Example**: - *no idea how the example would even look.*

**Definition**: -

Theorem stating: "If Ybar is the average in a random sample of size n from a normally
distributed population, the sampling distribution of its t-ratio is
described by Student's t-distribution."

**Checklist**: yes; true; 
*no-example*; *example-matching-subject*; *failed*;

--- 

**Claims**: [1] for randomization is a useful approximation.

**Subject**: the usefulness of [1] for randomization

**Predicate**: is useful approximation

**Example**: We go back to the creativity study we saw in the first
chapter. Here, a group of "creative people" were picked and then
randomized into two interventions. The goal is to identify causal
relations between the intervention and the creativity score.

In total there were 47 people split as 23 and 24 into the different
interventions namely intrinsic and extrinsic.

Using the T-tools for randomization: For the given group we have the
t-statistic = `(4.14-0)/1.42 = 2.92`. This gives a 0.0027 p-value when
looked up on a t-distribution of 45 dofs.

Using the randomization procedure and a computer simulation with 500
random assignments of the people into different studies the real
p-value is 0.002. This is the correct value.

<!-- We would like to compare this to the "actual". In chapter 1, there is -->
<!-- an estimation of the p-value based on the randomization -->
<!-- procedure. This is 0.004 one-sided p-value. This is obtained by -->
<!-- looking at all randomizations of the creativity scores and the -->
<!-- resulting difference between the two groups and comparing how often a -->
<!-- number as high as 4.14 is obtained. -->

<!-- 0.0027 and 0.004 both seem to give the same conclusion if we assume a -->
<!-- cutoff of 5%. but the values as such are different (48% off). The text -->
<!-- book however uses another number to compare to 0.0027. It uses the -->
<!-- p-value from the randomization procedure not of the creativity scores -->
<!-- but of the t-ratio. And then the p-value is 0.002. -->

**Definition**: The actual p-value and the approximation as a result
of [1], seem to be quite close. All we need for t-tools is a table of
values. But to determine actual values you need a computer to perform
randomizations.

**Checklist**: yes; true;
*example-matching-definition*; *time*; (second time)

---

**Claims**: [1] for random sampling is a useful approximation.

Just as above was done for randomizations we can establish one for
random sampling based on the sex discrimination study.

**Checklist**: yes; true;
*no-example*; 

---

> The (randomization-based procedure)[1] (to determine the CI) relies
> on (a relationship between testing and confidence intervals)[2]: Any
> hypothesized parameter value should be included or excluded from
> 100(1-alpha)% confidence interval according to whether its test
> yields a two-sided p-value that is greater than or less than alpha.

**Claims**: [1] is based on testing and CI.

**Subject**: What [1] relies on.

**Predicate**: relies on [2].

**Example**: We look at the same creativity study.

The randomization procedure to determine the CI of creativity study
starts with looking at one value of delta.

Let's say delta=5. We subtract 5 from all scores in the intrinsic
group. Now with this homogeneous mixture, we perform the
randomization and check if the estimate is greater than the two-sided
p-value. If so, then that delta=5 is within the 95% confidence
interval. 

By trial and error we keep shifting delta's value to find the limits
of this 95% CI.

**Definition**: This procedure has 2 parts to it. First step involves:
Taking each hypothesized parameter value (delta=5) and then TESTING
if that delta value is likely (>5% p-value). The second step involves:
doing this until you find the CI limits. 

**Checklist**: yes; true;
*example-matching-definition*; *time*

---

**Claims**: There is a (relationship between testing and confidence
intervals)[1].

*I don't have an example for this. I don't understand how to give
example for [1]*

*This is really hard. How long it takes to understand this is still
puzzling. A few hours >3hrs easily and no answer. How to show the
relationship is hard.*

**Checklist**: yes; neither; 
*no-example*; *failed*; *time*; (>3 hrs) *relationship*;

---

**Claims**: [1] relies on [2].

*I don't know how to give an example for this.*

**Checklist**: yes; false; 
*no-example*; *failed*; *time*; *relationships*;

---

### 2.5 related issues

**Claims**: It is difficult and unwise to decide on absolute cutoff points for
p-values in all situations.

*One reason I can think of is say you land up with a value of 5.1% but
you don't accept it but you land up with 5% then you accept it. There
seems to be no difference between 5 and 5.1% such that you reject a
hypothesis or fail to reject it. But we need an example for ""*

**Subject**: How difficult absolute cutoff points for p-values are to decide.

**Predicate**: are difficult and unwise

**Example**: ~~If we take the absolute cutoff point to be 5%, and we get
a sample with 5.1% p-value then we accept the null hypothesis. If we
get 4.9%, then we are going to reject the null hypothesis.~~

~~Although important for leading to advances in the theory of
statistics. The rejection region apporach has largely been discarded
for practical applications and p-values are reported instead.~~

*I don't have an actual example for this.*

**Definition**: ~~Looks like choosing 5% and saying it is valid for
all cases as a hard cut-off seems to be difficult. Also choosing 5%
and seems to be unwise as this would result in 2 very close
percentages being interpreted completely differently.~~

**Checklist**: yes; true;
*example-matching-subject*; *unsure*;

*Maybe writing out the subject and predicate is not overrated
after all. helps me decide with I need to give an example for.*

---

**Claims**: p-values can be comprehended by comparing them to events
whose probabilities are more familiar. 

**Subject**: Comparing p-values to events whose probabilities are more familiar

**Predicate**: makes them comprehensible.

**Example**: ~~We look at the probabilities with respect to a fair
coin.  
p(4 heads in a row) = 6.3%  
P(5 heads in a row) = 3.1%  
P(6 heads in a row) = 1.5%  
P(10 heads in a row) = 0.1%  
If we get 10 heads in a row, then we would start expecting that maybe
our coin is probably not fair.~~

*no example*

**Definition**: -

**Checklist**: yes; neither;
*example-matching-subject*; *unsure*; *example-matching-definition*;
*unsure* 

---

**Claims**: The actual confidence levels are not important for some
cases.

**Example**: Experiments were made to understand the value of the
parameter "general relativity" (gamma) and to see who was right. Newton made a
0 prediction and Einstein made a prediction of 1. A graph showing the
value of gamma over several years of experimentation, shows values
ranging from 0.6 to 1.2 in 1920, to 0.95 to 1.05 in 1985. Just this
was enough  to show that the value of gamma was closer to one than 0.

**Definition**: The whole spread of the gamma values shows that in
1920 the value was close to 1 rather than 0. The CI was not important
here but just the whole spread.

**Checklist**: yes; true;

## Chapter 3 a closer look at assumptions (2)
### Case studies
### 3.1.1 Cloud seeding to increase rainfall (1)

> (Massive injection of silver iodide into cumulus clouds)[1] can lead to
> (increased rainfall)[2].

**Claims**: [1] can lead to [2].

**Example**:  Clouding seeding to increase rainfall randomized
experiment: 

On 52 days that were deemed suitable for cloud seeding, a random
mechanism was used to decide whether to seed the target on that day
or to leave it unseeded as a control. An airplane flew in either
cases. Precipitation was measured on those 52 days.

Estimate = 3.1 times as large as when not seeded. 95% CI is 1.3 times
to 7.7 times.

**Definition**: Since randomization was used, it is safe to infer
causality. Checks out.

**Checklist**: yes; true;

### 3.1.2 Effects of Agent Orange on Troops in Vietnam (2)

> Dioxin levels tends to be higher for the Vietnam veterans than for
> the non-vietnam veterans.

**Claims**: Dioxin levels in Vietnam Veterans than the non-vietnam
veterans is higher

**Example**: Agent Orange Study :   
In a non-randomly selected sample of 646 Vietnam veterans who served
in Vietnam in most heavily treated regions with Agent Orange (Dioxin)
were selected as the test group. 97 non-Vietnam veterans who served in
US and Germany were the control. Blood tests were done on Dioxin
levels reported.

A one-sided p-value of 0.4 for the null hypothesis was obtained.

**Definition**: The p-value of 40% informs that there is not
sufficient evidence to conclude that the levels are higher for the
test group than the control. 

**Caveat**: As the sample was not randomly selected and we need to
investigate more. For example, non-participating Vietnam veterans may
have failed to participate because of dioxin-related illnesses. At
best we can say there isn't sufficient evidence and that the results
could be seriously biased.

**Checklist**: yes; neither; 

---

> Inference to populations is speculative.

*Not sure how to give an example in this context as there is no data
of the true reality to compare with (here). However we have seen
before that without randomness inference to population is
speculative.*


### Robustness of two-sample t-tools
### 3.2.1 The meaning of robustness (2)

> Actual conditions did not seem to match the ideal models upon which
> t-tools are based for both studies.

What are the actual conditions? huh? population should be normal, how
the fuck are you going to decide that by looking at a
sample... because the sample has relatively high number and if it is
expected to be representative of a sample then...

I need to probably look at normality and maybe SD of the two groups
and also the independence. As those are the three points they talk
about in the 3rd chapter. In the second chapter though, they only
discuss normality as a formality.

**Claims**: The conditions of the Seeded Rainfall study do not match
the ideal model on which t-tools are based upon.

**Example**: When we look at the box plots of the Seeded and Unseeded
samples (n=26), we see that the box plots has Outliers at 2500 units,
when the median is at 250 units and the 75th percentile is at 750
units. There is ~15% of outliers, making it NON-NORMAL.

In addition the SD seen for now as the distance between 25th and 75th
percentile in the box plot are ranging from 0 to 750 units in the
"Seeded" group and 0 to 450 units in the other group.

**Definition**: Checks out that the normality is not met along with
the standard deviations of the population not equal (In this case it
is only possible to measure the standard error of the sample).

**Checklist**: yes; true.

<!-- *One thing I realize now that I don't know is how they are able to -->
<!-- comment on the population based on the sample. The t-tools are based -->
<!-- on population normality equal sd and independence* -->

**Claims**: The conditions of the Agent Orange study do not match the
ideal model on which t-tools are based upon.

**Example**: We look at the box plot of the Vietnam study. We see
again similar trends in outliers as in the last example. The outliers
are >4times the 75th percentile. AKA making making it NON-normal.

In addition the SD or spread, is for both are same ranging from 0 to 8 units. 

**Definition**: Checks out! Only the non-normality is not met.

**Checklist**: yes;true
 

### 3.2.2 Robustness Against Departures from normality (6)

> Underlying normality is not a serious issue, as long as sample size
> are reasonably large.

*no-example*; but it should be possible to simulate in a computer if needed.

> Many empirical investigations and related theory, however confirm
> that the t-tools remain reasonably valid in large samples

*no-example* (in the book).

> If the two populations have same (SD and approximately shapes)[1],
> and if the (sample sizes)[2] are equal, then the (validity of the
> t-tools)[3] is affected moderately by (long-tailedness)[4] and very
> little by (skewness)[5].

> If the two populations have the same standard deviations and
> approximately the same shapes, but if the sample sizes are not
> approximately the same, then the validity of the t-tools is affected
> moderately by long-tailedness and substantially by skewness. The
> adverse effects diminish, however, with increasingly large sample
> sizes.

> If the skewness in the two populations differs considerably, the
> tools can be very misleading with small and moderate sample sizes.

**Claims**: If [1] is same, and if [2] is equal, then [3] is affected
moderately by [4].

**Example**: 1000 computer simulations involving a success criterion
that 95% of the simulations will contain the parameter of interest
were performed. All the populations have the same SD and same sample
sizes.

For a given sample size and SD being equal in the population, we see
that using t-tools we get the following:

| Sample size  | Long tail | Short tail  |  
| ------------ | --------- | ----------- |  
| 5            | 98.3      | 94.5        |  
|              |           |             |  

*I suspect that you are going to ask me what Long tail and short tail
means. The book as some pictures of how it could look but does not
provide actual rules of thumb to identify them.*

**Definition**: Looking at the output it looks like the output is good
for both short tailed and longtailed non normal distributions. I am
not sure it affects at all, let alone moderately. 94.5% is pretty darn
close to 95% (which is the criterion for success).

But the book seems to suggest otherwise: "Only the long-tailed
distribution appears to have success rates poor enough to cause
potentially misleading statements."

**Checklist**: yes; true;
*example-matching-definition*; *unsure*; (book says otherwise)

---

**Claims**: If [1] is same, and if [2] is equal, then [3] is affected
very little by [5].

**Example**: Same example but this time we look at the skewedness.

| Sample size | strongly skewed | mildly skewed |
|-------------|-----------------|---------------|
| 5           | 95.5            | 95.2          |

**Definition**: Looks like it is barely affected as expected in the claim.

<!-- *Until I actually wrote this, I totally believed their claim.* -->

---

**Claims**: If [1] is same, and if [2] is NOT equal, then [3] is affected
moderately by [4].

**Example**: Example not available for this case.

**Definition**: -

**Checklist**: yes; neither;
*no-example*

---
 
**Claims**: If [1] is same, and if [2] is NOT equal, then [3] is
affected substantially by [5].

**Example**: Example not available for this case.

**Definition**: -

**Checklist**: yes; neither; 
*no-example*

---
 
**Claims**: If [5] between the two populations differs considerably,
then the tools can be very misleading with small [2]. 

**Example**: *no-example* 

**Definition**: -

**Checklist**: yes; false; 
*no-example*; 

---
 
**Claims**: If [5] differs considerably, then the tools can be
misleading with moderate [2].

**Example**: -

**Definition**: -

**Checklist**: yes; false;
*no-example*;

---

> Of the five distributions examined, only the long-tailed
> distribution appears to have success rates that are poor enough to
> cause potentialy misleading statements---and even those are not too
> bad. 

**Example**:

| size | strg. skewed | Mod. skewed | mild. skewed | longtailed | shorttailed |
|------|--------------|-------------|--------------|------------|-------------|
| 5    | 95.5         | 95.4        | 95.2         | 98.3       | 94.5        |


**Definition**: The longtailed distribution appears to have only
higher success rates than shorttailed. *How is that a having poor
success rates.* No Idea.

**Checklist**: yes; false; 
*example-not-matching-reality*; *failed* (I don't know if the book
made a mistake or I don't understand something right!)

### 3.2.3 Robustness Against Differing Standard Deviations (3-4)

> In this case, the pooled estimate of standard deviation does not
> estimate any population parameter and the standard error formula
> which uses the pooled estimate of sd, no longer estimates the sd of
> the difference between sample averages.

*no-example* but can be tested using simulations.

---

> (t-tools)[1] remain fairly valid when the (standard deviations are
> unequal)[2], as long as the (sample sizes are roughly the same)[3]. 

**Claims**: If [2] and [3], then [1] remain fairly valid.

**Example**: A computer simulation involving two populations that have
different std.deviations but are normal:

For n1=10 and n2=10, and sigma2/sigma1=1/4; success rate as a result
of simulation is 95.2%.

**Definition**: [1] remains fairly valid due to the 95% success rate.
 
**Checklist**: yes; true; 

---

> (For substantially different sigma's and different n's the CI are
> unreliable)[1] (the worst situation is when the ratio of the sd is much
> different from one and the smaller sized sample is from the
> population with the larger sd)[2].

**Claims**: [1].

**Example**: 

A computer simulation involving two populations that have
different std.deviations but are normal.

For n1=10 and n2=40, and sigma2/sigma1=1/4; success rate as a result
of simulation is 71%.

**Definition**: unreliable indeed.

**Checklist**: yes; true;

---

**Claims**: [2].

**Example**:  Based on 1000 computer simulations on normal distributions.

| n1 | n2 | sd2/sd1 | sd1/sd2 |
|----|----|---------|---------|
| 10 | 40 | 71%     | 99%     |

**Definition**: checks out!

**Checklist**: yes; false;

---
 
### 3.2.4 Robustness against Departures from Independence
### 3.2.4.1 Cluster effects and Serial effects (2-3)

> Cluster effect occurs sometimes when the data have been collected in
> sub groups. For example, 50 experimental anmals may have been
> collected from 10 litters.

I don't know what this effect means or what is the impact.

*no-example* 

> The serial effect: The other type of dependence commonly encountered
> is caused in which measurements are taken over time and observations
> close together in time tend to be more similar than observations
> collected at distant time points. 

*no-example* 


### 3.2.4.2 Effects of lack of independence (3)

> When the independence assumptions are violated, the standard error of
> the difference of averages is an inappropriate estimate of the sd of
> the difference in averages.

*can be tested but I don't know how to simulate dependence/independence*; *no-example* 

> The t-ratio no longer has a t-distribution, and the t-tools may give
> misleading results.

*no-example* 

> It is unwise to use t-tools directly if cluster of serial effects are
> suspected.

*no-example* 

### Resistance of Two-Sample t-Tools
### 3.3.1 Outliers and Resistance (3)

> Long-tailed population distributions are not the only explanation for
> outliers.

**Example**: Contamination could be another reason for an outlier.

In the Agent Orange study about US veterans and Dioxin, 2 outliers are
identified. The sample was about people who were in vietnam in Orange rich
zones. The two outliers in this study were, one of them was not exposed
to herbicides during his stay in Vietnam. The other had 180 days of
indirect military exposure to herbicides.

**Definition**: checks out

**Checklist**: yes; true.

---

> It is irrelevant to distinguish between a natural long-tailed
> distribution and the one that includes outliers that result from
> contamination.

*no-example* *The idea is that it becomes irrelevant because they
both don't capture the group behavior.* 

> It is useful to know how sensitive a statistical procedure may be to
> one or two outlying observations.

**Example**: We comeback to the same Agent Orange data. We have two
outliers here. The sample size is >600 in the case of veterans in
Vietnam. 

The one-sided p-value is 40% with all observations, 48% with one
outlier removed and 54% with both outliers removed.

**Definition**: Although the conclusion didn't change regarding
rejecting or accepting an hypothesis, the variation is quite large
between keeping outliers despite the large number of the sample.

This example I think checks out that it is useful. I think this
example is instrumental in showing the havoc, outliers can breathe when
values become closer to the "cutoff"(say 5%)

**Checklist**: yes; true;

### 3.3.2 Resistance of t-tools (2)

> Since t-tools are based on averages, they are not resistant 

**Example**: ~~In a hypothetical sample of 10,20,30,50,70, the sample
average is 36, and the sample median is 30. Now change the 70 to 700,
and we see that the average becomes 162, but the sample median remains
30.~~

*no-example* 

**Definition**: -

**Checklist**: yes; true; 
*no-example*;*because-should-due-to*; *example-matching-subject*; *unsure*;

---

> one or two outliers can affect the CI or change the p-value enough
> to completely alter a conclusion.

*no-example* 


### 3.4 Practical Strategies for the two-sample problem
### 3.4.1 Consider Serial cluster effects (1)

> Were the subjects selected in distinct groups? Were different Groups
> of subjects treated differently in a way that was unrelated to the
> primary treatment? Were different responses merely repeated
> measurements of the same subjects? Were observations taken at
> different but proximate times or locations? Affirmative answers to any
> of these questions suggest that independence may be lacking.

**Claims**: If the answer to above questions is yes then it suggests
that independence may be lacking.

**Checklist**: yes; neither;
*no-example*; *definition-unclear*; *failed* (*should know how to check for
independence but not given in the text clearly*)
 
---

### 3.4.2 Evaluate the suitability of the t-tools (1)

> A (transformation)[2] should be considered if the (graphical displays of
> the transformed data appear to be closer to the ideal conditions)[1].

**Subject**: If [1], Should [2] be done?

**Predicate**: should be considered.

**Example**: We go back to the Cloud seeding case study. We see in the
normal box plots that both the groups look "skewed". And the spread
(SD) looks much larger for the seeded one. 

When we make this into a logarithm chart we see that immediately the
spread looks very similar, the skewness vanishes (closer to normal
looking). These are conditions that are close to what the t-tools are
created based on.

**Definition**: Checks out. We should consider it as the
transformation could make your data look more applicable to the t-tools.

*Something more nicer would be to check the results of using the
actual values and the transformed values and seeing how different the
results are.*

**Checklist**: yes; true;
*example-matching-definition*; *unsure*;
*because-should-due-to*;*unsure* (unsure if I can give this example)


### 3.4.3 A strategy for Dealing with Outliers (2)

> If investigation reveals that an outlying observation was recorded
> improperly or was the result of contamination from another population,
> the solution is to correct it if the right value is known or to leave
> it out.

**Example**: We comeback to the same Agent Orange study. We have two
outliers here. The sample size is >600 in the case of veterans in
Vietnam. 

The one-sided p-value is 40% with all observations, 48% with one
outlier removed and 54% with both outliers removed.

Here even though it does not affect the conclusion of this study, the
variation in the p-value is 14%.

**Definition**: Quite a large variation, and by removing them we are
more closer to the truth (without contaminants).

*This is the best example I have, unfortunately it doesn't show a
failing case.*

**Checklist**: yes; neither;
*example-matching-definition*; *unsure* 

> An important aspect of adopting this procedure is that an outlier
> does not get swept under the rug simply ~~because it is different from
> the other observations.~~

**Claims**: Using careful examination as shown in fig.3.7, we prevent
contaminants from influencing the result.

**Subject**: Using careful examination

**Predicate**: prevent contaminants from influencing the result.

**Example**: We take the same example as before.

**Definition**: Checks out.

**Checklist**: yes;true;
*example-matching-definition*; *unsure*; *subject-predicate-split*;
*unsure*; *time* (15 mins)

### 3.4.4 Agent orange (2)

> the skewess is mild and unlikely to cause any problems with the
> t-test or the CI (for the Agent orange study)

**Claims**: the skewness in Agent Orange study is mild

**Example**: We look at the skewness on pg67. Here the tail is long on
one side and there seems to be a smaller tail on the other side. 

**Definition**: Looking at the picture on pg61 describing mildly
skewness, we see that a mild skewness looks such that there are tails
on both sides, but the tail on one side is shorter.

*Yes it seems quite subjective, as the book does not seem to want to
quantify it*

**Checklist**: yes; true.
 
---

**Claims**: The skewness is unlikely to cause any problems with t-test
or the CI.

**Example**: *It is possible to run a computer simulation on a similar
problem based on this skewness and number of units in a sample, to
test it. But not for this exact study.*

**Definition**: -

**Checklist**: yes; neither
*no-example* 

### Transformations of the Data
### 3.5.1 The Logarithmic Transformation (1)

> The most useful transformation is the logarithm for positive data.

*It is unclear against what dimensions this is most useful. I could
probably show in an example, say with the Vietnam war study, that log
works better in this case, but going to MOST from here I have no idea
how to go about it. *

**Checklist**: yes; neither; most; 
*no-example* ;*failed* 

### 3.5.1.1 Recognizing the need for Log (5)

> The data themselves usually suggest the need for a log
> transformation. If the ratio of the largest to the smallest
> measurement in a group is greater than 10, then the data are
> probably more conveniently expressed on the log scale. If the
> (graphical displays of the two samples show them both to be skewed)[1]
> and if (the group with the larger average also has the larger spread)[2],
> the (log transformation)[3] is likely to be a good choice.

**Claims**:  If [1] and [2], then [3] is a good choice.

**Example**: We take the cloud seeding example. We plot the box data
and see that the data is "moderately skewed" (according to some
graphical display on pg61). Also the seeded group has much larger
spread (median @250 and extreme at 2500), than unseeded (medain @150
and extreme at 1250).

Taking log transforms we get two groups that have the same spread and
no skewness.

**Definition**: The initial groups wouldn't work with t-tools due to
long-tailedness of the sample (as seen before). After transformation
they would work with t-tools as there is no skewness or
long-tailedness and both groups have the same spread, which is what
the t-tools can work well on.

*Ideally we would like the result from using t-tools for the data
without transforms and the data with transforms and compare it to
reality. But that is going to have to be a computer simulation and
can't be done with this data.*

**Checklist**: yes; true;
*example-matching-definition*; *time* (20mins).

Post picture of unseeded and seeded during 3rd run down.
<!-- !!! add picture -->

> The overall result is that the (two distributions on the transformed
> scale)[1] appear to be (symmetric and have equal spread)[2]--- just the right
> conditions for applying the t-tools.

**Claims**: [1] appears to be [2].

**Example**: Same example as above.

**Definition**: checks out.

**Checklist**: yes;true
 
 ---

**Claims**: If two distributions have symmetric and equal spread, then
they have right conditions for applying t-tools.

**Example**: *Don't have an example. A computer simulation providing
the success rate would be the check.*

**Definition**: -

**Checklist**: yes; neither;
*no-example* 

> Small numbers get spread out more, while large numbers are squeezed
> more closely together (as a result of log transformation)

**Example**: If you look at a log plot and divide it equally... then
this is what you see...

1-10 say corresponds to 2units. 10 to 100 has the same 2 units. And 100 to 1000 has the same 2 units.

**Definition**: checks out!

**Checklist**: yes; true

---

### 3.5.2 Interpretation after a Log Transformation (1)

> For some measurements, the results of an analysis are appropriately
> presented on the transformed scale. 

**Example**: The richter scale used to measure earthquakes strength.

**Definition**: checks out.

**Checklist**: yes; true;

---

### 3.5.2.1 Randomized experiment model
### 3.5.2.2 Population model (5)

~~> Mean of logged values is not the log of the mean~~

> Taking the (antilogarithm of the estimate of the mean on the log
> scale)[1] does not give (an estimate of the mean on the original
> scale)[2].

**Example**: For [1] : 169.01 for the seeded case in the
cloud seeding example.

	exp(mean(df$lograin[df$Treatment=="Seeded"]))
	
For [2], we compute the mean of the rainfall in the original scale = 441

	mean(df$Rainfall[df$Treatment=="Seeded"])

**Definition**: Checks out!

**Checklist**: yes; neither; 
*definition-unclear*; *time* (20mins)

---

> A problem with interpretation on the original scale arises because
> of the previous claim.

*because-should-due-to* 

**Claims**: (A problem with interpretation on the original scale)[2] arises
if we use (log transformation)[1].

**Subject**: If [1], [2].

**Predicate**: is there.

**Example**: don't know what the problem is and don't have an example
for now.

<!-- come back ??? -->

**Definition**: 

**Checklist**: 

---


> If, log-transformed data have symmetric distributions, then 
> Mean[logY] = Median[logY]

**Example**: 

	summary(df$lograin[df$Treatment=="Seeded"])
	Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
	1.411   4.581   5.396   5.134   6.001   7.918

**Definition**: Although this treatment does not result in totally
symmetric distribution (still has a small tail on one side), it still
manages to keep the median and mean close by.

**Checklist**: yes; true;

---
 
> It is evident that (the anti logarithm of the mean of the log
> values)[1] is the (median on the original scale of measurements)[2].

**Example**: We think of the same cloud seeding example:

For [1] we think of

	exp(mean(df$lograin[df$Treatment=="Unseeded"]))
	= 54
	
For [2] we think of 

	median(df$Rainfall[df$Treatment=="Unseeded"])
	= 44

**Definition**: 

	summary(df$Rainfall[df$Treatment=="Unseeded"])
	Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
	1.00   24.82   44.20  164.59  159.20 1202.60 

The data taken is not fully symmetric. It still has some
tails. Despite that [1] is a close match to the median in the normal
scale.

**Checklist**: yes;true;

--- 

> `exp(Z2bar-Z1bar)`estimates `Median(Y2)/Median(Y1)`

**Claims**: ^^

**Example**: *Either I can simulate and show this using computer
simulations in R. OR I provide the proof as in the text book. Proof is
not an example. So the best I can do is a Computer simulation.*

**Definition**: -

**Checklist**: yes; neither;
*no-example*;
 
---

> the point of the above is that a very useful multiplicative
> interpretation emerges in terms of the ratio of population medians.

**Claims**: (multiplicative interpretation in terms of the ratio of
population medians)[1], emerges from the (previous claim)[2].

**Question**: Does [1] emerge from [2].

**Example**: 

**Definition**: 

**Checklist**: yes; neither;
*no-example*; *failed*; *time*; *example-matching-subject*; *failed*;
*emerges*; *failed*; (Very hard, very long to wrap my head around,
requires a lot of my focus. Unable to proceed now).

---

**Claims**: The emerged multiplicative interpretation is very useful.

**Example**: After using the log transformation and performing the
t-test on the Cloud seeding data, we see that the confidence interval
suggests that the rainfall is 1.27 times to 7.74 times higher in the
case of seeded.

**Definition**: The log transformation seems to allow to interpret the
original data in terms of ratio which is useful to understand the
outcome. Not sure how it is "very useful"

**Checklist**: yes; neither;
*missed-comparison*; *unsure*; *definition-unclear*;

---

> In addition, (back-transforming the ends of a confidence interval
> constructed on the log scale)[1] produces a (confidence interval for the
> ratio of medians)[2]

**Example**: No example.

*The only way to show this seems to be through a computer
simulation. With the studies given in the book, it is not possible to
tally this claim. For example, with the Cloud seeded study, I can
compute the confidence intervals on the log scale and back transform
it. To check if the number produces a CI of the ratio of medians I
have nothing to check it against.*

**Definition**: -

**Checklist**: yes; neither; 
*no-example*; *unsure*;

### 3.5.2.3 Example (sex discrimination) (1)

> Graphical displays of the log-transformed salaries indicate that
> analysis would also be suitable on the log scale.

**Example**: Looking at the male and female histograms

1. `hist(df$logSalary[df$Sex=="Male"])`

Looks symmetric with very short tail (very little skewness and
short-tailed histogram). The spread ranges from 8.4 to 9.0 = 0.6

2. `hist(df$logSalary[df$Sex=="Female"])`

Has a small tail (mildly skewed and short-tailed histogram). The
spread ranges from 8.26 to 8.74 =0.48 

**Definition**: Both histograms seem to be close to normal and have
similar spread and , which are roughly ideal conditions for applying
t-tools hence make analysis also suitable for the log scale. 

**Checklist**: yes; true.

---
### 3.5.3 Other transformations for Positive measurements (5)

> There are other useful transformations for positive measurements
> with skewed distributions where the means and standard deviations
> differ between groups.

*no-example* *No example of actually applying another transformation
is given.* 

> The square root transformation applies to data that are counts.

*no-example* 

> The reciprocal transformation 1/Y applies to data that are waiting
> time

*no-example* 

> The arcsine square root transformation and the logit transformation
> apply when the measurements are proportions between zero and one.

*no-example* 

> Only log gives such ease in converting inferences back to the
> original scale of measurement.

*no-example* 

> Situations arise where presenting results in terms of population
> medians is not sufficient.

*no-example* 

### Related Issues
### 3.6.1 Prefer Graphical Methods over Formal Tests for Model (3)
Adequacy

> Tests for normality and tests for equal sd are available in most
> computer programs.

*no-example* 

> The diagnostic tests are not very helpful for model checking.

*no-example* 

> Graphical displays provide a good indication of whether or not the
> data are amenable to t-analysis and, if not, they often suggest a
> remedy.

**Subject**: What Graphical displays provide

**Predicate**:  a good indication of ... t-analysis

**Example**: ~~On pg61, we see different types of graphs (short-tailed,
long-tailed, mildly-skewed, overly-skewed) and their resulting success
rates. In p63, we see that look at graphs we are able to get informed about
the spread (aka SD)~~

*I don't think the above is an example. What we need is a computer
simulation with different distributions and checking the result of the
graphical analysis against what is expected.*

**Definition**: -checks out?

**Checklist**: yes; neither;
*example-matching-subject*; *unsure*;


### 3.6.2 Robustness and Transformation for Paired t-Tools (2)

> When the (observations within each pair are positive)[1], either (an
> apparent multiplicative treatment effect (in an experiment))[2] or a
> tendency for larger differences in pairs with larger average values
> suggest the use of log transformation.

*Dealt with similar claim*



### 3.6.3 Example-Schizophrenia
### Summary (1)

> This is the situation where log-transformation confirms the adequacy
> of the transformation.

*claim discussed before*

## Summary

mean of sampling distribution of average = mean of distribution

SD(sampling distribution) = SD(population)/sqrt(n)

## 50% work on same problem
## Identify the problems and isolate them and work on them alone
## Notes

- I feel that I am not taking too seriously every single sentence,
  unless it is claims of importance.. For example they talk abotu IJ
  GOOd an what he expects to happen in the future.
  
  Who cares? What are the claims? are there examples for it? moving on!
## Experiment

So The point of this excercise seems to be that we need to see how we
are performing.

I want to identify where I am having trouble. make statistics.

I want to finish the essay 3 more claims

Once I identify where I am having trouble I should look at the last
essay and check out what the outcome of that was.

More so,,,,, I need to statistics. Identify type and successrate of
type.


- Grammar check
- understandability check 


Let's start by looking at the diff stuffs. Let's identify each claim?
lets give it names. Look at the last essay of where I see myself failing.


- how to make life easier for me.

- add additional claims for getting until 

## Statistics Superintelligence

| chapter | time | phrases | dist | claims | pages | mins/phr | mins/page |
|---------|------|---------|------|--------|-------|----------|-----------|
| 2.2     | 10   | 2       | 1    | 1      | (6)   | 5        |           |
| 2.3     | 60   |         | 5    |        | 8     |          | 7.5       |
| 2.3     | 21   | 2       | 0    |        | (8)   | 10       |           |
| 2.4     | 20   |         | 1    |        | 4     |          | 6.25      |
| 2.5     | 15   |         | 1    |        | 3     | 5        |           |
| 2.4 2.5 | 20   |         | 2    |        |       | 4        |           |
| 3       | 27   |         |      |        | 5     |          | 5.4       |
| 3       | 60   |         | 13   |        | 6     |          | 10        |
| 3       | 159  | 34      | 9    |        |       | 4.67     |           |

4.6 phrases/hour phrases including reading

15 hrs and 30 claims i.e., ~70 phrases

## Statistics Statistical sleuth
	
do excercise

| chapter   | time  | phrases | dist | claims | pages | mins/phr | mins/pg |       |
|-----------|-------|---------|------|--------|-------|----------|---------|-------|
| 1.1.1     | 19    |         |      |        | 3     |          | 6.3     |       |
| 1.1.1     | 40    | 2       |      | 1      |       | 20       |         |       |
| 1.1.2     | 7     |         |      |        | 2     |          | 3.5     |       |
| 1.1.2     | 22    | 2       |      | 1      |       | 11.5     |         |       |
| 1.2.1,.2  | 60    |         | 2    |        | 4     |          | 15      |       |
| 1.2.1,2   | 90    | 16      | 8    | 8      |       | 5.6      |         |       |
| "         | 60    | 3       | 2    | 2      |       | 20       |         |       |
| ""        | 25    | 6       | 1    | 3      |       | 4.16     |         |       |
| 1.3.1,2   | 40    |         | 8    |        | 4.5   |          | 8.8     |       |
| 1.4       | 24    |         | 4    |        | 2     |          | 12      | 3/09  |
| 1.5.1     | 48    |         | 9    |        | 5     |          | 9.6     | 3/09  |
| 1.2.3     | 90    | 8       | 10   | 4      |       | 11.25    |         | 3/09  |
| 1.2.3     | 80    | 6       | 9    | 3      |       | 13.3     |         | 4/09  |
| 1.3.1,2   | 90    | 9       | 11   | 4      |       | 10       |         | 4/09  |
| 1.4,1.5   | 80    | 9       | 11   | 4 (3)  |       | 8.88     |         | 4/09  |
| 1.5       | 75    | 12      | 15   | 6      |       | 6.25     |         | 5/09  |
| 2.1,2*    | 46    |         |      |        | 7     |          | 6.57    | 7/09  |
| 2.1       | 45    | 4       | 7    | 2      |       | 11.25    |         | 7/09  |
| 2.2       | 90    | 8       | 8    | 4      |       |          |         | 7/09  |
| 2.2.4,2.3 | 54    |         |      |        | 8     |          | 6.75    | 8/09  |
| ^^        | 27    |         |      |        | 3     |          | 9       | 8/09  |
| ^^        | 30    |         |      |        | 4     |          |         | 8/09  |
| ^^        | 90    | 3       |      | 1      |       |          |         | 8/09  |
| ^^        | 100   | 4       | 7    | 2      |       | 25       |         | 9/09  |
| ^^        | 28    | 2       | 2    | 1      |       |          |         | 9/09  |
| ^^        | 80    | 0       | 9    | 0      |       |          |         | 9/09  |
| ^^        | 120   | 2       | 8    | 1      |       | 75       |         | 10/09 |
| ^^        | 45    | 3       |      | 1      |       | 15       |         | 11/09 |
| ^^        | 60    | 4       | 9    | 2      |       | 15       |         | 11/09 |
| 3.1,3.2   | 50    |         | 9    |        | 7     |          | 7.14    | 12/09 |
|           | 33    |         |      |        | 4.5   |          | 6.66    | 12/09 |
|           | 60    |         | 9    |        | 5     |          | 12      | 14/09 |
|           | 13    |         | 3    |        | 2.75  |          | 4.7     | 14/09 |
|           | 97    | 18      | 8    | 9      |       | 5.38     |         | 15/09 |
| pr**      | 52    | 20      | 2    | 10     |       | 2.6      |         | 15/09 |
|           | 35    | 10      | 2    | 5      |       | 3.5      |         | 15/09 |
|           | 62    | 18      | 7    | 9      |       | 3.4      |         | 16/09 |
|           | 62*** | 10      | 6    | 5      |       | 6.2      |         | 16/09 |
|           | 66    | 14      | 7    | 7      |       | 4.17     |         | 16/09 |
|           | 18    | 6       | 6    | 3      |       | 3        |         | 16/09 |
|           |       |         |      |        |       |          |         |       |

*2 pages of images
** started skipping claims if I had no example, and if I could see the
level to which if needed I could run a simulation. The goal seems to
be to think inexamples as much as possible. Simply skip claims or mark
them as no example. Also, I stopeed writing the whole thing. Am done
with the setup! Feels better too.
30 mins 900 words while listening to music.

*** took some time due to puzzling as well as using R to setup and
make shit happen Pnn!

## Corrections

| date  | type | time | Claims | phrases | dist | min/phr | min/dist | words/min |
|-------|------|------|--------|---------|------|---------|----------|-----------|
| 17/09 | IC   | 44   | 2      | 4       | 4    | 11      | 11       |           |
| 17/09 |      |      |        |         |      |         |          |           |
| 18/09 |      | 60   | 10     |         | 7    | 3       | 8.5      |           |
| 18/09 |      | 72   | 4      | 8       | 6    | 9       | 12       |           |
| 18/09 |      | 60   | 4      | 8       | 4    | 7.5     | 15       |           |
| 19/09 |      | 54   | 4      | 8       | 7    | 6.75    | 7.7      |           |
| 19/09 |      | 56   | 14     | 28      | 9    | 2       | 6.2      |           |
| 19/09 |      | 53   | 9      | 18      | 8    | 2.94    | 6.6      |           |
| 21/09 |      | 60   | 10     | 20      | 10   | 3       | 6        |           |
| 21/09 |      | 90   | 8      | 16      | 12   | 5.6     | 7.5      |           |
| 21/09 |      | 63   | 15     | 30      | 12   | 2.1     | 5.25     |           |
| 21/09 |      | 28   | 7      | 14      | 8    | 2       | 3.5      |           |
| 21/09 |      | 62   | 9      | 18      | 10   | 3.4     | 6.2      |           |
| 22/09 |      | 30   | 1      | 2       | 3    | 15      | 10       |           |
| 22/09 |      | 30   | 5      | 10      | 4    | 3       | 7.5      |           |
| 23/09 | SI   | 60   | 10     | 20      | 15   | 3       | 4        |           |
| 23/09 | SI   | 45   | 10     | 20      | 7    | 2.25    | 6.42     |           |


## First feedback
exmade
19

noex
16

ens
2

deun
3

mico
3

suprsp
5

exmasu
10

cuz
3

fai
56

tot
134

## part 2 statistics

3 types in 40 mins with X number of distractions

| what  | time | claims | dist | mins/claims | mins/dist |
|-------|------|--------|------|-------------|-----------|
| *find | 40   | 3      | 10   | 13.3        | 4         |
| *     | 60   | 3      | 7    |             |           |
|       | 60   | 3      | 7    |             |           |
|       | 56   | 7      | 9    | 8           | 6.2       |
|       | 60   | 4      | 13   | 15          | ~5        |
|       | 45   | 4      | 11   | 11.25       | 4         |
| fwoex |      |        |      |             |           |

*find --> finding things to work on

## todo

- stm reply ages back on less wrong!
- work on failures
- which content to work on? the book or jblevins stuff?

- **identify failures from previous post and check if we failed?**

Identify patterns and inform failure! Make simple statistic on number
of failures over 133 claims.. type of failures and claims.

check if tru or false is rightly written

### Real todo

#### new
- failures post clean up(34 claims only) (3hrs) [maybe skip this or do
  a short version of it]
- 100 claims practicing failures 15hrs
- rework (5hrs)
- grammar (2 hrs)
- statistics (2hrs)

by friday night! post it bitch

#### old
- grammar
- identify which claim is what

## Where the examples are hidden at?

Today I am working and trying to explain to a colleague. Why something
works and he doesn't want to accept it. I am telling him I thought
about it and what I say is right. He asked me why the tooling flange
and the actual flange were not connected in the diagram. I told him
they are, via "repros". i.e., I made a claim, and I openly said, I
have no idea how to prove it. I didn't know how I was going to find an
example. It was going to be impossible to find an example or test it
you know. but I had to convince him and more importantly convince
myself.

Me having spent so many hours FAILED majorly, when my boy pointed out
something. 

He made a change to the tooling and asked me if there is any
difference. i.e., we took a real example... that we could test on
whole tolerance train, albeit with "logic". That was it. I was
convinced. Any change we did, to the tooling the result was
agnostic. And taking that motherfucking example with dovel pins, made
everything so much more clear for me.

Same thing a couple of days back I was making tolerance trains with
blocks.. I made a couple and in the end I said fuck this shit. I don't
work with boxes I work with actual parts. So I drew them to get a feel
of what they would look like and what the box represented.

## Beliefs

### beliefs about right or wrong (24)

> (Crime)[0] should (not pay)[1], is (very simple common sense)[2].
>
> Claims: Crime should not pay
>
> Definition: checks out I think!

**STM**: This is a predicate based on his beliefs about what is right
and wrong, not on empirical examples. “Crime does not pay” is a
predicate about the world and it would be false if the average crime
led to a lot of money without imprisonment. “Crime should not pay” can
be skipped for now. (“The Holy B says that crime should not pay” is
testable, though.)

**Pattern**: "is common sense" or similar?

**Source**: https://youtu.be/g-9TdoU4Ay8?t=2683

> If (you want to create a different pronoun for people who are
> intrasex)[1], that makes some sense to me.

**Claims**: [1] makes some sense to me.

**Subject**: If [1], what it does to me

**Predicate**: makes some sense to me.

**Checklist**: no; neither;
*no-example*; *belief-about-right-wrong*;

**Pattern**: "A" makes sense to me.

---

> But you do not get to (redefine fundamental terms of human biology)[1]
> simply because you have (a subjective feeling about yourself)[2], is my
> main objection.

**Claims**: You do not get to [1].

**Subject**: What you do not get to do.

**Predicate**: [1].

**Checklist**: no; neither;
*no-example* ; *belief-about-right-wrong*; *time* (10mins)

**Pattern**: You do not get to do X.

--- 
> People can say what they want particularly when (it happens to be
> true)[1]

**Claims**: People can say what they want when [1] 

**Checklist**: no; neither;
*no-example*; *belief-about-right-wrong*; *time*; (5mins)

**Pattern**: People can do/say X.

---

> Right now they are trying to take title nine and apply to
> transgender people, which makes no sense at all.

**Claims**: Applying title nine to trans people makes no sense at all.

**Checklist**: no; neither;
*belief-about-right-wrong*;

**Pattern**: A makes sense.

---

> I don't understand (how you can simultaneously claim that you are a
> feminist standing up for women and also claim that a man can be a
> women)[1]. That is (puzzling to me)[2]. There are (lot of internal
> contradictions here)[3], logically speaking

**Claims**: [1] is [2].

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: A is puzzling to me.

---

**Claims**: There are [3], when logically speaking.

**Checklist**: yes; neither;  
*not-a-belief-about-right-wrong*; *definition-unclear*;

---

> What I do care about is (when my 5-year old daughter is in a bathroom
> with my wife see Logan paul (who identifies as a woman) in the
> bathroom)[1]. Is my wife wrong to feel a threat, The answer I think is
> no. Why in the world would she be wrong to feel a threat

**Claims**: I care about [1].

**Checklist**: yes; neither; 
*not-a-belief-about-right-wrong*

---

**Claims**: My wife is not wrong to feel the threat when [1].

**Checklist**: no; neither;  
*belief-about-right-wrong*

**Pattern**: X is wrong/right.

---

> it argues to me that there should be (a different level (lesser) of threat
> when my wife and child see a someone with hormone treatment who look
> like a female)[1].

**Claims**: There is [1].

**Subject**: When wife perceives a man to be a female, what the level
of threat she perceives is.

**Predicate**: lesser than that of a male.

**Checklist**: yes; neither;  
*because-should-due-to*; *not-a-belief-about-right-wrong* 

---

> (The same people who are arguing that women ought to be afraid of
> toxic masculinity are arguing that a man can be a woman)[1]. How is that
> even logically coherent?

**Claims**: [1] 

**Checklist**: yes; neither;  
*not-a-belief-about-right-wrong*

---

**Claims**: [1] is not logically coherent.

*Author suggests some hypocritism. I guess I can check for it.*

**Checklist**: yes; neither;  
*not-a-belief-about-right-wrong*; 

---

> You feel (pretty safe when we have one room but the toilets are all
> locked off)[1]

**Claims**: You feel [1]

**Checklist**: yes; neither;  
*not-a-belief-about-right-wrong*

---

> I think when we lock it away and say there's no improvements we can
> make to that system, that's where it can kind of become very
> segregating.

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> If you want to come up with solutions that make sense, I am all for
> it.

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: if X makes sense then Y

---

> I am completely at peace with new age identification systems with
> gay marriage.

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> I support gay marriage

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> I am a huge fan of the LGBTQ community

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> The problem that I see, is that (once you start encoding that in
> state law, the next move is to call everyone who disagrees, a bigot
> and to remove their tax-exempt status)[1]

**Claims**: [1]

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> As a libertarian I find this very scary.

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong* 

---

> (People should be allowed to do whatever they want)[1]. (I don't owe
> you a duty to bake you a cake)[2]. You don't like my way of baking a
> cake, go find some other baker.

**Claims**: [1] 

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: A should be allowed to do B.

---

**Claims**: [2]

**Checklist**: yes; neither;
*not-a-belief-about-right-wrong*; *unsure*

---

> If you don't have a claim on me and yet you are pointing a
> government gun at me, you are the bad guy in the scenario

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: You are bad.

---

> If I say that you owe me, you have to make dinner tonight and you
> don't want to make me dinner, so I get the government to point a gun
> at you and you make me dinner, I think I am the bad guy.

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: You are bad.

---

> (Businesses)[1] should be allowed to (do bad things that I don't like
> (like not serving gay people), so long as they are not forcing me to
> do anything.)[2]

**Claims**: [1] are to be allowed to [2].

**Checklist**: no; neither;  
*belief-about-right-wrong* 

**Pattern**: A should not be allowed to do B

---

> "People able to boycott things like discrimination", I think is a good
> part of American discourse.

**Claims**: ^^

**Checklist**: no; neither;  
*belief-about-right-wrong* 

---

## future with and without examples

**Source**:
https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/



> There is no doubting the force of [the] arguments … the problem is a
> research challenge worthy of the next generation’s best mathematical
> talent. (Human civilisation is at stake.)[1]

**Claims**: [1]

**Checklist**: no; neither;  
*future-without-example;

**Pattern**: about the future; X is at stake; 

Examples about the future, examples that predict the future; cases
where there are no examples from the past, i.e., it is new, all seem
to fall under this category. I think the goal here shall be to see if
things can be tested or not. For example the below example cannot be
tested. There is no AI unfortunately to test your shit on and see if
HC is at stake. (I realize this only during re-reading my work.)

---

> A growing number of experts believe that (a third revolution will occur
> during the 21st century)[1], through the invention of machines with
> intelligence which far surpasses our own.

**Claims**: [1] 

**Checklist**: no; neither;  
*future-without-example*;

**Pattern**: about the future; *will*

---

> Rapid progress in machine learning has raised the prospect that
> (algorithms will one day be able to do most or all of the mental
> tasks currently performed by humans)[1].

**Claims**: [1] 

**Checklist**: no; neither;  
*future-without-example*;

**Pattern**: about the future; *will*

---

> This could ultimately lead to machines that are much better at these
> tasks than humans.

**Claims**: ^^

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *could lead to*

---

> (These advances could lead to extremely positive developments,
> presenting solutions to now-intractable global problems)[1], but
> (they also pose severe risks)[2].

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *could lead to*

---

**Claims**: [2] 

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; implied *could*

---

> (If machines surpass humans in intelligence)[1], then just as the fate of
> gorillas currently depends on the actions of humans, (the fate of
> humanity may come to depend more on the actions of machines than our
> own.)[2]

**Claims**: If [1], [2].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *may come to*

---

> (This might be the most important transition of the next century)[1] –
> either ushering in an unprecedented era of wealth and progress, or
> heralding disaster.

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *might be*

---

> We’ve also come to believe (the technical challenge can probably be
> overcome if humanity puts in the effort)[1].

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *can probably*?

---

> (Working on a newly recognized problem)[1] means that (you risk
> throwing yourself at an issue that never materializes or is solved
> easily)[2] – but it also means that (you may have a bigger impact by
> pioneering an area others have yet to properly appreciate, just like
> many of the highest impact people in history have done.)[3]

**Claims**: [1] means [2].

*Can possibly give an example from the past*

**Checklist**: yes; neither; 
*no-example* 

---

**Claims**: [3] 

**Checklist**: yes; neither; 
*no-example* 

---

> Many experts believe that (there is a significant chance that humanity
> will develop machines more intelligent than ourselves during the 21st
> century)[1]. (This could lead to large, rapid improvements in human
> welfare, but there are good reasons to think that it could also lead
> to disastrous outcomes)[2]. 


**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *will*

---

**Claims**: [2].

**Checklist**: no; neither;  no; neither;
*future-without-example*

**Pattern**: about the future; *could lead to*

---

> (If AI research continues to advance without enough work going into the
> research problem of controlling such machines, catastrophic accidents
> are much more likely to occur.)[1]

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *are likely*; AI

---

> (We estimate that the risk of a serious catastrophe caused by machine
> intelligence within the next 100 years is between 1 and 10%.)[1]

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *prediction of future*; *machine intelligence*

---

> We think a doubling of effort would reduce the size of the existing
> risk by around 1%.

**Claims**: [1].

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; *prediction of future*; 

---

**New article on 80k:**
https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/

> Those organizations have an interest in making sure that AI is as
> beneficial as possible, and they’re keenly aware of the fact that
> they can be misused and that (there might be accident risks
> associated with them)[1].

**Claims**: [1] 

**Subject**: Accident risks associated with AI

**Predicate**: might exist.

**Example**: 

> By the afternoon of May, 6, 2010, US equity markets were already
> down 4% on worries about the European debt crisis. At 2:32 p.m., a
> large seller (a mu- tual fund complex) initiated a sell algorithm to
> dispose of a large number of the ­E-Mini S&P 500 futures contracts
> to be sold off at a sell rate linked to a measure of
> minute-to-minute liquidity on the exchange. These contracts were
> bought by algorithmic high-frequency traders, which were programmed
> to quickly eliminate their temporary long positions by selling the
> contracts on to other traders. With demand from fundamental buyers
> slacking, the algorithmic traders started to sell the E-Minis
> primarily to other algorithmic traders, which in turn passed them on
> to other algorithmic traders, creating a “hot potato” effect driving
> up trad- ing volume—­this being interpreted by the sell algorithm as
> an indicator of high liquidity, prompting it to increase the rate at
> which it was putting E-Mini contracts on the market, pushing the
> downward spiral. At some point, the high-frequency traders started
> withdrawing from the market, drying up liquidity while prices con-
> tinued to fall. At 2:45 p.m., trading on the E-Mini was halted by an
> automatic circuit breaker, the exchange’s stop logic
> functionality. When trading was restarted, a mere five seconds
> later, prices stabilized and soon began to recover most of the
> losses. But for a while, at the trough of the crisis, a trillion
> dollars had been wiped off the market, and spillover effects had led
> to a substantial number of trades in in- dividual securities being
> executed at “absurd” prices, such as one cent or 100,000
> dollars. After the market closed for the day, representatives of the
> exchanges met with regulators and decided to break all trades that
> had been executed at prices 60% or more away from their pre-crisis
> levels (deeming such transactions “clearly erroneous” and thus
> subject to post facto cancellation under existing trade rules). ---
> SuperIntelligence chapter 1.

**Definition**: checks out! 

**Checklist**: yes; true; 
*future-with-example*;

**Pattern**: about the future; *might*

---

**Source**: https://80000hours.org/articles/us-ai-policy/

> one of the most impactful things that people can work on is ensuring
> that the transition to a world with advanced AI technology benefits
> all of humanity.

**Claims**: ^^

**Checklist**: no; neither;  
*future-without-example* 

**Pattern**: about the future; transitioning to a world with advanced
AI.

---

**Claims**: AI safety needs progress

*This can be tested assuming I think, if AI they talk about is the
current existing technologies*

**Checklist**: yes; neither;  
*no-example*; *not-future-without-example* ; *unsure* 

---

**Claims**: AI policy needs progress

**Checklist**: yes; neither;  
*no-example*; *not-future-without-example* ; *unsure*  

---

> (ensuring that advanced AI, benefits all humanity, requires
> substantial progress to be made on both AI safety and AI policy)[1],
> particularly work with a longer-term perspective that considers more
> advanced AI systems.

**Claims**: [1].

**Checklist**: not-sure; neither; 
*no-example*; *future-without-example*; *time* 

**Pattern**: *advanced AI*; X needs progress

*So here I spent 20 mins figuring out if it is a claim of the
future just like ("human civilization is at stake").*

---

> One element of this coordination problem is that the perceived
> rewards from (accelerating the development of AI capabilities may
> create a race-to-the-bottom)[1].

**Claims**: [1].

**Checklist**: yes; neither; *no-example* 
*future-with-example*; *time*

**Pattern**:  *may*

---

> Racing in this way may be counterproductive even from actors’
> self-interest.

**Claims**: ^^

**Checklist**: yes; neither; *no-example* 
*future-with-example*; *time* 

**Pattern**:  *may*

---

> (Perceptions or misperceptions of a race could exacerbate rivalrous
> development)[1], as the nuclear arms race did during the cold war,
> potentially even leading to conflict.

**Claims**: [1].

**Example**: nuclear arms race during cold war.

**Checklist**: yes; neither;  
*future-with-example*

**Pattern**: about the future; *could*

---

**Claims**: [1] could lead to conflict

**Example**: nuclear arms race during cold war.

**Checklist**: yes; neither;  
*future-with-example* 

**Pattern**:  *could lead to*

---

> (In such a scenario, a lack of coordination risks a worst-case outcome
> for all actors)[1], while (a coordinated response in which parties credibly
> pre-commit to the broad sharing of benefits could allow a good outcome
> for all.)[2]

**Claims**: [1].

**Checklist**: yes; neither;  
*no-example* 

---

**Claims**: [2].

**Checklist**: yes; neither;  
*future-with-example*; *no-example* 

**Pattern**: about the future; *could*

---

## IF

**STM**

> (These areas)[6a] can be (particularly worth pursuing)[7] if you’re
> (especially motivated by one of them)[8].

Your response:

> For [6a] we think of, working in promoting EA as in the above
> example.

> For [8], we think of a personal fit of more than 50%

> For [7], we think of an impact of 5300*50%=2650 lives which is
> better than working a DS job resulting in 530 net people.

But that doesn’t use [8] at all. Why is it particularly worth pursuing
if you are “especially motivated”? The “impact” [7] you pointed out
would seem to be the same if you had [8] or if you didn’t.

I would expect an example where someone who had this magical [8] went
on to have particularly great “impact”. And I suspect that they do not
have that example.

Consider this: You can bowl a particularly high bouncer if you’re 6
feet tall. Showing Bhuvaneshwar Kumar bowling a bouncer is not an
example. You have to show Courtney Walsh bowling a bouncer that is one
foot higher than usual bouncers.

---

https://80000hours.org/key-ideas/

> if (an area already receives plenty of attention)[1], then there
> will usually already be (people)[2] working on the (most promising
> interventions)[3]. 

**Claims**: If [1], then there will already be [2] working on [3].

**Subject**: If [1], what [2] will already be working on.

**Predicate**: most promising interventions. 

**Example**: For [1], we think of "[health in poor countries](https://80000hours.org/problem-profiles/health-in-poor-countries/)"
where about 300 billion<span>$</span> on health each year. Contrast
that to the spending of 10 to 100 million<span>$</span> on factory
farming.

For "what [2] are working on", we think of AMF working on delivering
bednets to people in africa.

For [3], we cite 80khours suggesting [here](https://80000hours.org/problem-profiles/health-in-poor-countries/) as most needed: "Get
everyone exposed to malaria sleeping under bednets".

**Definition**: Checks out. 

**Checklist**: yes; true;

---

>In the 1950s, the large-scale production of nuclear weapons meant
>that, for the first time, (a few world leaders )[1] gained the ability to
>kill (hundreds of millions of people)[2] — and possibly many more if (they
>triggered a nuclear winter)[3], which would make it nearly impossible to
>grow crops for several years. 

**Claims**: [1] could kill [2], if [3].

**Subject**: If [3], What [1] could kill.

**Predicate**: [2].

**Example**: No example for nuclear winter ([3]) from the past.

**Definition**: -

**Checklist**: no; neither;
*no-example*; *future-without-example*;

---

> However, over the past eight years, we’ve come to realise that the
>(present generation)[1] is capable of (putting the entire future of
>civilisation at stake)[2] if (it doesn’t wisely navigate the development
>of these technologies)[3].

**Claims**: [1] is capable of [2], if [3].

**Example**: *no-example*

**Checklist**: yes; neither; not-chapter;
*no-example*;

---

> It (global catastrophe that leads to billions of deaths) seems like
> (such an event would be among the worst things that could happen)[1].
> This is especially true if (one takes a longtermist perspective)[2],
> because extinction would also mean the loss of the potential welfare
> of all future generations.

**Claims**: [1] if [2].

**Example**: no example. 

**Definition**: -

**Checklist**: no; neither;
*future-without-example*; *no-example* 

---

>Some other issues we’ve focused on in the past include (ending factory
>farming and improving health in poor countries)[1]. They seem especially
>promising if (you don’t think people can or should focus on the
>long-term effects of their actions)[2].

**Claims**: [1] seem promising if, [2].

**Subject**: if [2], what [1] seems to be.

**Predicate**: promising

**Example**: 80khours ranks most promising areas to work on [here](https://80000hours.org/problem-profiles/).

if [2], then this list cuts across to factory farming and health in
poor countries only, neglecting things like climate change or AI safety.

**Definition**: checks out.

**Checklist**: yes; true;

---

>(These areas (i.e., issues 80khours hasn't been able to look
>into))[1] can be particularly worth pursuing if (you’re especially
>motivated by one of them)[2]. We cover this more in the section on
>‘personal fit’ below.

**Claims**: [1] can be particularly worth pursuing if [2].

**Example**: no example

**Definition**: -

**Checklist**: yes; neither; ; not-in-chapter;
*no-example*; 
 
---

>Given our take on the world’s most pressing problems and the most
>pressing bottlenecks these issues face, we think the following five
>broad categories of career are a good place to start generating ideas
>if you have the flexibility to consider a new career path.

**Checklist**: yes; neither; ; *not-inchapter* 
*no-example* 

---

>Research is the most difficult to enter of the five categories, but
>it has big potential upsides, and in some disciplines, going to
>graduate school gives you useful career capital for the other four
>categories. This is one reason why (if you might be a good fit for a
>research career, it’s often a good path to start with)[1] (though we
>still usually recommend exploring other options for 1-2 years before
>starting a PhD unless you’re highly confident you want to spend your
>career doing research in a particular area).

**Claims**: [1] 

*we would like an example of someone who is a "good fit" for a
research career and see that "it is a good path"*

*No way am able to give examples for this. This is too broad and
pointless for me to attempt to give an example about.*

**Checklist**: yes; neither;  
*no-example* 

---

**Source**: https://80000hours.org/problem-profiles/health-in-poor-countries/

>People with HIV live nearly normal lifespans, and rarely pass on the
>virus to others, if promptly and consistently treated with
>anti-retroviral drugs.

**Example**: "Among nearly 1,000 male couples across Europe where one
partner with HIV was receiving treatment to suppress the virus, there
were no cases of transmission of the infection to the HIV-negative
partner during sex without a condom."---[link](https://www.theguardian.com/society/2019/may/02/end-to-aids-in-sight-as-huge-study-finds-drugs-stop-hiv-transmission)


**Definition**: this is the best example I could get quickly. checks out.

**Checklist**: yes; true;

---

[Link](/deliberate-practice.html)

>If (you look at experience)[1], it certainly does not look like the
>(deciding factor regarding this)[2].

**Claims**: If [1], it does not relate to skill.

**Subject**: If [1], What experience does not relate to.

**Predicate**: to skill.

**Example**: My colleague is 50 years old with 20+ years of design
experience. Despite that I was the one who did all the important
calculations and reviewed his design.

**Definition**: checks out.

**Checklist**: yes; true; 

---

>If talent existed and refused to show itself even after so many years
>of life, it beckons if inate ability even exists.

**Claims**: If talent existed, and it refused to show itself even
after so many years of life, then talent doesn't exist.

**Checklist**: no; neither;  
*no-example*: *failed* (not sure how the example could look).

---

**Claims**: Everyone would ~~achieve greatness~~ do X, if it were easy and fun.

**Example**: *I think the closest I can come to giving an example, is to
give an example of a certain X and not just greatness (as I wouldn't
have an example for that claim)*

Every friday night my colleagues religiously plan outings with friends
and get wasted. It costs very little and is fun.

**Definition**: checks out.

**Checklist**: yes; true; 

---

**Source**: http://agent18.github.io/deliberate-practice.html

>(You didn’t really have to know much about a field)[1] if you knew the
>(best ways to analyze a problem and think it through)[2], and (you needed
>to know even less)[3] if your (analysis and reasoning power could be
>juiced by a computer)[4]

**Claims**: Knowledge about field was not required (to be successful),
if you knew [2].

*the if statement is unclear. I can falsify the claim without the if
statement, but with it is very hard.*

**Checklist**: no; neither;  
*if*; *time*; *failed* (failed as I did not know how to answer this claim)

---

**Claims**: You needed to know lesser than someone with [2], if [4].

Don't have an example for [2].

**Checklist**: yes; neither;  

---

**Claims**: You needed to know very little about the field to be
successful, if [4].

**Example**: The AlphaGo system that defeated Lee Sedol (4-1),
required tens of millions of games of training data.

**Definition**: falsifies claim.

**Checklist**: yes; false;

---

> Given a (word)[1] it is easier to remember if (it is familiar)[3] and with
> little effort we can spell it backwards even, but if the letters are
> in a random order, it is going to be pretty hard. What chess players
> could be seeing is words.

**Claims**: Given [1] it is easier to remember if [3].

**Example**: Contrast remembering
"pneumonoultramicroscopicsilicovolcanoconiosis" (which is not
familiar), with "Mitochondria" (which is familiar).

**Definition**: checks out.

**Checklist**: yes; true
 
 ---
 
**Claims**: Given a word, if the letters are in random order, it is going to be
pretty hard to remember.

**Example**: "asdfjahsdkfjhagskdfjhg"

**Definition**: checks out.

**Checklist**: yes; true;

---

> If (we would like to become an expert in our field)[1] (we would read
> tons about our field, the history, read everything that the experts
> are doing, get insights from colleagues etc…)[2]

**Claims**: If [1], then [2].

**Checklist**: yes; neither;  
*future-with-no-ex*  

---

> In simple terms, when the tasks are easy then it gets boring. When
> tasks involved are challenging enough that they just stretch us
> beyond our skills, then we are in flow. If (it gets too
> challenging)[1] then (we get frustrated)[2]. Top-level performers in
> sports seem to rate practice high on the scale of enjoyableness. But
> the violinists seen in Ericsson’s study seem to rank it as not
> enjoyable. The sharp contrast continues.
 
**Claims**: If [1] then [2].

**Example**: It is very very hard for me to reach 181bpm average. On
the day when I made it I wanted to quit after the first 5 minutes as
I was unable to maintain the heart rate.

**Definition**: checks out.

**Checklist**: yes; true;
*if*; *time* 

---

>if you look at the (early lives of Welches, Ogilvies, and Rockefellas,)[1]
>there was (no hint at the giant success that was about to come)[2]
>(since a young age).

**Claims**: If you look at [1], we see [2].

**Example**: Jack Welch did his masters and PhD in Chemical
engineering in a top school by the age of 25 and started a job in GE
in chemical development. Whereas he became the most influential
business manager of his time.

**Definition**: checks out.

**Checklist**: yes; true.

---

> IQ’s didn’t help predict if someone was going to be good or bad at
> betting on horses.

**Claims**: ^^

**Example**: In the study, a person with an IQ of 85, was able to pick
out the top horse in 10/10 races. Whereas a person with IQ 118, picked
up the top horse for 3/10 cases.

**Definition**: checks out

**Checklist**: yes; true.

---

**Claims**: If you toggle the input factor, you can see if it has any
impact on the output.

**Example**: Blondlot claimed that if you have an aluminium prism and
a treated thread of cadmium sulfide, you will get a faint glowing in
the dark. 

"One day Blondlot had given a demonstration of N-Rays. The lights had
turned out, and his assistant had called off the brightening and
darkening as Blondlot performed his manipulations."

"It had been a normal demonstration, all the results going as
expected. Even though an American scientist named Robert Wood had
quietly stolen the aluminium prism from the center of Blondlot’s
mechanism."

This way we know the prism did jack shit to the output.

**Definition**: checks out.

**Checklist**: yes; true.
 
---

**Claims**: if you don't toggle the input factor, you won't know if it
has any effect at all.

**Example**: Blondlot didn't toggle the prism, and he didn't know that
it had no effect on his experiment or the production of N-rays.

**Definition**: checks out.

**Checklist**: yes; true.

---

## Subject predicate split

### It is B

https://en.wikipedia.org/wiki/2020_Democratic_Party_presidential_debates_and_forums

>It is important to note (that previously DNC policy has been passed
>down orally, and only confirmed later by statements to the press,
>without any official ruling, as was done with the Bullock controversy
>above)[1]. --- [link](https://en.wikipedia.org/wiki/2020_Democratic_Party_presidential_debates_and_forums)

**Claims**: It is important to note [1].

**Subject**: the importance of noting [1].

**Predicate**: is important.

**Checklist**: -

---

>An identical DNC approved poll conducted on the 1st of July was also
>located in the data, but it is unclear which category was used for
>(the qualification for the debates, as no candidate had 2% in one
>category and 1% in the other, although FiveThirtyEight claims the
>above DNC source told them the sample for the "debate qualification
>will be the adult sample", and Politico used the "registered" column
>for their data compilation)[1]. --- [link](https://en.wikipedia.org/wiki/2020_Democratic_Party_presidential_debates_and_forums)

**Claims**: It is unclear which category was used for [1].

**Subject**: The clarity of which category was used for [1].

**Predicate**: is unclear.

**Checklist**: -

---

>It is unclear (how long Mr Sanders will need to recover from his
>surgery)[1], and whether it will affect his appearance in the next
>Democratic debate on 15 October. --- [link](https://www.bbc.com/news/world-us-canada-49911035)

**Claims**: It is unclear how long [1].

**Subject**: the clarity of how long [1] is.

**Predicate**: is unclear.

**Checklist**: -

---

>It is unclear why. Iowa hosts the first voting contest in the US
>presidential race. --- [link](https://www.bbc.com/news/world-us-canada-49911035)

ditto

>It is being held in (Houston and will also be available on streaming
>services)[1].--- [link](https://www.bbc.com/news/world-us-canada-4991103)

**Claims**: It is being held in Houston.

**Subject**: Where the Democratic debate is being held

**Predicate**: in Houston.

**Checklist**: -

---

>But it is exactly because (Castro is polling at 1 percent)[1] that these
>moments may work for him. What Castro really needs at this point is
>anything to stand out. --- [link](https://www.nytimes.com/2019/09/12/us/politics/when-is-sept-democratic-debate.html)

**Claims**: It is exactly because [1] that these moments (where he
attacks Biden) may work for him.

**Subject**: The reason for the attacks on biden, working for him(castro).

**Predicate**: [1].

**Checklist**: no; neither;  
*time* 

**Pattern**: because; It is X that Y.

<!-- >without adaptation, it is projected to displace nearly 200 million -->
<!-- >people. --- [link](https://www.givewell.org/shallow/climate-change/extreme-risks) -->


---

<!-- ### A has/am, X -->


<!-- >I have tried to order these explanations from strongest to weakest -->
<!-- >(in my view, at least): --- [link](https://fivethirtyeight.com/features/why-do-black-democrats-usually-prefer-establishment-candidates/) -->


<!-- ### there is X -->

<!-- >There is some evidence that African Americans are more likely to turn -->
<!-- >out to vote if there is a black candidate. ---[link](https://fivethirtyeight.com/features/why-do-black-democrats-usually-prefer-establishment-candidates/) -->


<!-- > So there is a very real possibility that black voters will play the -->
<!-- > same role in the 2020 presidential primary that they have played in -->
<!-- > Democratic politics over much of the last four years: blocking the -->
<!-- > path of the liberal left as it attempts to dethrone the party’s -->
<!-- > establishment. ---[link](https://fivethirtyeight.com/features/why-do-black-democrats-usually-prefer-establishment-candidates/) -->


## adjective

**Source**: https://www.givewell.org/shallow/climate-change/extreme-risks

>This discussion has been limited and conceptual. Below, we review a
>few non-systematic examples of how (damages from worse-than-expected
>outcomes could play an important role in an overall assessment of the
>harms of climate change)[1].

**Claims**: [1] 

**Checklist**: no; neither;  
*future-with-no-ex* 

---

>(These examples)[1] are only a few of the many possible
>low-probability, high-impact results of climate change that may play
>(an important role in the overall harms of climate change)[2].

**Claims**: [1] may play [2].

**Checklist**: no; neither;  
*future-with-no-ex* 

---

>"What concrete funding opportunities exist to limit extreme risks from
> climate change?" is an important question

**Claims**: ^^

**Checklist**: no; neither;  
*no-example*; *failed* (not sure how the example will look)

---

**Source**: http://pradeep90.github.io/toggle-curious-factor.html

> Loud sound effects were definitely important.

**Claims**: ^^

**Example**: When the sound for the horror movie was lowered as
opposed to the "original" sound, the movie appeared to be much less
scary.

**Definition**: checks out.

**Checklist**: yes; true;

---

> Visuals were not as important as the sound

**Claims**: ^^

**Example**: When the sound was on but the visuals were not, the
movie was still "pretty scary". Where as watching the Visuals with
muted sound was not at all scary.

**Definition**: checks out.

**Checklist**: yes; true.

---

**Source**: Talent is overrated

**Claims**: Talents are much less important than we usually think.

**Example**: Lazlo Polgar, married someone with the intention of
making his kids prodigies in some sport. He later chose Chess as that
would be easy to measure. Judit polgar became grandmaster at 15. Susan
Polgar became top ranked female player at the age of 15. She is also a
woman grandmaster. The odds that he was able to make all his kids
grandmasters is the evidence for the claim.

**Definition**: checks out.

**Checklist**: yes; true.
 
 ---
 
 **Claims**: critical thinking is obviously important in the real
 world.
  
**Checklist**: yes; neither;  
*no-example*; :(
  
---
 
 > Coaches advice are important
 
**Example**: I go often to shoot balls in the court and practice. This
particular day, had been after a few weeks of 0 practice. I kept
shooting and I got I think something like 20% shooting over maybe 100
shots (I should probably give up). My friend (who is extremely good)
saw me and said I was all over the place with my action, performing
different motions for every single shot, suggested I shoot from the
fore head in one motion and for the next 10 shots kept criticizing my
every move.

Almost instantaneously, I started nailing every single shot. It didn't
take that much effort even to push the ball. Averaged 50%, which was
pretty sick for 50 shots and my highest in a while considering my
recent hiatus.

**Definition**: checks out.

**Checklist**: yes; true.
 
---

> running to the point of exhaustion was centrally important activity
> (for jerry Rice's success.)
 
I could look at Jerry before joining NFL and Jerry after he one his
first season and compare what was the difference, but I don't have
such data.
 
**Checklist**: yes; neither; 
*no-example*; (hard to give an example here due to lack of data)

---

> What DP means is critically important

**Example**: Not able to get real-life examples for this.

**Definition**: -

**Checklist**: yes; neither;
*no-example*; 
 
--- 

> Choosing the aspects of performance is itself an important skill

**Subject**: How important a skill is choosing the aspects of performance.

**Example**: no example. X chose ABC, and Y chose XYZ, Y is grandmaster
X is not. How will I even get such examples.

**Definition**: -

**Checklist**: yes; neither
*no-example*; *time*; (somehow how the example could look became
clearer when I wrote out the subject )

---

> High repetition is the most important difference between deliberate
> practice of a task and performing the task for real, when it counts.


I do not think I can find an example for the above claim mainly
because of "most". How do I give an example that out of all the
factors, "repetition" is the most important.

If I think of the basketball example I gave earlier, "feedback" was
the most important rather than practice at that point.

**Checklist**: yes; neither;
*no-example* 

---

> Most important thing you can do to improve performance is not fun

**Claims**: ^^

**Subject**: Most important thing you can do to improve your performance 

**Predicate**: is no fun

**Example**: As a highest level figure skater, Shizuka Arakawa trained
on the jumps she couldn't do. Arakawa's road to the gold medal
involved at least twenty thousand derriere impacts on an unforgiving
surface.

**Definition**:  It cannot be fun to fall on ice on your ass 20000 times.

**Checklist**: yes; true;

---
 
> Another important variable is how much effort a person puts into it
> (practice)

**Claims**: ^^

**Subject**: The effort put by person.

**Predicate**: is an important variable.

**Example**: A study of singers found that when amateurs took a voice
lesson, they experienced it as an enjoyable release of tension, but
when professionals took a lesson, they experienced it as an intense,
difficult effort.

**Definition**: checks out

**Checklist**: yes; true;

---

> Comparing hours of practice by large numbers of people reveals
> important trends

**Example**: A study of violinists found that by the top violinists
had 7410 hours of lifetime practice whereas the "ok" students at the
institute clocked 3420 hours.

*I concede that I have not dealt with the large numbers part but
assume the study took sufficiently large numbers*

**Definition**: checks out. These trends seem to inform us that more
practice leads to greatness.

**Checklist**: yes; true;
 
---

> Indeed, (the most important effect of practice in great performers)[1] is
> that it takes them beyond—or, more precisely, around—(the limitations
> that most of us think of as critical)[2].


**Claims**: [1] is that it takes them beyond [2].

**Checklist**: yes; neither;
*no-example*; *definition-unclear*;

---

> Reaction time doesn't play an important role, but the stakes can be
> extremely high (regarding reading X-rays).


**Claims**: Reaction time doesn't play an important role in reading
X-rays

**Example**: A radiologist roughly takes 5 seconds to decide if a
chest X-ray is normal. If he takes 1 second more or 10s more, the
consequence is not much other than it adds cost to the hospital.

Where as a tennis player needs to be able to react to the ball in
0.47s otherwise he loses the game.

**Definition**: checks out.  

**Checklist**: yes; true.

---

> Excellent performers in other fields have learned to spot
> non-obvious information that's important.

**Claims**: ^^

**Subject**: What excellent performers have learned to spot

**Predicate**: non-obvious information that's important

**Example**: Top Tennis players look at a servers body and not at the
tennis ball to understand where the ball is expected.

**Definition**: checks out.

**Checklist**: yes; true;

---

> the most important ingredient in any expert system is knowledge

**Claims**: One of the most important ingredients in any expert system is
knowledge.

**Example**: Despite having state of the art computer systems and
programmers and programs rich in general inference methods, the
AlphaGo still seems to need millions of games to train on before it
defeated the GO champion 4-1.

**Definition**: checks out.

**Checklist**: yes; true.

---
 
> An important part of prework self-regulation centers on attitudes and
> beliefs.

**Claims**: ^^

**Subject**: What an important part of prework self-regulation centers on

**Predicate**: attitudes and beliefs

**Example**: "figuring out specific goals and plans for what you'll
be doing every day sounds hard and requires high motivation"

*This is the best example I see from the book.*

**Definition**: checks out!

**Checklist**: yes; true;
*example-matching-subject*; *unsure* 

---

> (The most important self-regulatory skill that top performers use
> during their work)[1] is self-observation.

**Claims**: ^^

**Subject**: [1] 

**Predicate**: is self-observation

**Example**: 

*I need more data for MOST. So I skip it assuming I am not going to be
able to find an example here.*

"Elite runners, by contrast, focus intensely on themselves; among
other things, they count their breaths and simultaneously count their
strides in order to maintain certain ratios."

**Definition**: checks out! 

**Checklist**: yes; true;
*subject-predicate-split*; *time*

---

