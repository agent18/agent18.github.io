I"˝\<h2 id="introduction">Introduction</h2>

<p>I am currently trying to figure out what sort of career I should go
into. Whether I should do GPR or ETG or get a Master‚Äôs and beef up
skills in AI. I am really unsure, of what the market has to offer,
what the market needs, and where all I can contribute.</p>

<p>As a result, I was trying to asses what skills were constrained, with
the intention that I could potentially beef up skills and reduce the
bottleneck. I primarily looked at 80khours posts and surveys. At that
time, I found this article: <a href="https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really">‚ÄúAfter one year of applying for EA
jobs‚Ä¶‚Äù</a> which lead me into a rabbithole of articles, and
evidence, that ended up changing my view completely. I try to write a
post on this, in an attempt to clarify my thought and pool all the
data there is for others to see clearly.</p>

<p>With this post I start with exploring what ‚Äútalent constrained‚Äù
means. Next, the different claims for TC are looked into, followed by,
checking if these claims are true with atleast one example. In the
end, we extrapolate this to what it means for me.</p>

<p>During this essay I hope to uncover the following:</p>

<ul>
  <li>
    <p>Talent constrain (bottleneck, funding constrain etc..)</p>
  </li>
  <li>
    <p>Easiness to get a job in EA (how I compare to these people)</p>
  </li>
  <li>
    <p>What is the value you add working at an EAO (how to consider replaceability)</p>
  </li>
  <li>
    <p>EA is definitely better than ETG in most cases (Stretch)</p>
  </li>
</ul>

<h2 id="definitions">Definitions</h2>

<p>We are going to be primarily dealing with the term ‚ÄúTalent
Constrained‚Äù. To avoid confusion we try to understand what it is
first. 80khours defines TC in ‚Äú<a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps">Why you should work on Talent
gaps</a>‚Äù (Nov 2015):</p>

<blockquote>
  <p>For some causes, additional money can buy substantial progress. In
others, the key bottleneck is finding people with a specific skill
set. This second set of causes are more ‚Äútalent constrained‚Äù than
‚Äúfunding constrained‚Äù; we say they have a ‚Äútalent gap‚Äù.</p>
</blockquote>

<p>Ok! A cause is TC if finding people with specific skill set proves to
be difficult. The difficulty I assume is in the lack of specifically
skilled people and not some process/management constrain. <a href="https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/">EA
Concepts</a> however, clears this confusion up with a better worded
(‚Äúactively hiring‚Äù) ‚Äúexample‚Äù:</p>

<blockquote>
  <p>Organization A: Has annual funding of $5m, so can fund more staff,
and has been actively hiring for a year, but has been unable to find
anyone suitable‚Ä¶ Organization A is more talent constrained than
funding constrained‚Ä¶</p>
</blockquote>

<p><strong>Note</strong>: In this article, discussions are on ‚ÄúOrgs that are TC‚Äù and
not ‚ÄúCauses that are TC‚Äù. I am unable at this moment to add value when
I am told that AI strategy Cause is TC with the lack of
‚ÄúDisentanglement Research‚Äù (DR). But if I know FHI and many other orgs
is TC in DR, then I can plausibly get skilled in DR and apply to close
the lack of people with that skill set. So looking at causes for me is
less helpful and less concrete for me and is not what I have set out
to uncover.</p>

<p>Different definitions and my thoughts in the footnotes: <!-- tbc --></p>

<h2 id="evidence-for-tc">Evidence for TC</h2>

<p>80khours claims EA is TC. 80khours claims EA has been TC
from 2015. 80khours claims following EA are TC. Note: there has been
some confusion with this term and 80khours set out to clear it. I am
not sure life is any different today as a result of this clearing up.</p>

<p>EA has been and is talent constrained according to surveys made by
80khours and CEA since 2017. Several organizations seem to think so in
these surveys: <a href="https://80000hours.org/2017/11/talent-gaps-survey-2017/">2017 survey</a>, <a href="https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions">2018 survey</a>, <a href="https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis">2019
survey</a>. In all the surveys EA‚Äôs on average claim to be more Talent
Constrained than Funding constrained. For example in 2019 EAOs
reported feeling more (3 out of 5 rating) Talent Constrained and less
(1 out of 5 rating) Funding Constrained<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>. More details in the
footnote <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>.</p>

<p>80khours doesn‚Äôt seem to have changed it‚Äôs position on this matter in
its posts. Since 2015 already, 80khours seems to be suggesting that we
should focus on providing talent to the community rather than ETG in
<a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/">‚ÄúWhy you should focus on talent gaps and not funding gaps</a>. They
make the case that if someone can setup a Charity that meets
GiveWell‚Äôs criteria, then they seem to have access to 10s of millions
of dollars. Another example 80khours made was about AI Safety and that
the funds were enough as per the evaluation of Open Phil and that
there are people who are ready to donate even more funds, but think
there isn‚Äôt enough ‚Äútalent pool‚Äù (back in 2015)<sup id="fnref:12" role="doc-noteref"><a href="#fn:12" class="footnote" rel="footnote">3</a></sup>. This continues
through June 2017 in <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/">‚ÄúWorking at EAO</a> and <a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/">‚ÄúThe world desperately
needs AI strategists</a><sup id="fnref:16" role="doc-noteref"><a href="#fn:16" class="footnote" rel="footnote">4</a></sup>.</p>

<p>In August 2018, 80k can be seen saying that we need people to
work on AI safety, Biorisk, EA, GPR, Nuclear security and
institutional decision making.</p>

<blockquote>
  <p>Why did we choose these categories (Research, Govt policy, eff non
profits, ETG)<sup id="fnref:13" role="doc-noteref"><a href="#fn:13" class="footnote" rel="footnote">5</a></sup>?  Why do we especially highlight
research, policy and non-profit jobs; deprioritize earning to give;
and omit advocacy and entrepreneurship?</p>

  <p>In brief, we think our list of top problems (AI safety, biorisk, EA,
GPR, nuclear security, institutional decision-making) are mainly
constrained by research insights, either those that directly solve the
issue or insights about policy solutions. ‚Äî <a href="https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories">High Impact Careers
</a> Aug 2018</p>
</blockquote>

<p>In Nov 2019, 80khours tries to clear up the ‚Äúconfusions‚Äù we create
when we talk about ‚Äútalent gaps‚Äù.</p>

<blockquote>
  <p>Rather than funding vs. talent gaps, we propose that people aim to
identify specific bottlenecks facing the field and the skills needed
to resolve them. A ‚Äòbottleneck‚Äô is the resource that a field most
needs in order to make progress.</p>
</blockquote>

<p>Ok, what if a cause is bottlenecked by a specific skill? Let me
think‚Ä¶ ah Talent constrained. It appears that the word is not
confusing as per their initial definition. But somehow somewhere in
the way, wait am not sure what happened. Let‚Äôs read that article
again and see where that gets us‚Ä¶</p>

<blockquote>
  <p>Today we usually recommend that people who are a good fit for
filling these bottlenecks treat them as their first priority. This
usually means initially considering relevant jobs in research, top
non-profits and policy, and if you‚Äôre willing to consider something
especially competitive, our list of priority paths.</p>

  <p>In contrast, we rarely think that earning to give should be the top
priority for people who could be a good fit for these other
roles. This is another idea we hoped to highlight by talking about
‚Äòtalent constraints‚Äô.</p>

  <p>However, we also recognize that our priority problems aren‚Äôt ‚Äòtalent
constrained‚Äô in general, and our priority paths require a fairly
narrow set of skills. So, we continue to recommend building career
capital and earning to give as a high impact option for people whose
skills don‚Äôt match the particular constraints currently faced by our
priority problems.</p>
</blockquote>

<p><strong>What I think Talent Constrained means</strong></p>

<p>EAOs are talent constrained when there are not enough capable people
to work at that EAO. There is a lot of demand and the supply is really
low was my thought process.</p>

<p><strong>80khours defines it:</strong></p>

<p>Lack of people with specific skill set.</p>

<p>I am going to try and argue here that for majority of the people EA is
not constrained by talent.</p>

<p>First we need to be more clear than 80khours, so we talk about the
lack of talent constrain, in 80khours suggested top career paths.</p>

<ul>
  <li>AI strategy and Policy research</li>
  <li>AI safety technical research</li>
  <li>Grant maker focused on top areas</li>
  <li>Work in effective Altruism orgs</li>
  <li>Global priorities researcher</li>
  <li>Bio-risk strategy and policy</li>
  <li>China Specialists</li>
  <li>Earning to give in quant trading</li>
  <li>Decision making psychology research and roles</li>
</ul>

<hr />

<blockquote>
  <p>People sometimes act as if the main alternative to earning to give is
working at an ‚Äòeffective altruism non-profit‚Äô. However, this misses
many types of high impact roles including those in academia, policy
and relevant companies, which could absorb far more people. Our recent
survey showed that roles in policy are highly valued, as are research
positions that could be done within academia.</p>
</blockquote>

<p>Footnote added at the end, needs to be corrected: <!-- tbc --><sup id="fnref:15" role="doc-noteref"><a href="#fn:15" class="footnote" rel="footnote">6</a></sup></p>

<h2 id="ea-seems-to-be-talent-constrained-eaorgs-say">EA seems to be Talent Constrained (EAorgs say)</h2>

<p>Rethink Charity, Open Phil Gen Researcher, TLYCS, EAF‚Äôs hiring round</p>

<p>I don‚Äôt have a whole lot of evidence for every single of the career
paths. But just broadly in general looking at ‚ÄúWorking at EAO‚Äù or
‚ÄúGlobal Priorities Research‚Äù, there seems to be evidence of the lack
of highly skilled personnel for the job. Especially in the cases of
Operations people, Senior hires in places like Rethink Charity and
also Generalist researchers.</p>

<p>Open Philanthropy (OP) hired 5 Generalist Research Analysts (GRs) in
2018 and wrote about their experience and provide some key
numbers. Apparently, there were hundreds of applicants with strong
resumes and seemed quite aligned with OP‚Äôs mission. 58 of them
performed best in their work-tests and 17 of them were offered 3-month
trials from which 5 were selected. Further more OP acknowledges that
it doesn‚Äôt have the capability to deploy such a pool of available
talent.</p>

<p>I don‚Äôt know why GR is one of the most talked about (top 3) in all the
surveys done by 80khours. Maybe it is because it is the demand but
there is plenty of supply as seen above. Global priorities research
seems to be a joke, considering the lack of capability to absorb
talent. This is also a priority paths. I can hear 80k‚Äôs defense: ‚Äúbut
we will need them in the coming years‚Äù, really? you are going to
absorb 50 people and who knows how many more are going to be available
especially in the coming years? All this considering the ‚Äústartups
should hire slow philosophy‚Äù. Maybe there are plenty of these orgs and
everyone gets a job? but unlikely.</p>

<p>EAF (Germany), similar to OP, gave a <a href="https://forum.effectivealtruism.org/posts/d3cupMrngEArCygNk/takeaways-from-eaf-s-hiring-round">detailed account into their
hiring round</a> for Operations and Research Analyst. Without any
further research I assume that the RA position is similar to that of
GiveWell‚Äôs. Within a period of 2 weeks they got 66 applicants. 66
applicants ‚Äì&gt; 17 work tests ‚Äì&gt; 10 interviews ‚Äì&gt; 4 trial week ‚Äì&gt; 2
offers. They didn‚Äôt want to have a larger period for apping due to
organizational constraints. In the end they appear to have hired 4% of
their initial applicants. Considering that this is Germany (not really
an EA hub), it appears that they atleast had 17 potential candidates
whom they wanted to test. It still appears that there are a lot of
talented people out there for roles like these despite being in a
non-EA hub.</p>

<p><a href="https://www.linkedin.com/in/peterhurford8/">Peter Hurford</a>, has various titles such as Vice Chairman of the
Board, President of Board and Co-executive Director of Charity
Science, Rethink Charity and Rethink Priorities. He seems to have no
problem finding talented people to work for him. In fact he says he
finds it hard to turn down strong applicants and still has to do it
anyway in 2019.</p>

<blockquote>
  <p>I‚Äôve certainly had no problem finding junior staff for Rethink
Priorities, Rethink Charity, or Charity Science (Note: Rethink
Priorities is part of Rethink Charity but both are entirely separate
from Charity Science)‚Ä¶ and so far we‚Äôve been lucky enough to have
enough strong senior staff applications that we‚Äôre still finding
ourselves turning down really strong applicants we would otherwise
really love to hire.‚Äî<a href="https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience?commentId=ySRBeBocRz7oSahAC">Peter Hurford says in the 2019 survey</a></p>
</blockquote>

<p>Peter Expresses his concern on the bemoaning of ETG. As evidence to
his claim I believe unless I can be a quants trader I am a loser and
that it is better to focus on working at an EAO as a result. And now
even this is turning out to be hard as fuck. And the one org we turn
to for career advice sucks.</p>

<p>The Life You Can Save‚Äôs Jon Behar also agrees with Peter that this
whole ‚Äútalent bottleneck‚Äù, atleast with the people they seem to be the
case and that money is more in need for them. And that they are more
strapped for Funding.</p>

<p>Firstly, it took me a while, but now I understand what is AI
research. It splits to three or four things. (Technical) AI safety
research (one done by ML engineers in OpenAI, MIRI etc‚Ä¶), AI
strategy and policy (seems to be in the same bracket both strategy and
policy) and then we have AI policy practice/implementation. This is
roughly found in 80khours <a href="https://80000hours.org/articles/ai-policy-guide/#ai-policy-practitioner">Policy guide</a> and <a href="https://80000hours.org/career-reviews/artificial-intelligence-risk-research/">Technical safety
research</a> and this post by <a href="https://www.linkedin.com/in/carrickflynn/">Carrick Flynn</a>. Ok! now for the lack
of or presence of AI safety and policy jobs. Miles Brundage in June
2017 previously from FHI and now in OpenAI (Policy) says in this
podcast‚Äì‚Äú<a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/#transcript">The world desperately needs AI strategists</a>‚Äù‚Äìseems to
imply that the policy research space is growing and there will be more
jobs. <a href="https://www.linkedin.com/in/carrickflynn/">Carrick Flynn</a> in Sep 2017, who managed hiring for FHI in
Strategy seems to suggest the desperate need for People but not
now. Now there are very few positions due to the problems with
‚Äúdisentanglement‚Äù. That is the bottleneck apparently and suggests to
develop skill (somehow) and wait for the opportunities. But it goes on
to suggest that AI Strategy and Policy space is also not ‚ÄúTalent
Constrained‚Äù. Will it be in the future? Yes there are claims and
possibly so. How long into the future I don‚Äôt know. No one knows. It‚Äôs
Feb 2020 now, and most of the articles on 80khours in the <a href="https://80000hours.org/topic/priority-paths/ai-policy/">strategy
space are still from 2017</a>, So I don‚Äôt know if things changed and
if there has been that success with disentanglement. There is no sign
regarding people needing to work in the policy space.</p>

<p>Back in June 2017 already, Miles Brundage was in a podcast with
80000hours titled, ‚Äú<a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/#transcript">The world desperately needs AI
strategists</a>‚Äù. In that podcast Miles informs Rob, that getting a
job is pretty competitive and that it is pretty much going to remain
like this. <a href="https://www.linkedin.com/in/carrickflynn/">Carrick Flynn</a> from FHI who handled recruitment (in
2017), writes <a href="https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy">here</a>, about the lack of jobs in AI strategy. There
is one place called the ‚Äúdisentanglement research‚Äù and they need
really skilled people at it, but otherwise, he asks people to hang on
until this disentanglement progresses. Such as people from policy
implementation, policy research are on hold. He also lists some broad
areas which are bottlenecked, such as knowledge of Chinese politics,
International law etc‚Ä¶ which I am unsure how it is expected to
work. As Carrick flynn points out there are probably not many jobs and
they are going to be super competitive. If I come in once
disentanglement is done it could be fire.</p>

<blockquote>
  <p>The AI strategy space is currently bottlenecked by entangled and
under-defined research questions that are extremely difficult to
resolve, as well as by a lack of current institutional capacity to
absorb and utilize new researchers effectively.‚Äî<a href="https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy">Carrick Flynn
FHI</a> June 2017</p>
</blockquote>

<p>Although this is not clear in numbers, I get the impression that there
are ‚Äúvery few‚Äù jobs and more demand for disentanglement research
mainly. He even said ‚ÄúFHI is hiring but in limited capacity‚Äù. I don‚Äôt
have data on how many people applied etc‚Ä¶ but there is some data in
general and where availble I look at the evidence. So there seems to
be some serious demand for disentanglement, but I want to take a
stance and say we are further more not TC‚Äôed.</p>

<p>You don‚Äôt expect Harvard to say they are talent constrained when they
pretty much take in 5% of the total applicants. And the same with
Y-combinator, they have tons of applicants in the order of 10000 and
they accept only 100-150 (1%). There are some places where EA seems to
be genuinely Talent constrained. An example would be:</p>

<p>So far we have seen AI safety, Rethink serieses, TLYCS and EAF all
seem to be full a people and not having much capacity to take in new
players. Except for one concrete thing of Disentanglement that I have,
it appears for the jobs</p>

<p>Of course this is narrow in its view, but my point is I don‚Äôt want to
slog my ass off and then find in the end that its too copetitive and
that there are no jobs. If in the end selection if I am just slightly
better than the other person what is the point? I dont know! and if
that guy can‚Äôt get a job anywhere else.</p>

<blockquote>
  <p>Below are some more specific options that are among the most
promising paths we know. Many of them are difficult to enter ‚Äì you
may need to start by investing in your skills for several years, and
there may be relatively few positions available. However, if you
have potential to excel in any of these paths, we encourage you to
seriously consider it, as it may be one of your highest-impact
options.‚Äî<a href="https://80000hours.org/career-reviews/#our-priority-paths">High Impact Careers April 2019</a></p>
</blockquote>

<p>So these are not bottleneck options, ok! but why does 80khours want us
to get better and work on it? again! I was thinking maybe focussing on
bottlenecks was the think to do! This is just tooo tooo confusing for me.</p>

<p>No: of vacancies in a year? (50?) aaron getler</p>

<p>https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on?commentId=r3vv6HWvZ8riBfLEM</p>

<p>Here Jon Beyer and Peter Hurford seem to be hitting the nail in the
head. Please have a look</p>

<h2 id="ea-is-not-talent-constrained-people-says">EA is not talent constrained (People says)</h2>

<p>This is also proxy for will I get a job?</p>

<p>I stumbled upon this post by accident and it was the most popular post
(most upvotes ever) in any post seen in the EA Forum (all
time). OK. When I started getting into it, it started hitting me, my
reality was completely being shaken. Great. And for the first time I
had evidence and not words (80k) about what this god forsaken TC
meant. This sent me into a crazy spiral of evidence which allowed me
to take two steps back and probably impressed in me to test the
80khours claims from now on. Atleast 80khours claims. Those n*****
have been fucking with me for far too long. First it was CC, now it is
TC. Anyways taking a shit on 80khours is for another post.</p>

<p>Many people have applied. Many good intelligent people seem to have
applied and not made it. A lot of effort goes into these
things. Mostly if you ask them, it seems like they will say ah but EA
is TC (The great term coined by 80k). And the distancing of 80khours
from theses feedback or suggestions that 80khours could potentially
offer feedback and shave years of time waste in people is not really
nice. Because they publicise themselves as some for the workld career
feedback giving institution. But they are not. They are all about the
elite. But then market your fucking ass like that. If you don‚Äôt have
two oscars, this advice is not for you. Up until two years, they
wouldn‚Äôt even say what they meant by young and old. They love to keep
it vague.</p>

<p>User <a href="https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really">EA applicant</a>, wrote a post on Feb 2019 which garnered the most likes
ever in a post in the EA forum. This atleast suggests that this is an
important topic. He applied to 20 posts and barely got a job after one
year and some 500 hrs of time later. He seems to have gotten a lot of
feedback from other EAs in EAOs that he is ‚Äúworthy‚Äù to be in EAOs. I
so very much agree with his take on what 80khours is saying:</p>

<blockquote>
  <p>‚ÄúHey you! You know, all these ideas that you had about making the
world a better place, like working for Doctors without Borders? They
probably aren‚Äôt that great. The long-term future is what
matters. And that is not funding constrained, so earning to give is
kind of off the table as well. But the good news is, we really,
really need people working on these things. We are so talent
constraint‚Ä¶ (20 applications later) ‚Ä¶ Yeah, when we said that we
need people, we meant capable people. Not you. You suck.‚Äù</p>
</blockquote>

<p>They literally said all of this. But let‚Äôs not digress.</p>

<p>So this EA applicant from Germany, has couple of scholarships, has 8
publications, has done many internships in the field of medicine, has
led medical refugee camps managing 50 people and has taken classes for
150 students at a time in University in Mathematics, and was ranked
16th out of 6000 people in Medical school. He applied to 20 positions
in the ‚Äúlong-termism, EA movement building, grant-making type‚Äù jobs
and got rejected to most of them (3 of them he didn‚Äôt pursue the work
trial due to ‚Äúvisa issues‚Äù). Apparently he spent around 400-800 hours
in one year for this and is completely dejected that he has got none
of the jobs. He seems to have gone to atleast the 2nd stage in most
interviews. He also claims to know ‚Äúseveral‚Äù people who went to a
great university like Oxford, were the top 5%, lead local EA chapters,
EA aligned and motivated, and 5 positions later 100%
rejections. ‚ÄúSeveral people‚Äù after this post messaged this applicant
stating that they had similar experiences.</p>

<p>Some may argue 5 is less number of jobs to apply for, but it seems to
be consistent that EA is not really TCed by these kind of talents who
are ready to do research, program management, operations you name
it. In fact there are more people in the comments and in other posts,
who decided based on 80khours possibly, that EAOs are going to be
their life but then it‚Äôs not really TCed. There are enough ‚Äúgood‚Äù
applicants for them to pick up from.</p>

<p>Saying, I need even better talent and saying that is what you meant by
TC, is kinda not right I think. As you can always say that, for every
case, that you want even more output from people. Another student
reporting his fuckery.</p>

<blockquote>
  <p>I‚Äôve recently graduated from one of the top ~10 universities
worldwide, after investing heavily in EA throughout my
studies. While a student, EA was the biggest thing in my life. I
read a lot, and several of my EA peers told me I stood out as
particularly well-informed about EA topics, especially long-termist
ones. Eventually I contributed some of my own research too. I also
invested enormous amounts of time in student EA projects. Many
people, including ones I thought well-informed about the talent
landscape, fully expected that I would go work for an ‚ÄòEA
organisation‚Äô. Naively, I believed it too.</p>

  <p>Over the last seven months, I‚Äôve made over 20 unsuccessful job
applications (I keep a spreadsheet). This has increased the severity
of my depression and anxiety. ‚Äî Anaonymousthrowaway</p>
</blockquote>

<p>I tread carefully as we are mostly dealing with words here, but if
people who were well informed about the talent landscape didn‚Äôt
predict him right after 20 applications, then is EA still TCed.</p>

<p>Such investment above seems to favor the elite as pointed out by
Milan Griffes. Only people who the time to spend 500 hrs in a year and
without the stress of job seem to be successful (next section).</p>

<p>Something that is more brutal out of all this subtexting is taht you
suck if you ETG other than quants trading. You are not worth a call
from 80khours, you suck. as pointed out by this guy:</p>

<blockquote>
  <p>So instead I earn-to-give, and am constantly hit with messages (see
above caveat! messages may not be real!) of ‚ÄúWhy are you doing this?
Nobody‚Äôs funding-constrained! Money isn‚Äôt real! Only talent
constraints matter!‚Äù while knowing that if I tried to help with
talent constraints, I would get ‚ÄúSorry, we have 2,000 applicants per
position, you‚Äôre imposing a huge cost on us by even making us
evaluate you‚Äù.</p>
</blockquote>

<p>https://physticuffs.tumblr.com/post/183108805284/slatestarscratchpad-this-post-is-venting-it</p>

<p>Joel Miller on applying to operations in this facebook post:
https://www.facebook.com/groups/473795076132698/permalink/1077231712455695/</p>

<p>etc‚Ä¶ etc‚Ä¶</p>

<p>‚Äúwow, these people are really impressive, and I find it surprising that
they could not find a job‚Äù ‚Äî Max Daniel</p>

<p>Reply to max daniel‚Äôs epistemic status:</p>

<p>But bro, the point is people like X can‚Äôt contribute. Taht is it. And
we are really unsure as to what in the hell 80khours means considering
there are organizations that clearly express that they don‚Äôt have
capacity. How can there be TC when there is no space to absorb. And I
don‚Äôt trust it one bit. I think they are trying to generalize info and
shit goes wrong there and then they dont use examples. They just write
lectures of long notes. OK I need examples for every single claims
that I make. That is not the attitude of 80khours I think.</p>

<p>Sending out personalized invitations‚Ä¶</p>

<h3 id="kinda-people-who-get-in">Kinda people who get in</h3>

<p>Max daniel Aaron Gertler, Luke prog etc‚Ä¶ and what their creds are.</p>

<h2 id="from-previous-article">From previous article</h2>

<p><strong>Someone who didn‚Äôt get there?</strong></p>

<p>EA applicant aaron gertler Max daniel all from:</p>

<p>https://forum.effectivealtruism.org/posts/jmbP9rwXncfa32seH/after-one-year-of-applying-for-ea-jobs-it-is-really-really?commentId=Aic5bcvLmunfhmnhr</p>

<p><strong>Is there any bottleneck? (evidence)</strong></p>

<p>There is no bottleneck at this moment it looks like, in that case
consider going into personal fit types? or potential in the future
types?</p>

<p>EA applicant talks about his 5 friends, Max daniel gets several
rejections, despite thier credentials such as:</p>

<blockquote>
  <p>However, I don‚Äôt think I am a very special case. I know several
people who fulfil all of the following criteria:</p>

  <ul>
    <li>
      <p>They studied/are studying at postgraduate level at a highly
competitive university (like Oxford) or in a highly competitive
subject (like medical school)</p>
    </li>
    <li>
      <p>They are within the top 5% of their course</p>
    </li>
    <li>
      <p>They have impressive extracurricular activities (like leading a
local EA chapter, having organised successful big events,
peer-reviewed publications while studying, ‚Ä¶)</p>
    </li>
    <li>
      <p>They are very motivated and EA aligned</p>
    </li>
    <li>
      <p>They applied for at least 5 positions in the EA community and got
rejected in 100% of the cases.</p>
    </li>
  </ul>

  <p>I think I also fulfil all these criteria. Here is my CV roughly at
the time when I was doing the applications. It sports such features
as ranking 16th out of around 6000 German medical students, and 8
peer-reviewed publications while studying.</p>
</blockquote>

<blockquote>
  <p>People working at EA organisations, sometimes in senior positions,
were surprised when they heard I didn‚Äôt get an offer (from another
organisation).  But he did get several interviews.</p>
</blockquote>

<blockquote>
  <p>Regarding me being a bit of an outlier: Yes, I think so as well. I
personally don‚Äôt know anyone who applied for quite as many
positions. I still don‚Äôt think I am a <em>very</em> special case. I also
got several private messages in response to this post, of people
saying they had made similar experiences. ‚Äî EA Applicant</p>
</blockquote>

<blockquote>
  <p>I know at least 2 people who unsuccessfully applied to a large
number of ‚ÄòEA jobs‚Äô. (I‚Äôm aware there are many more.) I feel
confident that they have several highly impressive relevant skills,
e.g. because I‚Äôve seen some of their writing and/or their CVs. I‚Äôm
aware I don‚Äôt know the full distribution of their relevant skills,
and that the people who made the hiring decisions are in a much
better position to make them than I. I‚Äôm still left with a
subjective sense of ‚Äúwow, these people are really impressive, and I
find it surprising that they could not find a job‚Äù.‚ÄîMax Daniel</p>
</blockquote>

<blockquote>
  <p>I‚Äôve recently graduated from one of the top ~10 universities
worldwide, after investing heavily in EA throughout my
studies. While a student, EA was the biggest thing in my life. I
read a lot, and several of my EA peers told me I stood out as
particularly well-informed about EA topics, especially long-termist
ones. Eventually I contributed some of my own research too. I also
invested enormous amounts of time in student EA projects. Many
people, including ones I thought well-informed about the talent
landscape, fully expected that I would go work for an ‚ÄòEA
organisation‚Äô. Naively, I believed it too.</p>

  <p>Over the last seven months, I‚Äôve made over 20 unsuccessful job
applications (I keep a spreadsheet). This has increased the severity
of my depression and anxiety.</p>
</blockquote>

<blockquote>
  <p>‚Äî Anonymousthrowaway</p>
</blockquote>

<p>But 80khours continues to argue shit like Talent constrain but where
is the talent constrain mother fucker?</p>

<p>People working here don‚Äôt seem to have funds to grow, idhula talent
oru keda?</p>

<p>And more of this here:
https://physticuffs.tumblr.com/post/183108805284/slatestarscratchpad-this-post-is-venting-it</p>

<blockquote>
  <p>So instead I earn-to-give, and am constantly hit with messages (see
above caveat! messages may not be real!) of ‚ÄúWhy are you doing this?
Nobody‚Äôs funding-constrained! Money isn‚Äôt real! Only talent
constraints matter!‚Äù while knowing that if I tried to help with
talent constraints, I would get ‚ÄúSorry, we have 2,000 applicants per
position, you‚Äôre imposing a huge cost on us by even making us
evaluate you‚Äù.</p>
</blockquote>

<p>https://www.facebook.com/groups/473795076132698/permalink/1077231712455695/</p>

<p>Joel miller on apping to operations.</p>

<p>My biggest qualm is these people from 80khours come out and say, oh
you misunderstood what we said, not that what the fuck they said was
misleading. They think giving a post of explanaiton is all they need
to do. Fuck me and all the time I and several other AEA‚Äôs are
attempting to spend to find a fucking a job which will add value.</p>

<p>The thought or less thought that seems to go into loose words like
career capital, bottleneck, talent constrained, is worrying.</p>

<p>https://forum.effectivealtruism.org/posts/2XfiQuHrNFCyKsmuZ/max_daniel-s-shortform?commentId=nRciXmjukddKadzwZ</p>

<h3 id="from-another-article">From another article</h3>

<p><strong>2019</strong></p>

<p>https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis</p>

<p>‚ÄúThe 2019 results were very similar to those of 2018, with few
exceptions. Demand remains high for people with skills in management,
prioritization, and research, as well as experts on government and
policy.‚Äù</p>

<p>Policy seems to have risen quite a bit since last year again for only
EA as a whole, but not for ‚ÄúMy Org‚Äù.</p>

<p><strong>2018</strong></p>

<p>https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions</p>

<p>If I make a claim saying I am going to look at ‚ÄúMy Org‚Äù details only
as it captures what that that organizations need, then atleast the
orgs listed things that they want:</p>

<p>Operations, management, GR, and MI and hustle bustle type of vague
roles.</p>

<p>Although gov and policy experts are rated high on what EA needs as a
whole.</p>

<p>https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis</p>

<p><strong>Funding constraints</strong> always lower than talent, but close by in the
5 point scale.</p>

<p><strong>It is pretty clear that Swe engineers are low in need (6 vs 33)</strong></p>

<p>Where as ML engineers seem to be on par with GR last year and this year!</p>

<p><strong>Generalist researcher exit opportunities</strong></p>

<p>All this maybe if you get a job then you are worth</p>

<p>What are the high impact careers?</p>

<p>https://80000hours.org/articles/high-impact-careers/#4-apply-an-unusual-strength-to-a-needed-niche</p>

<h3 id="80khours-sucks">80khours sucks</h3>

<p>https://forum.effectivealtruism.org/posts/7bp9Qjy7rCtuhGChs/survey-of-ea-org-leaders-about-what-skills-and-experience#comments</p>

<p>Peter Hurford suggests that the whole discussion of the EA world being
‚Äútalent constrained‚Äù seems to be bogus as he has had no problem
whatsoever to find people he can hire. But then it stands why these
idiot orgs are writing that they are talent constrained. He seems to
also be questioning the numbers to trade for x employees. And 80khours
seems to be suggesting in this article that that number includes some
extra bullshit () and might not represent the true value of your worth.</p>

<p>I think we need to look at this more clearly. My god! This is just
questioning what I should be doing like dw vs etg, the prime
foundation. ‚ÄúAn organisation reporting being ‚Äòtalent constrained‚Äô doesn‚Äôt
necessarily indicate that they are about to hire a large number of
people.‚Äù ‚Äî WTF
https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on</p>

<p>And that if you get a job then you it is probably worth it. Man the
wording infuriates me. Give me motherfucking examples dammit. I don‚Äôt
trust your fucking reasoning and playing with fucking words. Piss off
will you.</p>

<p>AGB seems to point out that in an already full talent pool with
serious competitiveness, if I go and fight for a spot and then there
are two outcomes. I get the job and the rest of the overflowing pool
(who did not make the cut) go to find other jobs or</p>

<p><strong>Rewrite of the discussion on replaceability and saying people are
worth more than what they are</strong></p>

<p>I think it is a discussion for if I should work in EAO or do DS. Nam saying‚Ä¶</p>

<h2 id="80ks-rebuttal-to-talent-gaps-nov-2018-article">80k‚Äôs rebuttal to talent gaps Nov 2018 article</h2>

<p>continues to say even today that there is bottleneck. Great. I don‚Äôt
know what they are talking about. I am unable to trust their findings,
especially the ones without examples. As the onus is on me to
determine if what they are saying is true. I really need a reality
check and the burden should not be on me, it should be on 80khours to
provide examples with what they are saying and why they are saying
shit. Otherwise we are again lost in the CC TC word game of who
understands what 80khours is saying. God help us.</p>

<blockquote>
  <p>We believe many of our top problem areas are highly constrained by
specific skill sets, as we outlined for AI safety earlier. What‚Äôs
more, there was an important shift in this direction from 2014 as
additional large funders entered these areas, especially the Open
Philanthropy Project. This increase in funding created a spike in
demand for certain key positions that couldn‚Äôt be quickly matched by
an equivalent increase in people able to fill them. This led to a
bottleneck of people with these types of skills, which persists today.</p>
</blockquote>

<p>I spent the last 2 years writing my ass off to follow their priciples
in CC and others to end up now (just by accident), in a position where
EAOs is not going to be for me in a long time.</p>

<blockquote>
  <p>Another way to see the problem is that a typical job application
process only accepts 1-10% of applicants. This means that even if an
organization is 3-times keener to hire than average, its acceptance
rate would still only be 3-30%, and most applicants will still not
get the job.</p>
</blockquote>

<p>(rolling my eyes! OK!).Then that fucking thing is not TC. There is no
skill bottleneck. My problem is not with 3-30% (there could always be
fluff applicants). My problem is with that the way it appears as
though there are many jobs and its hard to fill them, because the
right people don‚Äôt exist, whereas in reality it is completely
different. If you look at OP‚Äôs hiring round, you get the picture. They
had 50 candidates of good stature that they had to choose from and
several of whom they would consider hiring in the future. So I am not
really sure how this is contrain in skill. Anyways fuck 80khours and
their definitions.</p>

<p>My worries are further exploding because they think the proxy for their
success is VIEWS. OMG! Are you serious BT? are these the kind of
people you trust to change the world! Views gOoh! When you don‚Äôt care
about those people who view it and all you care about is the super
super elite. Fuck off.</p>

<p>My qualms are that 80khours did a poor job with it.  They think
english is the best way to communitcate not numbers. They did this
with CC being focus now its TC. My biggest fear is listening more to
their english blindly, without being able to test their claims. And
that is the danger of the situation. Most people (atleast me and EA
applicant) seem to heavily rely on theirr ‚Äúresearch‚Äù, but am not sure
it is that good or atleast the way they talk. Look at how they loosely
use words like MANY (without numbers or actual examples of what it is
they mean) in the 2018 survey. and TC and CC. Where do they get their
info from? More explanation is needed. maybe they trying to generalze
it so please stop that‚Ä¶ your OK is not my OK. (everything with
exmaples)</p>

<h2 id="conclusion">Conclusion</h2>

<ul>
  <li>
    <p>The surveys are wrong or pointless or not trustable</p>
  </li>
  <li>
    <p>Other than Disentanglement I do not know of any other bottleneck for
the long-termism gang.</p>
  </li>
  <li>
    <p>GR, Operations, AI policy and strategy seem to be saturated and
full, without many new jobs includnig open phil and FHI</p>
  </li>
  <li>
    <p>Working outside the EA, in Policy</p>
  </li>
  <li>
    <p>I don‚Äôt trust 80khours to communicate right</p>
  </li>
  <li>
    <p>For me, its al</p>
  </li>
</ul>

<h2 id="reflection-to-my-life">Reflection to my life.</h2>

<p>I think am at a cross roads and I very very unsure what I can excel
at. ML seems to be lucrative as atleast I would potentially have a job
even if I am not good enough for a Tech AI safety job.</p>

<p>The problem is the way the bottlenecks haev been framed in 80khours, I
don‚Äôt really know what to do. I am unsure I am unsure how to proceed.</p>

<p>Does the world need managers? how do I become one? is it also NOT TC?</p>

<p>Also I want evidence that something is TC or not. I dont‚Äô want to
trust words. I want someone to talk in numbers.</p>

<p>Wrap it up‚Ä¶. and prepare to post in EA blogs. and get feedback. how
is one supposed to decide how to work. Don‚Äôt just tell me based on
personal fit, what ever that advice is‚Ä¶</p>

<h2 id="bemoaning-etg">Bemoaning ETG</h2>

<p>https://80000hours.org/articles/high-impact-careers/#global-priorities-researcher</p>

<p>ETG last spot (if you have a personal fit dialogue)</p>

<p>Working at EAO</p>

<p>talent gaps 2015 article</p>

<p>peter hurford</p>

<p>EA applicant</p>

<p>and several others</p>

<p>MIRI wanting money</p>

<p>Number of people doated from less wrong?</p>

<h2 id="ea-is-competitive">EA is competitive</h2>

<h2 id="in-conclusion">In conclusion</h2>

<p>I don‚Äôt knwo what all those orgs in the surveys were talking
about. Does anyone though?</p>

<p>Considering the supposed need is for a particular type of workers (as
in the survey) might not be ideal. i.e., just looking at the DEMAND
alone is not useful. as there are 100 other or atleast 58 other GR‚Äôs
for 5 positions and there is no evidence it is going to suddenly grow
like crazy that the deamand is to be met. Hence my claim of
non-bottlenecks.</p>

<p>It appears useful to consider how to work in AI safety due to the
claim of potential bottleneck in that region too, but place caution on
how bottlenecked it becomes.</p>

<p>Additionally the value of being 1% better than the previous hire
(difficult to measure), needs to be estimated to give me a drive to
actually try and beat all these GR‚Äôs. There is also a fear that I
might not be working for an EAO anytime (possibly in my life?nah)</p>

<p>I was thinking I was always going to become a GR, but I am strongly
considering against it. but I need to check the value of what I could
be or maybe there are some REAL places where the supply is shit, which
might need me.</p>

<p>More organizations should publish data like OP or EAF for each round
to allow people to understand how bad or good the scene is and how the
candidates were (some quantitative measure to compare).</p>

<p>Market is so competitive and there doesn‚Äôt seem to be examples of TC
except for in Disentanglement as far as I know. or I have examples
for.</p>

<h2 id="points-about-80khours">points about 80khours</h2>

<ul>
  <li>
    <p>Waste of time of people</p>
  </li>
  <li>
    <p>english  english english‚Ä¶ many‚Ä¶ how many ? though</p>
  </li>
  <li>
    <p>squishy terms, career capital talent constrained</p>
  </li>
  <li>
    <p>Inability to apologize for the possible miscommunication</p>
  </li>
  <li>
    <p>Lack of ability to provide a proper reply when asked about the time
spent by EAs</p>
  </li>
  <li>
    <p>Let‚Äôs not loose focus. We want to identify what we should be
doing. Suprisingly this post was useful with its output on GR and
the lack of demand. Atleast teh abundance of supply.</p>
  </li>
  <li>
    <p>0 accountability (e.g., TC has 0 examples), its like people say or
they say and we got to take it on face value.</p>
  </li>
  <li>
    <p>making claims without evidence (all regard to TC). Need statements
that I can test. 80khours is not reliable.</p>
  </li>
  <li>
    <p>trying to genenralize goddammit</p>
  </li>
</ul>

<p><strong>Is there anything that is talent constrained?</strong></p>

<p>All this to me appears like a really fake hype. And further to cover
what they actually meant, they said they are talking about fucking
even smarter talent. I think one and only one example I have is people
in the AI safety where ‚ÄúDisentanglement‚Äù is a big deal and not many
people seem to be able to do that according to one of the operations
guys from a certain EAO.</p>

<p><strong>80k‚Äôs explanation</strong></p>

<p>An organisation reporting being ‚Äòtalent constrained‚Äô doesn‚Äôt
necessarily indicate that they are about to hire a large number of
people.‚Äù ‚Äî WTF
https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on</p>

<p>Benjamin todd in the same post continues to say he feels TC.</p>

<p><strong>Takeaways</strong></p>

<p>Certain jobs seem to be 0 constrained. There are not many jobs
available, EAO‚Äôs are hiring slowly.</p>

<p>Rob Wiblin should take questions from listeners and what topics they
want to hear more about. keiran@80000hours.org</p>

<p><strong>Examples</strong></p>

<p>And also in the same article include shit like,</p>

<blockquote>
  <p>Interestingly, many of the organizations report being neither heavily
constrained by funding or talent,‚Ä¶</p>
</blockquote>

<p>Talk about being vague. WTF is many! Jesus.</p>

<p>Naming of posts, my god: Aug 2018 : Highest impact career paths</p>

<p>April 2019: our list of high-impact careers</p>

<p>I find this confusing, if something is not leading anymore, put a note
on it and deprecate it. God dang it.</p>

<p>And it is so fucking similar in the index. Jesus! fuck you guys!</p>

<p><strong>Diff definitions</strong></p>

<p>There seems to be more than one definition:</p>

<blockquote>
  <p>Another factor is that hiring takes up a lot of senior staff time ‚Äì
you need to source candidates, train them, test them out, and many
won‚Äôt work out. Moreover, a bad hire could easily harm morale, take
up a lot of time, or damage the reputation of the organisation, so
there is a lot of risk. This means that it takes a long time to
convert funding into good new staff, creating a talent
bottleneck. But if a potential hire takes a short amount of time to
evaluate, train and manage, they often wouldn‚Äôt get replaced for a
long time. ‚Äî <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable">Working at EAO</a> June 2017.</p>
</blockquote>

<p>Confusing fuckers.</p>

<p>Another definition being:</p>

<blockquote>
  <p>A cause is constrained by a type of talent, X, if adding a (paid)
worker with talent X to the cause would create much more progress than
adding funding equal to that person‚Äôs salary. ‚Äî <a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps">Focus on talent
gaps</a></p>
</blockquote>

<p>80khours defines TC in ‚Äú<a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps">Why you should work on Talent gaps</a>‚Äù (Nov
2015):</p>

<blockquote>
  <p>For some causes, additional money can buy substantial progress. In
others, the key bottleneck is finding people with a specific skill
set. This second set of causes are more ‚Äútalent constrained‚Äù than
‚Äúfunding constrained‚Äù; we say they have a ‚Äútalent gap‚Äù.</p>
</blockquote>

<p>In the same article there is a ‚Äúslightly more precise
definition‚Äù:</p>

<blockquote>
  <p>A cause is constrained by a type of talent, X, if adding a (paid)
worker with talent X to the cause would create much more progress
than adding funding equal to that person‚Äôs salary.</p>
</blockquote>

<p>This was initially confusing and made me wonder ‚Äúwhat does this have
to do with being talent constrained?‚Äù. There are not many people with
the specific skill to work in <a href="https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy">Disentanglement research</a>. It is
thus TC. Adding a good paid worker to FHI in <a href="https://forum.effectivealtruism.org/posts/RCvetzfDnBNFX7pLH/personal-thoughts-on-careers-in-ai-policy-and-strategy">Disentanglement Research
seems to be vital</a> as it could potentially allow the many areas in
Policy and Strategy currently in hold to continue making
progress. Whereas adding salary of the researcher (say
300k<span>$</span> per year) to FHI (AI strategy and policy cause)
doesn‚Äôt seem to do much, as <a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/#what-are-talent-gaps">it seems to have enough money from Elon
Musk, Open Phil</a> etc‚Ä¶ to fund all the high quality proposals it
needs. The above quotes seems to check out. The statement holds when
we look at Global Health and Funding with the case of AMF.</p>

<p>In Nov 2018 80khours <a href="https://80000hours.org/2018/11/clarifying-talent-gaps/">clarifies the TC description</a>,</p>

<blockquote>
  <p>An organisation is talent constrained when, for someone who could take
(a reasonably important) job at that organisation, they would
typically contribute more to that organisation by taking the job than
earning to give.</p>
</blockquote>

<p>Why the definition can‚Äôt be the simple one at top and needs to keep
having variants is puzzling to me. This re-definition also stands the
test of examples such as Disentanglement Research (in FHI) being TC
and Global Health work (in AMF) being FC.</p>

<p><a href="https://concepts.effectivealtruism.org/concepts/talent-constraints-vs-funding-constraints/">EA Concepts</a> defines TC like how similar to 80k‚Äôs 2015 post,</p>

<blockquote>
  <p>Organization A: Has annual funding of $5m, so can fund more staff,
and has been actively hiring for a year, but has been unable to find
anyone suitable‚Ä¶ Organization A is more talent constrained than
funding constrained‚Ä¶</p>
</blockquote>

<p>Very clear, A definition you would expect from an org like 80khours
but‚Ä¶! When there is a lack of talent X in a particular cause and
people are looking for it, then the cause is TC by X.</p>

<p>Definitions that I don‚Äôt want to accept, as its just getting broad and
pointless</p>

<p>I don‚Äôt think what 80khours says in ‚ÄúWorking at EAO‚Äù matches the
definition we started off earlier.</p>

<blockquote>
  <p>Another factor (for orgs being TC) is that hiring takes up a lot of
senior staff time ‚Äì you need to source candidates, train them, test
them out, and many won‚Äôt work out. Moreover, a bad hire could easily
harm morale, take up a lot of time, or damage the reputation of the
organisation, so there is a lot of risk. This means that it takes a
long time to convert funding into good new staff, creating a talent
bottleneck. But if a potential hire takes a short amount of time to
evaluate, train and manage, they often wouldn‚Äôt get replaced for a
long time. ‚Äî <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable">Working at EAO</a> June 2017.</p>
</blockquote>

<p>The definition of TC is that an org needs to actively be looking for
people and is unable to find them. Like in the case of disentanglement
research. I don‚Äôt know where the time taken to hire is playing a
role. OP found set out to find 5 people and found more than 5
people. It took months for this hiring round. People would laugh if
anyone said OP is TC in GR. Sure they would like to hire more people
without spending any time from the management or operations. Sure, but
such people don‚Äôt exist. Saying that OP is TC because it wants new
people but is unable to hire them, sounds to me like wrong
understanding of TC, or trying to bloat the definition of TC just like
they did CC. I am really getting frustrated, by the lack of thought
that goes into these writings. At best it is something like management
constrained, not TALENT.</p>

<p>Moving on.</p>

<p><strong>40000 definitions of TC</strong></p>

<p><strong>Sentences that add little or no value (highly circular)</strong></p>

<blockquote>
  <p>We try to highlight how our views depend on problem selection in our
recent article and the survey. For instance, global health is
significantly more funding constrained than global catastrophic risks,
so earning to give is a relatively more attractive path if you‚Äôre
focused on health ‚Äî though as per point 2, additional funding is
useful in both.‚Äî Nov 2019 <a href="https://80000hours.org/2018/11/clarifying-talent-gaps/">Clarifying talent gaps</a></p>
</blockquote>

<blockquote>
  <p>Today we usually recommend that people who are a good fit for
filling these bottlenecks treat them as their first priority. This
usually means initially considering relevant jobs in research, top
non-profits and policy, and if you‚Äôre willing to consider something
especially competitive, our list of priority paths.</p>

  <p>In contrast, we rarely think that earning to give should be the top
priority for people who could be a good fit for these other
roles. This is another idea we hoped to highlight by talking about
‚Äòtalent constraints‚Äô.</p>

  <p>However, we also recognize that our priority problems aren‚Äôt ‚Äòtalent
constrained‚Äô in general, and our priority paths require a
fairly narrow set of skills. So, we continue to recommend building
career capital and earning to give as a high impact option for
people whose skills don‚Äôt match the particular constraints currently
faced by our priority problems.</p>
</blockquote>

<p>how about some decisive advice.. Apply to us, if we don‚Äôt pic you, the
priority paths are not for you. just etg. Something where I can check
based on your ‚Äúadvice‚Äù.</p>

<p>Lack of accountability to reply to people who have spent years wasting
based on their response.</p>

<p><strong>Bloating a definition so that it becomes untestable or useless</strong></p>

<blockquote>
  <p>Another factor is that hiring takes up a lot of senior staff time ‚Äì
you need to source candidates, train them, test them out, and many
won‚Äôt work out. Moreover, a bad hire could easily harm morale, take
up a lot of time, or damage the reputation of the organisation, so
there is a lot of risk. This means that it takes a long time to
convert funding into good new staff, creating a talent
bottleneck. But if a potential hire takes a short amount of time to
evaluate, train and manage, they often wouldn‚Äôt get replaced for a
long time. ‚Äî <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable">Working at EAO</a> June 2017.</p>
</blockquote>

<p>they did the same thign wiht CC as well.</p>

<p><strong>Unclear motherfuckers</strong></p>

<p>It appears that another way to arrive at these above ‚Äúpriority career
paths‚Äù is to look at the problem profiles and check what the
bottlenecks are. For example, in the <a href="https://80000hours.org/problem-profiles/positively-shaping-artificial-intelligence/">profile on AI</a> (March 2017),
we see that 80khours calls for people to help in AI technical
research, AI strategy and policy, Complimentary roles and Advocacy and
capacity building. Here again they strongly discourage ETG as there
are enough funds. So basically EVERYTHING IN AI. I guess this is the
same with each problem profile resulting in the above career paths.</p>

<p><strong>Personal fit</strong></p>

<p>And ‚ÄúIf I am a good fit for these‚Äù, then I should apply. There is no
way for me of determining that I am a good personal fit, especially
considering that there are several other people and that it is
competitive as shit.</p>

<p>Another piece of evidence would be the Problem profile and their
alleged bottlenecks, such as in AI safety, strategy, complementary
roles  and here again they say TC TC TC. I am tired of how loosely
they use the word TC and then have the audacity to say that TC not in
general but in ungeneral. where So to me all this
screams there are several places where I am needed. And ‚ÄúIf I have a
good personal fit for these‚Äù, then you should focus on them
(identifying how you have a good personal fit is a problem beyond me)</p>

<p>Until I saw the EA forum (by accident), I didn‚Äôt know how to get
advice on these things or to look up people who are similar to you to
see who is a personal fit and who not. Which was like 2 weeks
back. Until then the word of 80khours is all I had. Things like these
makes me think there is a huge demand</p>

<h3 id="clarification-on-talent-constrained">Clarification on talent constrained</h3>

<h3 id="why-arent-there-many-more-eas-then">Why aren‚Äôt there many more EA‚Äôs then?</h3>

<h3 id="why-arent-ea-hiring-like-crazy-">Why aren‚Äôt EA hiring like crazy ?</h3>

<h3 id="is-bottleneck-and-talent-constrained-the-same-thing">Is bottleneck and talent constrained the same thing?</h3>

<h3 id="ea-is-funding-constrained">EA is funding constrained</h3>

<p>They have been making quite a fuss about working at EAOs and not
etging (as in the Why should we focus more on talent gaps)</p>

<p>ETG and that too as a quants person in trading is ranked 8th in their
top priority paths behind, AI safety, policy and strategy, China
specialists, working in EAOs and doing global priorities research.
80khours suggests ETG unless it is quants person in trading or
hedge-funds (It‚Äôs their 8th <a href="https://80000hours.org/articles/high-impact-careers/#our-list-of-priority-paths">top priority path</a>) probably due to
the potential<a href="https://80000hours.org/2017/05/how-much-do-hedge-fund-traders-earn/">300k<span>$</span> average donations per year</a>.</p>

<blockquote>
  <p>If you‚Äôre able to take a job where you earn more than you need, and
you think none of the categories above are a great fit for you, we‚Äôd
encourage you to consider earning to give. It‚Äôs also worth
considering this option if you have an unusually good fit for a very
high-earning career.</p>
</blockquote>

<blockquote>
  <p>In brief, we think our list of top problems (AI safety, biorisk, EA,
GPR, nuclear security, institutional decision-making) are mainly
constrained by research insights, either those that directly solve
the issue or insights about policy solutions.</p>
</blockquote>

<blockquote>
  <p>On the other hand, there is currently more funding available than is
being spent in these areas, so earning to give doesn‚Äôt seem like the
key bottleneck. ‚Äî<a href="https://80000hours.org/articles/high-impact-careers/">high impact careers</a>(Aug 2018)</p>
</blockquote>

<h3 id="very-easy-to-get-into-eao">Very easy to get into EAO</h3>

<p><strong>How easy is it to get into EAO</strong></p>

<p>It is very easy to get into EAO:</p>

<blockquote>
  <p>What are the predictors of success?  Based on our experience, the
people most likely to excel at EA organisations tend to have the
following traits:</p>

  <p>They really care about effective altruism, and are happy to talk about
it all day. This is one of the main things the organisations look for,
and it can be hard if you don‚Äôt share the same level of enthusiasm
about effective altruism as other staff.  They‚Äôre excited and
enthusiastic about the mission of the specific organisation they work
for. You get a lot of responsibility in these roles, and it can be
hard to sustain the intensity and effort required to succeed without
being excited by the mission and strategy of the organisation.</p>

  <p>They‚Äôre self-directed, able to manage their time well, they can create
efficient and productive plans, and keep track of complex
projects. ‚Äî <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/">Working at EAOs</a></p>
</blockquote>

<p>More shit like this in ‚Äúhow can I get these jobs at EA‚Äù at <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#how-can-you-get-these-jobs">Working at
EAOs</a>. Such as Volunteer at EAGx, help run a local EA group,
participate in feedback and reviews etc‚Ä¶ (why I say shit hopefully
is clear later).</p>

<h3 id="vague">vague</h3>

<h3 id="vague-1">vague</h3>

<p>So the survey is supposed to inform us of what we need more of. So
when I see GRs are needed I know GRs such as in Open Phil or any of
the other EA orgs, is what is needed. If they say operations people
are missing, then I think they need people like Tanya to run EA
orgs. Simple.</p>

<p>But when people say one-on-one skills, it could mean many things (as
AG pointed out): talking to politicians about causes (policy people
maybe), People who are good at convincing people changing their career
path (career counselors), it could also mean fundraisers in the front
line bringing the big bucks. I am sure we can think of other things as
well. So what is it that people in the survey meant? everything? Why
not just say, ‚Äúwe need policy people with good social skills
instead‚Äù. At least this way the community knows what you are missing
‚Äúexactly‚Äù rather than allowing it to interpretation. This way, people
can act on it. What ‚Äúgood social skills‚Äù means? Well let‚Äôs not get
into that discussion as well. If I and the surveyors could be provided
with one example, like Tanya for FHI, it makes things concrete and
people exactly know what the survey is talking about.</p>

<p>I am not a big fan of these broad terminologies as they don‚Äôt allow ME
to act on them. Case in point: ‚ÄúBest ways to gain Career Capital (CC)
are: Work at a growing organisation that has a reputation for high
performance; Getting a graduate degree; Working in Tech sector; Taking
a data science job; Working in think tanks; Making ‚Äúgood connections‚Äù,
Having runway etc‚Ä¶ ‚Äú Literally everything under the sun.</p>

<p>I am unable to act on it. I could in theory pursue everything. I don‚Äôt
know how to compare which has higher CC and lower CC. The definition
says: ‚ÄúCC puts you in a better position to make a difference in the
future, including skills, connections, credentials and runway.‚Äù When I
work in Data Science in a FAANG job do I have higher CC compared to
when I work in computer science degree? I don‚Äôt know.</p>

<p>Economists routinely measure the impact of high-school dropout vs
high-school diploma vs some years of college but dropout vs undergrad
degree vs grad degree, in different fields, using the variable ‚Äúmedian
weekly earnings‚Äù or ‚Äúlifetime earnings‚Äù. So when someone says, ‚Äúyou
need a degree to get ahead in life‚Äù, I can imagine what they mean $470
weekly wage increase. Whereas when someone says, ‚ÄúComputer Science PhD
is good CC‚Äù, I am lost. Contrast that to saying ‚ÄúBest ways to gain CC
is by looking at earnings‚Äù. Then I could look at median earnings for
Data Science Faang job vs Phd in computer science in say top 20
university (based on my capability) and get ahead in life.</p>

<h2 id="replaceable">Replaceable</h2>

<p>https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable</p>

<p>read it</p>

<p>Also some statements about
	value‚Ä¶ https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#but-wont-i-be-replaceable</p>

<h2 id="value">Value</h2>

<p>EA people are valued super high
:https://forum.effectivealtruism.org/posts/pzEJmc5gRskHjGTak/many-ea-orgs-say-they-place-a-lot-of-financial-value-on</p>

<p>Milan Griffes estimate on 80khours says he could make a
contribution of 97k$ tomorrow if he works in givewell
https://80000hours.org/2016/08/reflections-from-a-givewell-employee/</p>

<p>Calculating value is very tricky</p>

<p>ETG vs EA (https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/)</p>

<p>Milan Griffes</p>

<p>how much value 80khours thinks you have by asking what to pay for last
hire.</p>

<h2 id="what-did-i-think-before-what-changes-now-to-my-future">What did I think before, what changes now to my future?</h2>

<h2 id="how-hard-is-it-to-get-a-job-in-ea-now">How hard is it to get a job in EA now?</h2>

<p>There seems to be money, even trying to earn to give seems to be
pointless, considering at max I can be a data
scientist. Entrepreneurship and starting a non-profit could well be
things in the bank. ‚Äì&gt; based on the article talent gaps vs funding
gaps</p>

<h2 id="references">References</h2>

<h2 id="ea-is-tc-footnote">EA is TC (footnote)</h2>
<p>EA has been and is talent constrained according to surveys made by
80khours and CEA since 2017. Several organizations seem to think so in
these surveys: <a href="https://80000hours.org/2017/11/talent-gaps-survey-2017/">2017 survey</a>, <a href="https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions">2018 survey</a>, <a href="https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis">2019
survey</a>. In all the surveys EA‚Äôs on average claim to be more Talent
Constrained than Funding constrained. For example in 2019 EAOs
reported feeling more (3 out of 5 rating) Talent Constrained and less
(1 out of 5 rating) Funding Constrained<sup id="fnref:11:1" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>. More details in the
footnote <sup id="fnref:1:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>.</p>

<p>Since 2015 already, 80khours seems to be suggesting that we should
focus on providing talent to the community rather than ETG in <a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/">‚ÄúWhy
you should focus on talent gaps and not funding gaps</a>. They make
the case that if someone can setup a Charity that meets GiveWell‚Äôs
criteria, then they seem to have access to 10s of millions of
dollars. Another example 80khours made was about AI Safety and that
the funds were enough as per the evaluation of Open Phil and that
there are people who are ready to donate even more funds, but think
there isn‚Äôt enough ‚Äútalent pool‚Äù (back in 2015)<sup id="fnref:12:1" role="doc-noteref"><a href="#fn:12" class="footnote" rel="footnote">3</a></sup>.</p>

<p>In June 2017, in <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/">‚ÄúWorking at EAO</a>‚Äù, they quote the survey to
inform people, that EAOs are TC. During the same time, a podcast is
titled <a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/">‚ÄúThe world desperately needs AI strategists</a>‚Äù, where Miles
Brundage talks to Rob about AI strategists. Here Miles is seen making
claims that AI strategy is a growth area and that jobs are currently
‚Äúfew‚Äù and ‚Äúpretty competitive‚Äù. Just as seen in the growth of AI
safety there is expected to be growth in this space as well in a
couple of years. Whether the adjective desperate was warrented or not
is a separate debate but the message seems to be that there is LOT OF
TC (atleast based on the title).</p>

<p>As late as August 2018, 80k can be seen saying that we need people to
work on AI safety, Biorisk, EA, GPR, Nuclear security and
institutional decision making.</p>

<blockquote>
  <p>Why did we choose these categories (Research, Govt policy, eff non
profits, ETG)<sup id="fnref:13:1" role="doc-noteref"><a href="#fn:13" class="footnote" rel="footnote">5</a></sup>?  Why do we especially highlight
research, policy and non-profit jobs; deprioritize earning to give;
and omit advocacy and entrepreneurship?</p>

  <p>In brief, we think our list of top problems (AI safety, biorisk, EA,
GPR, nuclear security, institutional decision-making) are mainly
constrained by research insights, either those that directly solve the
issue or insights about policy solutions. ‚Äî <a href="https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories">High Impact Careers
</a> Aug 2018</p>
</blockquote>

<p>In Nov 2019, 80khours tries to clear up the ‚Äúconfusions‚Äù we create
when we talk about ‚Äútalent gaps‚Äù.</p>

<blockquote>
  <p>Rather than funding vs. talent gaps, we propose that people aim to
identify specific bottlenecks facing the field and the skills needed
to resolve them. A ‚Äòbottleneck‚Äô is the resource that a field most
needs in order to make progress.</p>
</blockquote>

<p>Ok, what if a cause is bottlenecked by a specific skill? Let me
think‚Ä¶ ah Talent constrained. It appears that the word is not
confusing as per their initial definition. But somehow somewhere in
the way, wait am not sure what happened. Let‚Äôs read that article
again and see where that gets us‚Ä¶</p>

<blockquote>
  <p>Today we usually recommend that people who are a good fit for
filling these bottlenecks treat them as their first priority. This
usually means initially considering relevant jobs in research, top
non-profits and policy, and if you‚Äôre willing to consider something
especially competitive, our list of priority paths.</p>

  <p>In contrast, we rarely think that earning to give should be the top
priority for people who could be a good fit for these other
roles. This is another idea we hoped to highlight by talking about
‚Äòtalent constraints‚Äô.</p>

  <p>However, we also recognize that our priority problems aren‚Äôt ‚Äòtalent
constrained‚Äô in general, and our priority paths require a fairly
narrow set of skills. So, we continue to recommend building career
capital and earning to give as a high impact option for people whose
skills don‚Äôt match the particular constraints currently faced by our
priority problems.</p>
</blockquote>

<p><strong>What I think Talent Constrained means</strong></p>

<p>EAOs are talent constrained when there are not enough capable people
to work at that EAO. There is a lot of demand and the supply is really
low was my thought process.</p>

<p><strong>80khours defines it:</strong></p>

<p>Lack of people with specific skill set.</p>

<p>I am going to try and argue here that for majority of the people EA is
not constrained by talent.</p>

<p>First we need to be more clear than 80khours, so we talk about the
lack of talent constrain, in 80khours suggested top career paths.</p>

<ul>
  <li>AI strategy and Policy research</li>
  <li>AI safety technical research</li>
  <li>Grant maker focused on top areas</li>
  <li>Work in effective Altruism orgs</li>
  <li>Global priorities researcher</li>
  <li>Bio-risk strategy and policy</li>
  <li>China Specialists</li>
  <li>Earning to give in quant trading</li>
  <li>Decision making psychology research and roles</li>
</ul>

<hr />

<blockquote>
  <p>People sometimes act as if the main alternative to earning to give is
working at an ‚Äòeffective altruism non-profit‚Äô. However, this misses
many types of high impact roles including those in academia, policy
and relevant companies, which could absorb far more people. Our recent
survey showed that roles in policy are highly valued, as are research
positions that could be done within academia.</p>
</blockquote>

<h2 id="footnotes">Footnotes</h2>

<p>about ETG as in the later paragraph of the quotes.</p>

<h1 id="from-is-ea-bottlenecked-2">from is ea bottlenecked 2</h1>
<h2 id="qualms-with-80khours">Qualms with 80khours</h2>

<p>I am really frustrated with 80khours. Atleast to my knowledge they
have made 4 claims:</p>

<ul>
  <li>replaceability</li>
  <li>TC</li>
  <li>Pushing CC</li>
  <li>how easy getting a job in EA is</li>
  <li>They write in english (not numbers)</li>
  <li>They don‚Äôt think they need to apologise</li>
  <li>
    <p>very bad explanation:
Think twice Talent gaps
Survey 2019 EA work about cash</p>
  </li>
  <li>
    <p>LAck of decisive advice (saying just about everything)</p>
  </li>
  <li>
    <p>bloating a definition to make it useless</p>
  </li>
  <li>contradiction:
profile on AI says basically everything where as it is somehow TC in
specific areas in AI.</li>
</ul>

<p>TC not in general but for AI it is in general, for Working in EAO it
is in general.</p>

<ul>
  <li>
    <p>lack of updation of posts.</p>
  </li>
  <li>Several definitions for TC (god help me)</li>
  <li>
    <p>repeat posts (not sure what the difference is)</p>
  </li>
  <li>Mistakes mistakes mistakes</li>
</ul>

<p>recent hire cost,</p>

<ul>
  <li>useless advice</li>
</ul>

<p>go to the companies and ask them how much donation I would be
irrelavent. BS</p>

<ul>
  <li>
    <p>Not one place do they seem to mention the EA forum (My savior)</p>
  </li>
  <li>
    <p>how useless ETG is</p>
  </li>
  <li>
    <p>untestable claims unless for EA forum:</p>
  </li>
</ul>

<blockquote>
  <p>In brief, we think our list of top problems (AI safety, biorisk, EA,
GPR, nuclear security, institutional decision-making) are mainly
constrained by research insights, either those that directly solve
the issue or insights about policy solutions.</p>
</blockquote>

<p>Look at is-ea-bottlenecked.markdown</p>

<ul>
  <li>one of the hardest things to do is to estimate the impact and they
conviniently leave that out. They get very createive with their
example giving.</li>
</ul>

<p><strong>Other</strong></p>

<ul>
  <li>They expect english to convey shit‚Ä¶ not numbers</li>
</ul>

<p>When someone asked that 80khours hsould consider the cost of us
applying and figuring out how much life sucks they literally made a
shitty comment.</p>

<p>Peter Expresses his concern on the bemoaning of ETG. As evidence to
his claim I believe unless I can be a quants trader I am a loser and
that it is better to focus on working at an EAO as a result. And now
even this is turning out to be hard as fuck. And the one org we turn
to for career advice sucks.</p>

<p>https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#choosing-which-organisation-to-work-at</p>

<p>useless advice</p>

<p>https://80000hours.org/key-ideas/#most-pressing-problems
contradictory advice in 2019 article: operations staff still bottleneck</p>

<h2 id="how-replaceable-is-gr-in-actually">How replaceable is GR in actually?</h2>

<p>I tried to get data but that didn‚Äôt seem to work out in this case.
But is this what the world is undergoing? is it true that who ever
doens‚Äôt get the job has to do something significantly bad ? according
to peter hurford yes, according to his friends yes.</p>

<p>So now that EA is not TC atleast for the type of jobs I was planning
to upskill myself in (GR, AI safety guy), I need another plan.</p>

<p>I was thinking of working in GiveWell maybe and from there on going
further. Or doing a masters in AI and then finding my way into there.</p>

<h2 id="you-wont-get-into-ea">You wont get into EA</h2>

<p>Start with 80khours telling people they shouldn‚Äôt ETG (as it is
pointless). They should focus on</p>

<p>and maybe list all the people who didn‚Äôt get in</p>

<p>Orgs are hiring slow they remain small‚Ä¶</p>

<h2 id="how-i-think-80khours-misleads-everybody">How I think 80khours misleads everybody</h2>

<ul>
  <li>
    <p>definitions</p>
  </li>
  <li>
    <p>no examples</p>
  </li>
  <li>
    <p>working for the elite</p>
  </li>
</ul>

<p>or try to see if you can make that a post the things I have written
earlier.</p>

<p>or maybe it is just better to take mild digs at them‚Ä¶ here and
there.</p>

<p>Furthermore,
80khours has a history with mistakes in the past. They have gone <a href="https://80000hours.org/search/?cx=007036038893981741514%3Ad-war0ad7jy&amp;cof=FORID%3A11&amp;q=replaceability">back
and forth with replaceability</a> since 2012, they realized they put
too much stress on career capital, <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/#what-are-the-predictors-of-success">downplayed how hard it is to get a
job in EA</a>. I am having a hard time understanding how several people</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:11" role="doc-endnote">
      <blockquote>
        <p>1 = how much things cost is never a practical limiting factor for
you; 5 = you are considering shrinking to avoid running out of money</p>
      </blockquote>

      <blockquote>
        <p>1 = you could hire many outstanding candidates who want to work at
your org if you chose that approach, or had the capacity to absorb
them, or had the money; 5 = you can‚Äôt get any of the people you need
to grow, or you are losing the good people you have</p>
      </blockquote>
      <p><a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a>¬†<a href="#fnref:11:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:1" role="doc-endnote">
      <p>In the 2017 survey they (80khours) say,</p>

      <blockquote>
        <p>On a 0-4 scale EA organisations viewed themselves as 2.5 ‚Äòtalent
constrained‚Äô and 1.2 ‚Äòfunding constrained‚Äô (average),‚Ä¶</p>
      </blockquote>

      <p>In 2017 surveyed orgs seem to want Forecasting-Priorities
capabilities, GRs, Management and operations as top 4.</p>

      <p>2017 survey includes:</p>

      <blockquote>
        <p>The survey includes (number of respondents in parentheses): 80,000
Hours (3), AI Impacts (1), Animal Charity Evaluators (1), Center for
Applied Rationality (2), Centre for Effective Altruism (3), Centre for
the Study of Existential Risk (1), Charity Science: Health (1),
Foundational Research Institute (2), Future of Humanity Institute (3),
GiveWell (2), Global Priorities Institute (1), Leverage Research (1),
Machine Intelligence Research Institute (2), Open Philanthropy Project
(5), Rethink Charity (1), Sentience Institute (1) and Other (6) (who
were mainly researchers).</p>
      </blockquote>

      <p>In the 2018 survey they (80khours) say,</p>

      <blockquote>
        <p>On a scale of 0 to 4, respondents saw themselves as 2.8 constrained
by talent and 1.5 by funding, similar to last year and consistent
with the donation trade-off figures.</p>
      </blockquote>

      <blockquote>
        <p>The effective altruism community‚Äôs greatest talent needs are inthe
fields of operations, management, generalist research, government and
policy expertise, and AI/machine learning expertise‚Ä¶ Leaders thought
the key bottleneck for the community is to get More dedicated people
(e.g. work at EA orgs, research in AI safety/biosecurity/economics,
etg over $1m) converted from moderate engagement. The second biggest
is to increase impact of existing dedicated people through e.g. better
research, coordination, decision-making.‚Äù ‚Äî 2018 survey</p>
      </blockquote>

      <p>In 2018 surveyed orgs wanted Operations, Management, GRs, and AI
technical expertise were the top 4.</p>

      <p>2018 survey includes:</p>

      <blockquote>
        <p>80,000 Hours (3), AI Impacts (1), Animal Charity Evaluators (2),
Center for Applied Rationality (2), Centre for Effective Altruism
(2), Centre for the Study of Existential Risk (1), Berkeley Center
for Human-Compatible AI (1), Charity Science: Health (1), DeepMind
(1), Foundational Research Institute (2), Future of Humanity
Institute (2), GiveWell (1), Global Priorities Institute (2),
LessWrong (1), Machine Intelligence Research Institute (1), Open
Philanthropy Project (4), OpenAI (1), Rethink Charity (2), Sentience
Institute (1), SparkWave (1), and Other (5)</p>
      </blockquote>
      <p><a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a>¬†<a href="#fnref:1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:12" role="doc-endnote">
      <p>Well if you think of OpenAI, yes they seemt to be havign
billions in investment for them to burn, but just last month MIRI
came to me asking me for money in december as they could not meet
some 1m dollars or something‚Ä¶ <!-- rewrite and check if necessary -->¬†<a href="#fnref:12" class="reversefootnote" role="doc-backlink">&#8617;</a>¬†<a href="#fnref:12:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:16" role="doc-endnote">
      <p><a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/">‚ÄúThe world desperately needs AI strategists</a>‚Äù, where Miles
Brundage talks to Rob about AI strategists. Here Miles is seen making
claims that AI strategy is a growth area and that jobs are currently
‚Äúfew‚Äù and ‚Äúpretty competitive‚Äù. Just as seen in the growth of AI
safety there is expected to be growth in this space as well in a
couple of years. Whether the adjective desperate was warrented or not
is a separate debate but the message seems to be that there is LOT OF
TC (atleast based on the title).¬†<a href="#fnref:16" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:13" role="doc-endnote">
      <p>I think it is an error and that they were clearly not talking¬†<a href="#fnref:13" class="reversefootnote" role="doc-backlink">&#8617;</a>¬†<a href="#fnref:13:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:15" role="doc-endnote">
      <p>EA has been and is talent constrained according to surveys made
by 80khours and CEA since 2017. Several organizations seem to
think so in these surveys: <a href="https://80000hours.org/2017/11/talent-gaps-survey-2017/">2017 survey</a>, <a href="https://80000hours.org/2018/10/2018-talent-gaps-survey/#appendix-2-answers-to-open-comment-questions">2018 survey</a>,
<a href="https://forum.effectivealtruism.org/posts/TpoeJ9A2G5Sipxfit/ea-leaders-forum-survey-on-ea-priorities-data-and-analysis">2019 survey</a>. In all the surveys EA‚Äôs on average claim to be
more Talent Constrained than Funding constrained. For example in
2019 EAOs reported feeling more (3 out of 5 rating) Talent
Constrained and less (1 out of 5 rating) Funding
Constrained<sup id="fnref:11:2" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>. More details in the footnote <sup id="fnref:1:2" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">2</a></sup>.</p>

      <p>Since 2015 already, 80khours seems to be suggesting that we should
focus on providing talent to the community rather than ETG in <a href="https://80000hours.org/2015/11/why-you-should-focus-more-on-talent-gaps-not-funding-gaps/">‚ÄúWhy
you should focus on talent gaps and not funding gaps</a>. They make
the case that if someone can setup a Charity that meets GiveWell‚Äôs
criteria, then they seem to have access to 10s of millions of
dollars. Another example 80khours made was about AI Safety and that
the funds were enough as per the evaluation of Open Phil and that
there are people who are ready to donate even more funds, but think
there isn‚Äôt enough ‚Äútalent pool‚Äù (back in 2015)<sup id="fnref:12:2" role="doc-noteref"><a href="#fn:12" class="footnote" rel="footnote">3</a></sup>.</p>

      <p>In June 2017, in <a href="https://80000hours.org/career-reviews/working-at-effective-altruist-organisations/">‚ÄúWorking at EAO</a>‚Äù, they quote the survey to
inform people, that EAOs are TC. During the same time, a podcast is
titled <a href="https://80000hours.org/podcast/episodes/the-world-desperately-needs-ai-strategists-heres-how-to-become-one/">‚ÄúThe world desperately needs AI strategists</a>‚Äù, where Miles
Brundage talks to Rob about AI strategists. Here Miles is seen making
claims that AI strategy is a growth area and that jobs are currently
‚Äúfew‚Äù and ‚Äúpretty competitive‚Äù. Just as seen in the growth of AI
safety there is expected to be growth in this space as well in a
couple of years. Whether the adjective desperate was warrented or not
is a separate debate but the message seems to be that there is LOT OF
TC (atleast based on the title).</p>

      <p>As late as August 2018, 80k can be seen saying that we need people to
work on AI safety, Biorisk, EA, GPR, Nuclear security and
institutional decision making.</p>

      <blockquote>
        <p>Why did we choose these categories (Research, Govt policy, eff non
profits, ETG)<sup id="fnref:13:2" role="doc-noteref"><a href="#fn:13" class="footnote" rel="footnote">5</a></sup>?  Why do we especially highlight
research, policy and non-profit jobs; deprioritize earning to give;
and omit advocacy and entrepreneurship?</p>

        <p>In brief, we think our list of top problems (AI safety, biorisk, EA,
GPR, nuclear security, institutional decision-making) are mainly
constrained by research insights, either those that directly solve the
issue or insights about policy solutions. ‚Äî <a href="https://80000hours.org/articles/high-impact-careers/#why-did-we-choose-these-categories">High Impact Careers
</a> Aug 2018</p>
      </blockquote>

      <p>In Nov 2019, 80khours tries to clear up the ‚Äúconfusions‚Äù we create
when we talk about ‚Äútalent gaps‚Äù.</p>

      <blockquote>
        <p>Rather than funding vs. talent gaps, we propose that people aim to
identify specific bottlenecks facing the field and the skills needed
to resolve them. A ‚Äòbottleneck‚Äô is the resource that a field most
needs in order to make progress.</p>
      </blockquote>

      <p>Ok, what if a cause is bottlenecked by a specific skill? Let me
think‚Ä¶ ah Talent constrained. It appears that the word is not
confusing as per their initial definition. But somehow somewhere in
the way, wait am not sure what happened. Let‚Äôs read that article
again and see where that gets us‚Ä¶</p>

      <blockquote>
        <p>Today we usually recommend that people who are a good fit for
filling these bottlenecks treat them as their first priority. This
usually means initially considering relevant jobs in research, top
non-profits and policy, and if you‚Äôre willing to consider something
especially competitive, our list of priority paths.</p>

        <p>In contrast, we rarely think that earning to give should be the top
priority for people who could be a good fit for these other
roles. This is another idea we hoped to highlight by talking about
‚Äòtalent constraints‚Äô.</p>

        <p>However, we also recognize that our priority problems aren‚Äôt ‚Äòtalent
constrained‚Äô in general, and our priority paths require a fairly
narrow set of skills. So, we continue to recommend building career
capital and earning to give as a high impact option for people whose
skills don‚Äôt match the particular constraints currently faced by our
priority problems.</p>
      </blockquote>

      <p><strong>What I think Talent Constrained means</strong></p>

      <p>EAOs are talent constrained when there are not enough capable people
to work at that EAO. There is a lot of demand and the supply is really
low was my thought process.</p>

      <p><strong>80khours defines it:</strong></p>

      <p>Lack of people with specific skill set.</p>

      <p>I am going to try and argue here that for majority of the people EA is
not constrained by talent.</p>

      <p>First we need to be more clear than 80khours, so we talk about the
lack of talent constrain, in 80khours suggested top career paths.</p>

      <ul>
        <li>AI strategy and Policy research</li>
        <li>AI safety technical research</li>
        <li>Grant maker focused on top areas</li>
        <li>Work in effective Altruism orgs</li>
        <li>Global priorities researcher</li>
        <li>Bio-risk strategy and policy</li>
        <li>China Specialists</li>
        <li>Earning to give in quant trading</li>
        <li>Decision making psychology research and roles</li>
      </ul>

      <blockquote>
        <p>People sometimes act as if the main alternative to earning to give is
working at an ‚Äòeffective altruism non-profit‚Äô. However, this misses
many types of high impact roles including those in academia, policy
and relevant companies, which could absorb far more people. Our recent
survey showed that roles in policy are highly valued, as are research
positions that could be done within academia.</p>
      </blockquote>
      <p><a href="#fnref:15" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
:ET