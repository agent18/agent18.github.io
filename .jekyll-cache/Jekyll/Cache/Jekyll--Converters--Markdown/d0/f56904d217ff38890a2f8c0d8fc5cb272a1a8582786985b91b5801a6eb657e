I"@<h4 id="dangers-of-availability">Dangers of Availability</h4>

<p>Eleizer gives many examples to show that if we trust availability, we sort of go into this absurdity bias. He points out that societies constantly come up with an upperbound of the problems they’ll have, based on what they have seen in the past. For example, people refuse to buy flood insurance even though it is subsidized, as floods have not happened in a while (Kunreuther et. al. (1993)).</p>

<blockquote>
  <p>If something does not happen, its not available, and hence deemed to have zero probability.</p>
</blockquote>

<blockquote>
  <p>Instead, past experience of small hazards seems to set a perceived upper bound on risk.  A society well-protected against minor hazards takes no action against major risks, building on flood plains once the regular minor floods are eliminated.</p>
</blockquote>

<p>Look at Tamil Nadu. 2 years back there was so much flood as a result of non stop rains and poor drainage. The whole city was shaken for 1 week straight. No electricity, no food for many people. We have never had such a flood in our cities. So many lives claimed, and massive damages. The state was completely not prepared for such an event, probably because it had never happened before. The state couldn’t handle current rains, let alone massive floods.</p>

<p>And then there is Sheldon (from The big bang theory). People laugh at the absurdity of Sheldon waking his roommate in the middle of the night for a fire safety drill. It appears that many would not know what to do when there is a fire. People laugh when Sheldon shows one of his guests, emergency supplies in case needed. The jokes on us I guess. Fuck me! Even though the probability of that event is quite low, even though in the last 100 years it didn’t happen to you, would it hurt to be prepared? Especially considering the devastating impact that these events leave behind once they happen, and their calculable probability.</p>

<blockquote>
  <p>The wise would extrapolate from a memory of small hazards to the possibility of large hazards.</p>
</blockquote>

<p>This is meaning to say to extrapolate from small hazards how the impact would be in the case of large hazards, if they happen. And prepare for it.</p>

<blockquote>
  <p>A society subject to regular minor hazards treats those minor hazards as an upper bound on the size of the risks, guarding against regular minor floods but not occasional major floods.</p>
</blockquote>

<blockquote>
  <p>Memory is not always a good guide to probabilities in the past, let alone the future.
Word.</p>
</blockquote>

<h3 id="open-issue">Open Issue</h3>
<p>How is it concluded by Eliezer that there is an availability bias at work, while talking about the 1979 study?</p>

<p>Can we just show the middle finger to correlations that we think might not be causation related.</p>

:ET